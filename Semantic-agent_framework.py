"""
Unified Agent Framework - Enterprise Edition
Microsoft Agent Framework íŒ¨í„´ í†µí•© (MCP, Approval, Streaming ì§€ì›)

ğŸ”¥ ì£¼ìš” ê³ ë„í™” ë‚´ìš©:
1. MCP (Model Context Protocol) ì„œë²„ í†µí•© - ì™¸ë¶€ ë„êµ¬ ì—°ë™
2. Human-in-the-loop ìŠ¹ì¸ ì‹œìŠ¤í…œ - ë¯¼ê°í•œ ì‘ì—… ìŠ¹ì¸ í•„ìš”
3. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì› - ì‹¤ì‹œê°„ í† í° ì¶œë ¥
4. ì¬ì‹œë„ ë¡œì§ ë° íšŒë¡œ ì°¨ë‹¨ê¸° íŒ¨í„´ - ì¥ì•  ê²©ë¦¬
5. ë¹„ë™ê¸° ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ - Pub-Sub íŒ¨í„´
6. í–¥ìƒëœ ë©”ëª¨ë¦¬ ê´€ë¦¬ - LRU ìºì‹œ
7. Supervisor Agent íŒ¨í„´ - ë©€í‹° ì—ì´ì „íŠ¸ í˜‘ì—…
8. ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë° ë£¨í”„ ì§€ì› - ë™ì  ì›Œí¬í”Œë¡œìš°
9. ë²„ì „ ê´€ë¦¬ ë° ë¡¤ë°± - ìƒíƒœ ë³µì›
10. ìƒì„¸ ë©”íŠ¸ë¦­ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

ê¸°ì¡´ ì½”ë“œ ëŒ€ë¹„ ê°œì„ ì‚¬í•­:
- ì½”ë“œ ë¼ì¸: 500ì¤„ â†’ 1,100ì¤„ (2.2ë°° ì¦ê°€)
- Agent íƒ€ì…: 3ê°œ â†’ 5ê°œ
- ë°ëª¨ ì›Œí¬í”Œë¡œìš°: 2ê°œ â†’ 4ê°œ
- CLI ëª…ë ¹ì–´: 5ê°œ â†’ 12ê°œ
- ë””ìì¸ íŒ¨í„´: 4ê°œ ì¶”ê°€ (Circuit Breaker, Pub-Sub, LRU Cache, Supervisor)

pip install semantic-kernel python-dotenv redis opentelemetry-api opentelemetry-sdk pydantic
"""

import os
import asyncio
import json
import logging
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any, Callable, Set, AsyncIterator
from datetime import datetime, timezone
from enum import Enum
from collections import defaultdict
from dataclasses import dataclass, field
import time

from dotenv import load_dotenv
from pydantic import BaseModel, Field

# Semantic Kernel
from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase
from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior
from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import AzureChatPromptExecutionSettings
from semantic_kernel.connectors.ai.open_ai.services.azure_chat_completion import AzureChatCompletion
from semantic_kernel.contents.chat_history import ChatHistory
from semantic_kernel.contents.streaming_chat_message_content import StreamingChatMessageContent

# OpenTelemetry
from opentelemetry import trace
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import ConsoleSpanExporter, BatchSpanProcessor
from opentelemetry.sdk.resources import Resource


# ============================================================================
# ì„¤ì • (Configuration)
# ============================================================================

# ğŸ†• LLM ëª¨ë¸ ì¤‘ì•™ ì„¤ì •
DEFAULT_LLM_MODEL = "gpt-4.1"  # ë˜ëŠ” "gpt-4o-mini" ë“± ì›í•˜ëŠ” ëª¨ë¸ëª…
DEFAULT_API_VERSION = "2024-08-01-preview"


# ============================================================================
# ìœ í‹¸ë¦¬í‹° & ì¸í”„ë¼ (New)
# ============================================================================

class StructuredLogger:
    """
    JSON í˜•íƒœì˜ êµ¬ì¡°í™”ëœ ë¡œê¹…
    """
    def __init__(self, name: str):
        self.logger = logging.getLogger(name)

    def info(self, message: str, **kwargs):
        self._log(logging.INFO, message, **kwargs)

    def error(self, message: str, **kwargs):
        self._log(logging.ERROR, message, **kwargs)

    def warning(self, message: str, **kwargs):
        self._log(logging.WARNING, message, **kwargs)

    def _log(self, level: int, message: str, **kwargs):
        log_data = {
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "message": message,
            **kwargs
        }
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” json.dumps ì‚¬ìš©, ì—¬ê¸°ì„œëŠ” ê°€ë…ì„±ì„ ìœ„í•´ í¬ë§·íŒ…
        self.logger.log(level, f"[{level}] {json.dumps(log_data, ensure_ascii=False)}")

async def retry_with_backoff(
    func: Callable,
    max_retries: int = 3,
    base_delay: float = 1.0,
    max_delay: float = 60.0,
    exponential_base: float = 2.0,
    *args,
    **kwargs
) -> Any:
    """
    ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„ ë¡œì§
    """
    retries = 0
    while True:
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            retries += 1
            if retries > max_retries:
                raise e

            delay = min(base_delay * (exponential_base ** (retries - 1)), max_delay)
            logging.warning(f"âš ï¸ ì¬ì‹œë„ {retries}/{max_retries} ({delay:.2f}s í›„): {e}")
            await asyncio.sleep(delay)



# ============================================================================
# í•µì‹¬ ë°ì´í„° ëª¨ë¸
# ============================================================================

class AgentRole(str, Enum):
    """
    Agent ì—­í•  ì •ì˜

    [ìˆ˜ì •] SUPERVISOR ì¶”ê°€ - Microsoft AutoGen íŒ¨í„´
    ê¸°ì¡´: ASSISTANT, USER, SYSTEM, FUNCTION, ROUTER, ORCHESTRATOR
    ì¶”ê°€: SUPERVISOR - ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ê°ë…í•˜ê³  ì¡°ìœ¨í•˜ëŠ” ì—­í• 
    """
    ASSISTANT = "assistant"
    USER = "user"
    SYSTEM = "system"
    FUNCTION = "function"
    ROUTER = "router"
    ORCHESTRATOR = "orchestrator"
    SUPERVISOR = "supervisor"  # ğŸ†• ì¶”ê°€


class ExecutionStatus(str, Enum):
    """
    ì‹¤í–‰ ìƒíƒœ ì •ì˜

    [ìˆ˜ì •] ìŠ¹ì¸ ê´€ë ¨ ìƒíƒœ ì¶”ê°€ - Human-in-the-loop íŒ¨í„´
    ê¸°ì¡´: PENDING, RUNNING, COMPLETED, FAILED, PAUSED, WAITING_APPROVAL
    ì¶”ê°€: APPROVED, REJECTED
    """
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    PAUSED = "paused"
    WAITING_APPROVAL = "waiting_approval"
    APPROVED = "approved"    # ğŸ†• ì¶”ê°€
    REJECTED = "rejected"    # ğŸ†• ì¶”ê°€


class ApprovalStatus(str, Enum):
    """
    ìŠ¹ì¸ ìƒíƒœ ì •ì˜

    [ì‹ ê·œ] Microsoft Agent Frameworkì˜ approval íŒ¨í„´
    - PENDING: ìŠ¹ì¸ ëŒ€ê¸° ì¤‘
    - APPROVED: ì‚¬ìš©ìê°€ ìŠ¹ì¸í•¨
    - REJECTED: ì‚¬ìš©ìê°€ ê±°ë¶€í•¨
    - AUTO_APPROVED: ìë™ ìŠ¹ì¸ë¨ (ì•ˆì „í•œ ì‘ì—…)
    """
    PENDING = "pending"
    APPROVED = "approved"
    REJECTED = "rejected"
    AUTO_APPROVED = "auto_approved"  # ğŸ†• ìë™ ìŠ¹ì¸


class Message(BaseModel):
    """
    ë©”ì‹œì§€ ëª¨ë¸

    [ìˆ˜ì •] function_call í•„ë“œ ì¶”ê°€
    - í•¨ìˆ˜ í˜¸ì¶œ ì •ë³´ë¥¼ ì €ì¥í•˜ì—¬ OpenAI Function Calling ì§€ì›
    """
    role: AgentRole
    content: str
    metadata: Dict[str, Any] = Field(default_factory=dict)
    timestamp: str = Field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    agent_name: Optional[str] = None
    function_call: Optional[Dict[str, Any]] = None  # ğŸ†• í•¨ìˆ˜ í˜¸ì¶œ ì •ë³´

    class Config:
        use_enum_values = True


class AgentState(BaseModel):
    """
    Agent ìƒíƒœ - ì²´í¬í¬ì¸íŒ… ë° ë³µì› ì§€ì›

    [ìˆ˜ì •] pending_approvals, metrics í•„ë“œ ì¶”ê°€
    - pending_approvals: ìŠ¹ì¸ ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ ëª©ë¡
    - metrics: ì‹¤í–‰ ë©”íŠ¸ë¦­ (ì‹œê°„, í† í° ë“±)
    """
    messages: List[Message] = Field(default_factory=list)
    current_node: str = "start"
    visited_nodes: List[str] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)
    session_id: str
    workflow_name: str = "default"
    execution_status: ExecutionStatus = ExecutionStatus.PENDING
    pending_approvals: List[Dict[str, Any]] = Field(default_factory=list)  # ğŸ†• ìŠ¹ì¸ ëŒ€ê¸°
    metrics: Dict[str, Any] = Field(default_factory=dict)  # ğŸ†• ë©”íŠ¸ë¦­

    def add_message(self, role: AgentRole, content: str, agent_name: Optional[str] = None,
                   function_call: Optional[Dict[str, Any]] = None):
        """ë©”ì‹œì§€ ì¶”ê°€"""
        self.messages.append(Message(
            role=role,
            content=content,
            agent_name=agent_name,
            function_call=function_call
        ))

    def get_conversation_history(self, max_messages: int = 10) -> List[Message]:
        """ìµœê·¼ ëŒ€í™” ê¸°ë¡"""
        return self.messages[-max_messages:]

    def add_pending_approval(self, approval_request: Dict[str, Any]):
        """
        ìŠ¹ì¸ ëŒ€ê¸° ìš”ì²­ ì¶”ê°€

        [ì‹ ê·œ] Human-in-the-loop íŒ¨í„´ ì§€ì›
        """
        self.pending_approvals.append(approval_request)
        self.execution_status = ExecutionStatus.WAITING_APPROVAL


class NodeResult(BaseModel):
    """
    ë…¸ë“œ ì‹¤í–‰ ê²°ê³¼

    [ìˆ˜ì •] requires_approval, approval_data í•„ë“œ ì¶”ê°€
    - ìŠ¹ì¸ì´ í•„ìš”í•œ ì‘ì—…ì¸ì§€ í‘œì‹œ
    """
    node_name: str
    output: str
    next_node: Optional[str] = None
    metadata: Dict[str, Any] = Field(default_factory=dict)
    success: bool = True
    error: Optional[str] = None
    tokens_used: int = 0
    duration_ms: float = 0.0
    requires_approval: bool = False  # ğŸ†• ìŠ¹ì¸ í•„ìš” ì—¬ë¶€
    approval_data: Optional[Dict[str, Any]] = None  # ğŸ†• ìŠ¹ì¸ ë°ì´í„°


# ============================================================================
# AIFunction - Microsoft Agent Framework íŒ¨í„´
# ============================================================================

class AIFunction(ABC):
    """
    AI Function ì¶”ìƒ í´ë˜ìŠ¤ - Microsoft Agent Framework íŒ¨í„´

    [ì‹ ê·œ] OpenAI Function Callingì„ ìœ„í•œ ì¶”ìƒ í´ë˜ìŠ¤

    ì°¸ì¡°: https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/tools/

    ì£¼ìš” ê¸°ëŠ¥:
    - get_schema(): OpenAI Function Calling ìŠ¤í‚¤ë§ˆ ë°˜í™˜
    - invoke_with_metrics(): ë©”íŠ¸ë¦­ê³¼ í•¨ê»˜ ì‹¤í–‰
    """

    def __init__(self, name: str, description: str, parameters: Optional[Dict[str, Any]] = None):
        self.name = name
        self.description = description
        self.parameters = parameters or {}
        self.execution_count = 0
        self.total_duration_ms = 0.0

    @abstractmethod
    async def execute(self, **kwargs) -> Any:
        """í•¨ìˆ˜ ì‹¤í–‰"""
        pass

    def get_schema(self) -> Dict[str, Any]:
        """
        OpenAI Function Calling ìŠ¤í‚¤ë§ˆ

        [ì‹ ê·œ] OpenAI APIì— ì „ë‹¬í•  í•¨ìˆ˜ ìŠ¤í‚¤ë§ˆ ìƒì„±
        """
        return {
            "name": self.name,
            "description": self.description,
            "parameters": self.parameters
        }

    async def invoke_with_metrics(self, **kwargs) -> tuple[Any, float]:
        """
        ë©”íŠ¸ë¦­ê³¼ í•¨ê»˜ ì‹¤í–‰

        [ì‹ ê·œ] ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë° ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        """
        start_time = time.time()
        result = await self.execute(**kwargs)
        duration_ms = (time.time() - start_time) * 1000

        self.execution_count += 1
        self.total_duration_ms += duration_ms

        return result, duration_ms


class ApprovalRequiredAIFunction(AIFunction):
    """
    Human-in-the-loop ìŠ¹ì¸ì´ í•„ìš”í•œ í•¨ìˆ˜

    [ì‹ ê·œ] Microsoft Agent Frameworkì˜ approval íŒ¨í„´

    ì°¸ì¡°: https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/tools/ai_tool_with_approval.py

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ê²°ì œ ì²˜ë¦¬
    - ë°ì´í„° ì‚­ì œ
    - ì¤‘ìš”í•œ ì„¤ì • ë³€ê²½
    - ì™¸ë¶€ API í˜¸ì¶œ

    ìë™ ìŠ¹ì¸:
    - auto_approve_threshold ì„¤ì • ì‹œ ì•ˆì „í•œ ì‘ì—…ì€ ìë™ ìŠ¹ì¸
    - ì˜ˆ: ì½ê¸° ì „ìš© ì‘ì—…, ë‚®ì€ ê¸ˆì•¡ì˜ ê²°ì œ ë“±
    """

    def __init__(self, base_function: AIFunction,
                 approval_callback: Optional[Callable] = None,
                 auto_approve_threshold: Optional[float] = None):
        super().__init__(
            name=f"{base_function.name}_approval_required",
            description=f"{base_function.description} (Requires Approval)",
            parameters=base_function.parameters
        )
        self.base_function = base_function
        self.approval_callback = approval_callback
        self.auto_approve_threshold = auto_approve_threshold

    async def execute(self, **kwargs) -> Dict[str, Any]:
        """ìŠ¹ì¸ ìš”ì²­ ìƒì„±"""
        approval_request = {
            "function_name": self.base_function.name,
            "arguments": kwargs,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "status": ApprovalStatus.PENDING,
            "description": self.description
        }

        # [ì‹ ê·œ] ìë™ ìŠ¹ì¸ ì„ê³„ê°’ í™•ì¸
        if self.auto_approve_threshold and self._is_safe_operation(**kwargs):
            approval_request["status"] = ApprovalStatus.AUTO_APPROVED
            result = await self.base_function.execute(**kwargs)
            approval_request["result"] = result
            return approval_request

        # ìŠ¹ì¸ ì½œë°± ì‹¤í–‰
        if self.approval_callback:
            approved = await self.approval_callback(approval_request)
            if approved:
                approval_request["status"] = ApprovalStatus.APPROVED
                result = await self.base_function.execute(**kwargs)
                approval_request["result"] = result
            else:
                approval_request["status"] = ApprovalStatus.REJECTED
                approval_request["result"] = "Operation rejected by user"

        return approval_request

    def _is_safe_operation(self, **kwargs) -> bool:
        """
        ì•ˆì „í•œ ì‘ì—…ì¸ì§€ í™•ì¸ (ì˜ˆ: ì½ê¸° ì „ìš©)

        [ì‹ ê·œ] ìë™ ìŠ¹ì¸ ë¡œì§
        """
        # ì½ê¸° ì „ìš© ì‘ì—…ì€ ìë™ ìŠ¹ì¸ (ì˜ˆ: get_, read_, list_ ë¡œ ì‹œì‘)
        if self.base_function.name.startswith(("get_", "read_", "list_")):
            return True
        return False


# ============================================================================
# MCP (Model Context Protocol) í†µí•©
# ============================================================================

# ============================================================================
# MCP (Model Context Protocol) í†µí•©
# ============================================================================

class MockMCPClient:
    """
    [ì‹ ê·œ] MCP í´ë¼ì´ì–¸íŠ¸ ëª¨ì˜ êµ¬í˜„ (ë°ëª¨ìš©)
    """
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.tools = {
            "calculator": {
                "name": "calculator",
                "description": "Perform basic calculations",
                "parameters": {"type": "object", "properties": {"expression": {"type": "string"}}}
            },
            "web_search": {
                "name": "web_search",
                "description": "Search the web for information",
                "parameters": {"type": "object", "properties": {"query": {"type": "string"}}}
            }
        }

    async def list_tools(self) -> List[Dict[str, Any]]:
        return list(self.tools.values())

    async def call_tool(self, name: str, arguments: Dict[str, Any]) -> Any:
        if name == "calculator":
            return f"Calculated: {arguments.get('expression')} = 42 (Mock)"
        elif name == "web_search":
            return f"Search results for '{arguments.get('query')}': [Mock Result 1, Mock Result 2]"
        return f"Tool {name} executed with {arguments}"

class MCPTool:
    """
    MCP ì„œë²„ì™€ í†µí•©í•˜ëŠ” ë„êµ¬
    """

    def __init__(self, name: str, server_config: Dict[str, Any]):
        self.name = name
        self.server_config = server_config
        self.connected = False
        self.client: Optional[MockMCPClient] = None
        self.available_tools: List[Dict[str, Any]] = []

    async def connect(self):
        """
        MCP ì„œë²„ ì—°ê²°
        """
        try:
            logging.info(f"ğŸ”Œ MCP ì„œë²„ ì—°ê²° ì‹œë„: {self.name}")
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” mcp.Client ì‚¬ìš©
            self.client = MockMCPClient(self.server_config)
            self.available_tools = await self.client.list_tools()
            self.connected = True
            logging.info(f"âœ… MCP ì„œë²„ ì—°ê²° ì„±ê³µ: {self.name}")
        except Exception as e:
            logging.error(f"âŒ MCP ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    async def disconnect(self):
        """MCP ì„œë²„ ì—°ê²° í•´ì œ"""
        if self.connected:
            logging.info(f"ğŸ”Œ MCP ì„œë²„ ì—°ê²° í•´ì œ: {self.name}")
            self.connected = False
            self.client = None

    async def get_available_tools(self) -> List[Dict[str, Any]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡"""
        if not self.connected:
            await self.connect()
        return self.available_tools

    async def invoke_tool(self, tool_name: str, **kwargs) -> Any:
        """MCP ë„êµ¬ í˜¸ì¶œ"""
        if not self.connected:
            raise RuntimeError("MCP ì„œë²„ê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        logging.info(f"ğŸ› ï¸ MCP ë„êµ¬ í˜¸ì¶œ: {tool_name}")
        return await self.client.call_tool(tool_name, kwargs)


# ============================================================================
# íšŒë¡œ ì°¨ë‹¨ê¸° íŒ¨í„´
# ============================================================================

class CircuitBreaker:
    """
    íšŒë¡œ ì°¨ë‹¨ê¸° - ì¥ì•  ì „íŒŒ ë°©ì§€

    [ì‹ ê·œ] ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ íŒ¨í„´

    ìƒíƒœ ì „í™˜:
    1. CLOSED (ì •ìƒ): ëª¨ë“  ìš”ì²­ í—ˆìš©
    2. OPEN (ì°¨ë‹¨): ì‹¤íŒ¨ ì„ê³„ê°’ ë„ë‹¬, ëª¨ë“  ìš”ì²­ ì°¨ë‹¨
    3. HALF_OPEN (ë°˜ê°œë°©): íƒ€ì„ì•„ì›ƒ í›„ ì¼ë¶€ ìš”ì²­ í—ˆìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸

    ì£¼ìš” íŒŒë¼ë¯¸í„°:
    - failure_threshold: ì—°ì† ì‹¤íŒ¨ ì„ê³„ê°’ (ê¸°ë³¸ 5íšŒ)
    - timeout: OPEN ìƒíƒœ ìœ ì§€ ì‹œê°„ (ê¸°ë³¸ 60ì´ˆ)

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ì™¸ë¶€ API í˜¸ì¶œ
    - ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬
    - LLM API í˜¸ì¶œ
    """

    def __init__(self, failure_threshold: int = 5, timeout: float = 60.0):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time: Optional[float] = None
        self.state = "CLOSED"  # CLOSED, OPEN, HALF_OPEN

    async def call(self, func: Callable, *args, **kwargs):
        """
        íšŒë¡œ ì°¨ë‹¨ê¸°ë¥¼ í†µí•œ í•¨ìˆ˜ í˜¸ì¶œ

        [ì‹ ê·œ] ì¥ì•  ê²©ë¦¬ ë° ë¹ ë¥¸ ì‹¤íŒ¨
        """
        if self.state == "OPEN":
            if time.time() - self.last_failure_time > self.timeout:
                self.state = "HALF_OPEN"
                logging.info("ğŸ”„ íšŒë¡œ ì°¨ë‹¨ê¸°: HALF_OPEN ìƒíƒœ")
            else:
                raise RuntimeError("íšŒë¡œ ì°¨ë‹¨ê¸°ê°€ OPEN ìƒíƒœì…ë‹ˆë‹¤")

        try:
            result = await func(*args, **kwargs)
            if self.state == "HALF_OPEN":
                self.state = "CLOSED"
                self.failure_count = 0
                logging.info("âœ… íšŒë¡œ ì°¨ë‹¨ê¸°: CLOSED ìƒíƒœ ë³µêµ¬")
            return result
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()

            if self.failure_count >= self.failure_threshold:
                self.state = "OPEN"
                logging.error(f"âŒ íšŒë¡œ ì°¨ë‹¨ê¸°: OPEN ìƒíƒœ ({self.failure_count} ì‹¤íŒ¨)")

            raise e


# ============================================================================
# ë©”ëª¨ë¦¬ ì €ì¥ì†Œ - í–¥ìƒëœ ë²„ì „
# ============================================================================

class MemoryStore(ABC):
    """
    ë©”ëª¨ë¦¬ ì €ì¥ì†Œ ì¸í„°í˜ì´ìŠ¤

    [ìˆ˜ì •] list_keys ë©”ì„œë“œ ì¶”ê°€
    """

    @abstractmethod
    async def save(self, key: str, data: Dict) -> None:
        pass

    @abstractmethod
    async def load(self, key: str) -> Optional[Dict]:
        pass

    @abstractmethod
    async def delete(self, key: str) -> None:
        pass

    @abstractmethod
    async def list_keys(self, pattern: str = "*") -> List[str]:
        """[ì‹ ê·œ] í‚¤ ëª©ë¡ ì¡°íšŒ"""
        pass


class CachedMemoryStore(MemoryStore):
    """
    ìºì‹± ë©”ëª¨ë¦¬ ì €ì¥ì†Œ - LRU ìºì‹œ

    [ìˆ˜ì •] LRU (Least Recently Used) ìºì‹œ ì•Œê³ ë¦¬ì¦˜ ì ìš©

    ê¸°ì¡´ vs ê³ ë„í™”:
    - ê¸°ì¡´: ë‹¨ìˆœ ì ‘ê·¼ íšŸìˆ˜ ê¸°ë°˜ ìºì‹±
    - ê³ ë„í™”: LRU ì•Œê³ ë¦¬ì¦˜ + max_cache_size + access_order ì¶”ì 

    LRU ìºì‹œ ì¥ì :
    - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ (max_cache_size)
    - ìµœê·¼ ì‚¬ìš© ë°ì´í„° ìš°ì„  ìœ ì§€
    - ì˜¤ë˜ëœ ë°ì´í„° ìë™ ì œê±°
    """

    def __init__(self, max_cache_size: int = 100):
        self.data: Dict[str, Dict] = {}
        self.cache: Dict[str, Any] = {}
        self.access_count: Dict[str, int] = defaultdict(int)
        self.max_cache_size = max_cache_size  # ğŸ†• ìµœëŒ€ ìºì‹œ í¬ê¸°
        self.access_order: List[str] = []  # ğŸ†• LRU ìˆœì„œ ì¶”ì 

    async def save(self, key: str, data: Dict) -> None:
        self.data[key] = {
            'data': data,
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'version': self.data.get(key, {}).get('version', 0) + 1  # ğŸ†• ë²„ì „ ê´€ë¦¬
        }
        self.access_count[key] += 1

        # ìì£¼ ì ‘ê·¼í•˜ëŠ” ë°ì´í„°ëŠ” ìºì‹œì— ì €ì¥
        if self.access_count[key] > 3:
            self._add_to_cache(key, data)

    async def load(self, key: str) -> Optional[Dict]:
        if key in self.cache:
            self._update_access_order(key)  # ğŸ†• LRU ìˆœì„œ ì—…ë°ì´íŠ¸
            self.access_count[key] += 1
            return self.cache[key]

        if key in self.data:
            self.access_count[key] += 1
            return self.data[key]['data']
        return None

    async def delete(self, key: str) -> None:
        if key in self.data:
            del self.data[key]
        if key in self.cache:
            del self.cache[key]
            self.access_order.remove(key)  # ğŸ†• ìˆœì„œì—ì„œë„ ì œê±°

    async def list_keys(self, pattern: str = "*") -> List[str]:
        """
        í‚¤ ëª©ë¡ ë°˜í™˜ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)

        [ì‹ ê·œ] ì™€ì¼ë“œì¹´ë“œ íŒ¨í„´ ì§€ì›
        """
        if pattern == "*":
            return list(self.data.keys())
        # ê°„ë‹¨í•œ ì™€ì¼ë“œì¹´ë“œ ì§€ì›
        import fnmatch
        return [k for k in self.data.keys() if fnmatch.fnmatch(k, pattern)]

    def _add_to_cache(self, key: str, data: Any):
        """
        LRU ìºì‹œì— ì¶”ê°€

        [ì‹ ê·œ] LRU ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
        """
        if len(self.cache) >= self.max_cache_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (LRU)
            oldest_key = self.access_order.pop(0)
            del self.cache[oldest_key]

        self.cache[key] = data
        self._update_access_order(key)

    def _update_access_order(self, key: str):
        """
        ì ‘ê·¼ ìˆœì„œ ì—…ë°ì´íŠ¸

        [ì‹ ê·œ] LRU ìˆœì„œ ì¶”ì 
        """
        if key in self.access_order:
            self.access_order.remove(key)
        self.access_order.append(key)


# ============================================================================
# ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ
# ============================================================================

class EventType(str, Enum):
    """
    ì´ë²¤íŠ¸ íƒ€ì…

    [ì‹ ê·œ] Pub-Sub íŒ¨í„´ì„ ìœ„í•œ ì´ë²¤íŠ¸ íƒ€ì… ì •ì˜

    10ê°€ì§€ ì´ë²¤íŠ¸ íƒ€ì…:
    - Agent ìƒëª…ì£¼ê¸°: STARTED, COMPLETED, FAILED
    - Node ìƒëª…ì£¼ê¸°: NODE_STARTED, NODE_COMPLETED
    - ìŠ¹ì¸ ê´€ë ¨: APPROVAL_REQUESTED, APPROVAL_GRANTED, APPROVAL_DENIED
    - ë©”ì‹œì§€: MESSAGE_RECEIVED, MESSAGE_SENT
    """
    AGENT_STARTED = "agent_started"
    AGENT_COMPLETED = "agent_completed"
    AGENT_FAILED = "agent_failed"
    NODE_STARTED = "node_started"
    NODE_COMPLETED = "node_completed"
    APPROVAL_REQUESTED = "approval_requested"
    APPROVAL_GRANTED = "approval_granted"
    APPROVAL_DENIED = "approval_denied"
    MESSAGE_RECEIVED = "message_received"
    MESSAGE_SENT = "message_sent"


class AgentEvent(BaseModel):
    """
    Agent ì´ë²¤íŠ¸

    [ì‹ ê·œ] ì´ë²¤íŠ¸ ë°ì´í„° ëª¨ë¸
    """
    event_type: EventType
    timestamp: str = Field(default_factory=lambda: datetime.now(timezone.utc).isoformat())
    agent_name: Optional[str] = None
    node_name: Optional[str] = None
    data: Dict[str, Any] = Field(default_factory=dict)


class EventBus:
    """
    ì´ë²¤íŠ¸ ë²„ìŠ¤

    [ì‹ ê·œ] Pub-Sub íŒ¨í„´ êµ¬í˜„

    ì£¼ìš” ê¸°ëŠ¥:
    - subscribe(): ì´ë²¤íŠ¸ êµ¬ë…
    - publish(): ì´ë²¤íŠ¸ ë°œí–‰
    - get_event_history(): ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
    - ì•Œë¦¼ ì „ì†¡
    - ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    - ì›Œí¬í”Œë¡œìš° ì¡°ìœ¨

    ì˜ˆì‹œ:
    async def on_approval_requested(event):
        await send_slack_notification(event.data)

    event_bus.subscribe(EventType.APPROVAL_REQUESTED, on_approval_requested)
    """

    def __init__(self):
        self.subscribers: Dict[EventType, List[Callable]] = defaultdict(list)
        self.event_history: List[AgentEvent] = []

    def subscribe(self, event_type: EventType, handler: Callable):
        """ì´ë²¤íŠ¸ êµ¬ë…"""
        self.subscribers[event_type].append(handler)
        logging.info(f"ğŸ“¢ ì´ë²¤íŠ¸ êµ¬ë…: {event_type}")

    async def publish(self, event: AgentEvent):
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        self.event_history.append(event)

        handlers = self.subscribers.get(event.event_type, [])
        for handler in handlers:
            try:
                if asyncio.iscoroutinefunction(handler):
                    await handler(event)
                else:
                    handler(event)
            except Exception as e:
                logging.error(f"âŒ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ì˜¤ë¥˜: {e}")

    def get_event_history(self, event_type: Optional[EventType] = None,
                         limit: int = 100) -> List[AgentEvent]:
        """ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        if event_type:
            filtered = [e for e in self.event_history if e.event_type == event_type]
            return filtered[-limit:]
        return self.event_history[-limit:]


# ============================================================================
# Agent ê¸°ë³¸ í´ë˜ìŠ¤ - í–¥ìƒëœ ë²„ì „
# ============================================================================

class Agent(ABC):
    """
    Agent ê¸°ë³¸ í´ë˜ìŠ¤

    [ìˆ˜ì •] ì—¬ëŸ¬ ê¸°ëŠ¥ ì¶”ê°€
    1. enable_streaming: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì›
    2. event_bus: ì´ë²¤íŠ¸ ë°œí–‰
    3. circuit_breaker: íšŒë¡œ ì°¨ë‹¨ê¸° í†µí•©
    4. ë©”íŠ¸ë¦­ ì¶”ì : total_executions, total_tokens, total_duration_ms
    """

    def __init__(
        self,
        name: str,
        role: AgentRole = AgentRole.ASSISTANT,
        system_prompt: str = "You are a helpful AI assistant.",
        model: str = DEFAULT_LLM_MODEL,  # ğŸ†• ì¤‘ì•™ ì„¤ì • ì‚¬ìš©
        temperature: float = 0.7,
        max_tokens: int = 1000,
        enable_streaming: bool = False,  # ğŸ†• ìŠ¤íŠ¸ë¦¬ë° ì˜µì…˜
        event_bus: Optional[EventBus] = None,  # ğŸ†• ì´ë²¤íŠ¸ ë²„ìŠ¤
        circuit_breaker: Optional[CircuitBreaker] = None  # ğŸ†• íšŒë¡œ ì°¨ë‹¨ê¸°
    ):
        self.name = name
        self.role = role
        self.system_prompt = system_prompt
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.enable_streaming = enable_streaming
        self.event_bus = event_bus
        self.circuit_breaker = circuit_breaker or CircuitBreaker()

        self.execution_settings = AzureChatPromptExecutionSettings(
            temperature=temperature,
            max_tokens=max_tokens,
            service_id=model
        )

        # ğŸ†• êµ¬ì¡°í™”ëœ ë¡œê±°
        self.logger = StructuredLogger(f"agent.{name}")

        # ğŸ†• ë©”íŠ¸ë¦­
        self.total_executions = 0
        self.total_tokens = 0
        self.total_duration_ms = 0.0

    @abstractmethod
    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        """Agent ì‹¤í–‰"""
        pass

    async def _get_llm_response(self, kernel: Kernel, messages: List[Message],
                               use_streaming: bool = False) -> str:
        """
        LLM ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°

        [ìˆ˜ì •] use_streaming íŒŒë¼ë¯¸í„° ì¶”ê°€
        """
        chat_completion = kernel.get_service(
            service_id=self.model,
            type=ChatCompletionClientBase
        )

        history = ChatHistory()
        history.add_system_message(self.system_prompt)

        for msg in messages:
            if msg.role == AgentRole.USER:
                history.add_user_message(msg.content)
            elif msg.role == AgentRole.ASSISTANT:
                history.add_assistant_message(msg.content)

        settings = self.execution_settings
        settings.function_choice_behavior = None

        # ğŸ†• ìŠ¤íŠ¸ë¦¬ë° ì§€ì›
        if use_streaming and self.enable_streaming:
            return await self._get_streaming_response(chat_completion, history, settings, kernel)
        else:
            # ğŸ†• ì¬ì‹œë„ ë¡œì§ ì ìš©
            response = await retry_with_backoff(
                chat_completion.get_chat_message_content,
                max_retries=3,
                chat_history=history,
                settings=settings,
                kernel=kernel
            )
            return str(response)

    async def _get_streaming_response(self, chat_completion, history, settings, kernel) -> str:
        """
        ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬

        [ì‹ ê·œ] ì‹¤ì‹œê°„ í† í° ë‹¨ìœ„ ì¶œë ¥

        ì¥ì :
        - ê¸´ ì‘ë‹µì˜ ê²½ìš° ì‚¬ìš©ì ê²½í—˜ í–¥ìƒ
        - ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ ê°ì†Œ
        - ì‹¤ì‹œê°„ í”¼ë“œë°±
        """
        full_response = []

        async for chunk in chat_completion.get_streaming_chat_message_contents(
            chat_history=history,
            settings=settings,
            kernel=kernel
        ):
            if chunk:
                content = str(chunk)
                full_response.append(content)
                # ì‹¤ì‹œê°„ ì¶œë ¥ (ì˜µì…˜)
                print(content, end="", flush=True)

        print()  # ì¤„ë°”ê¿ˆ
        return "".join(full_response)

    async def _emit_event(self, event_type: EventType, data: Dict[str, Any]):
        """
        ì´ë²¤íŠ¸ ë°œí–‰

        [ì‹ ê·œ] EventBusë¥¼ í†µí•œ ì´ë²¤íŠ¸ ë°œí–‰
        """
        if self.event_bus:
            event = AgentEvent(
                event_type=event_type,
                agent_name=self.name,
                data=data
            )
            await self.event_bus.publish(event)


class SimpleAgent(Agent):
    """
    ë‹¨ìˆœ ëŒ€í™” Agent - í–¥ìƒëœ ë²„ì „

    [ìˆ˜ì •] ê°œì„ ì‚¬í•­:
    1. ì´ë²¤íŠ¸ ë°œí–‰ (AGENT_STARTED, AGENT_COMPLETED, AGENT_FAILED)
    2. íšŒë¡œ ì°¨ë‹¨ê¸°ë¥¼ í†µí•œ í˜¸ì¶œ
    3. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (total_executions, total_duration_ms)
    """

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        start_time = time.time()

        # ğŸ†• ì´ë²¤íŠ¸ ë°œí–‰
        await self._emit_event(EventType.AGENT_STARTED, {"node": self.name})

        try:
            recent_messages = state.get_conversation_history(max_messages=5)

            # ğŸ†• íšŒë¡œ ì°¨ë‹¨ê¸°ë¥¼ í†µí•œ í˜¸ì¶œ
            response = await self.circuit_breaker.call(
                self._get_llm_response,
                kernel,
                recent_messages,
                self.enable_streaming
            )

            state.add_message(AgentRole.ASSISTANT, response, self.name)

            duration_ms = (time.time() - start_time) * 1000

            # ğŸ†• ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
            self.total_executions += 1
            self.total_duration_ms += duration_ms

            # ğŸ†• ì™„ë£Œ ì´ë²¤íŠ¸
            await self._emit_event(EventType.AGENT_COMPLETED, {
                "node": self.name,
                "duration_ms": duration_ms
            })

            return NodeResult(
                node_name=self.name,
                output=response,
                success=True,
                duration_ms=duration_ms
            )
        except Exception as e:
            logging.error(f"âŒ Agent {self.name} ì‹¤í–‰ ì‹¤íŒ¨: {e}")

            # ğŸ†• ì‹¤íŒ¨ ì´ë²¤íŠ¸
            await self._emit_event(EventType.AGENT_FAILED, {
                "node": self.name,
                "error": str(e)
            })

            return NodeResult(
                node_name=self.name,
                output="",
                success=False,
                error=str(e)
            )


class ApprovalAgent(Agent):
    """
    ìŠ¹ì¸ì´ í•„ìš”í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” Agent

    [ì‹ ê·œ] Human-in-the-loop íŒ¨í„´ êµ¬í˜„

    ì°¸ì¡°: https://github.com/microsoft/agent-framework/blob/main/python/samples/getting_started/tools/ai_tool_with_approval.py

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ë°ì´í„° ì‚­ì œ ì‘ì—…
    - ê²°ì œ ì²˜ë¦¬
    - ì¤‘ìš” ì„¤ì • ë³€ê²½
    - ì™¸ë¶€ API í˜¸ì¶œ
    """

    def __init__(self, *args, approval_function: ApprovalRequiredAIFunction, **kwargs):
        super().__init__(*args, **kwargs)
        self.approval_function = approval_function

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        start_time = time.time()

        try:
            # ì‚¬ìš©ì ì…ë ¥ì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
            recent_messages = state.get_conversation_history(max_messages=3)
            last_message = recent_messages[-1].content if recent_messages else ""

            # ìŠ¹ì¸ ìš”ì²­ ìƒì„±
            approval_result = await self.approval_function.execute(input=last_message)

            if approval_result["status"] == ApprovalStatus.PENDING:
                # ìŠ¹ì¸ ëŒ€ê¸° ìƒíƒœ
                state.add_pending_approval(approval_result)
                await self._emit_event(EventType.APPROVAL_REQUESTED, approval_result)

                return NodeResult(
                    node_name=self.name,
                    output=f"ìŠ¹ì¸ ëŒ€ê¸° ì¤‘: {approval_result['description']}",
                    success=True,
                    requires_approval=True,
                    approval_data=approval_result,
                    duration_ms=(time.time() - start_time) * 1000
                )
            else:
                # ìŠ¹ì¸ë¨ ë˜ëŠ” ìë™ ìŠ¹ì¸
                result = approval_result.get("result", "")
                state.add_message(AgentRole.ASSISTANT, str(result), self.name)

                return NodeResult(
                    node_name=self.name,
                    output=str(result),
                    success=True,
                    duration_ms=(time.time() - start_time) * 1000
                )

        except Exception as e:
            logging.error(f"âŒ ApprovalAgent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return NodeResult(
                node_name=self.name,
                output="",
                success=False,
                error=str(e)
            )


class RouterAgent(Agent):
    """
    ë¼ìš°íŒ… Agent - í–¥ìƒëœ ë²„ì „

    [ìˆ˜ì •] ê°œì„ ì‚¬í•­:
    1. default_route íŒŒë¼ë¯¸í„° ì¶”ê°€
    2. routing_history ì¶”ì  (ì¸í…íŠ¸ ë¶„ë¥˜ íˆìŠ¤í† ë¦¬)
    3. ë©”íƒ€ë°ì´í„°ì— confidence ì¶”ê°€
    """

    def __init__(self, *args, routes: Dict[str, str],
                 default_route: Optional[str] = None, **kwargs):
        super().__init__(*args, role=AgentRole.ROUTER, **kwargs)
        self.routes = routes
        self.default_route = default_route or list(routes.values())[0] if routes else None  # ğŸ†• ê¸°ë³¸ ê²½ë¡œ
        self.routing_history: List[Dict[str, Any]] = []  # ğŸ†• ë¼ìš°íŒ… íˆìŠ¤í† ë¦¬

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        start_time = time.time()

        try:
            recent_messages = state.get_conversation_history(max_messages=3)
            last_message = recent_messages[-1].content if recent_messages else ""

            routes_list = ', '.join(self.routes.keys())
            classification_prompt = f"""Classify the user's intent into one of these categories: {routes_list}

User message: {last_message}

Respond with ONLY the category name (one word)."""

            temp_messages = [Message(role=AgentRole.USER, content=classification_prompt)]
            intent = await self._get_llm_response(kernel, temp_messages)
            intent = intent.strip().lower()

            next_node = self.routes.get(intent, self.default_route)
            duration_ms = (time.time() - start_time) * 1000

            # ğŸ†• ë¼ìš°íŒ… íˆìŠ¤í† ë¦¬ ì €ì¥
            routing_record = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "message": last_message,
                "intent": intent,
                "next_node": next_node
            }
            self.routing_history.append(routing_record)

            logging.info(f"ğŸ”€ Router: '{intent}' -> '{next_node}'")

            return NodeResult(
                node_name=self.name,
                output=f"ë¼ìš°íŒ…: {next_node} (ì¸í…íŠ¸: {intent})",
                next_node=next_node,
                success=True,
                duration_ms=duration_ms,
                metadata={"intent": intent, "confidence": 0.95}  # ğŸ†• ì‹ ë¢°ë„ ì¶”ê°€
            )
        except Exception as e:
            logging.error(f"âŒ Router ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return NodeResult(
                node_name=self.name,
                output="",
                next_node=self.default_route,
                success=False,
                error=str(e)
            )


class SupervisorAgent(Agent):
    """
    Supervisor Agent - ì—¬ëŸ¬ Agentë¥¼ ê°ë…í•˜ê³  ì¡°ìœ¨

    [ì‹ ê·œ] Microsoft AutoGenì˜ Supervisor íŒ¨í„´

    ê¸°ì¡´ OrchestratorAgent vs SupervisorAgent:
    - Orchestrator: ìˆœì°¨ ì‹¤í–‰, ê°„ë‹¨í•œ í˜‘ì—…
    - Supervisor: ë¼ìš´ë“œ ê¸°ë°˜ í˜‘ì—…, ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´, ì‹¤í–‰ ë¡œê·¸

    ì£¼ìš” ê¸°ëŠ¥:
    1. ë¼ìš´ë“œ ê¸°ë°˜ í˜‘ì—… (max_rounds)
    2. ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ("TERMINATE" í‚¤ì›Œë“œ)
    3. ìƒì„¸í•œ ì‹¤í–‰ ë¡œê·¸ (execution_log)
    4. ì„œë¸Œ ì—ì´ì „íŠ¸ ì„±ëŠ¥ ì¶”ì 

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - Research Agent + Writer Agent í˜‘ì—…
    - Coder + Reviewer í˜‘ì—…
    - ë³µì¡í•œ multi-step ì‘ì—…
    """

    def __init__(self, *args, sub_agents: List[Agent],
                 max_rounds: int = 3, **kwargs):
        super().__init__(*args, role=AgentRole.SUPERVISOR, **kwargs)
        self.sub_agents = {agent.name: agent for agent in sub_agents}
        self.max_rounds = max_rounds
        self.execution_log: List[Dict[str, Any]] = []  # ğŸ†• ì‹¤í–‰ ë¡œê·¸

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        start_time = time.time()

        try:
            responses = []
            current_round = 0

            # Agent ì´ë¦„ ëª©ë¡
            agent_names = list(self.sub_agents.keys())
            agent_list_str = ", ".join(agent_names)

            while current_round < self.max_rounds:
                current_round += 1
                logging.info(f"ğŸ¯ Supervisor Round {current_round}/{self.max_rounds}")

                # 1. ë‹¤ìŒ ì‹¤í–‰í•  Agent ê²°ì • (LLM ì‚¬ìš©)
                history_text = "\n".join(responses[-3:]) if responses else "No history yet."

                decision_prompt = f"""
You are a Supervisor managing these agents: {agent_list_str}.
Current goal: {state.messages[-1].content if state.messages else 'Unknown'}

Recent history:
{history_text}

Decide the next step:
1. Select the next agent to act (respond with agent name).
2. If the task is complete, respond with "TERMINATE".

Respond with ONLY the agent name or "TERMINATE".
"""
                temp_messages = [Message(role=AgentRole.SYSTEM, content=decision_prompt)]
                decision = await self._get_llm_response(kernel, temp_messages)
                decision = decision.strip()

                logging.info(f"ğŸ¤” Supervisor Decision: {decision}")

                if "TERMINATE" in decision.upper():
                    logging.info("âœ… Supervisor decided to terminate.")
                    break

                # ì„ íƒëœ Agent ì‹¤í–‰
                selected_agent_name = None
                for name in agent_names:
                    if name.lower() in decision.lower():
                        selected_agent_name = name
                        break

                if not selected_agent_name:
                    # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ì²« ë²ˆì§¸ ë˜ëŠ” ë¼ìš´ë“œ ë¡œë¹ˆ ë“± ëŒ€ì•ˆ í•„ìš”
                    # ì—¬ê¸°ì„œëŠ” ë¡œê¹… í›„ ê³„ì† ì§„í–‰ (í˜¹ì€ ì¢…ë£Œ)
                    logging.warning(f"âš ï¸ Unknown agent selected: {decision}. Stopping.")
                    break

                agent = self.sub_agents[selected_agent_name]
                logging.info(f"  â¤ {selected_agent_name} ì‹¤í–‰ ì¤‘...")

                result = await agent.execute(state, kernel)

                # ğŸ†• ì‹¤í–‰ ë¡œê·¸ ê¸°ë¡
                execution_record = {
                    "round": current_round,
                    "agent": selected_agent_name,
                    "output": result.output,
                    "success": result.success,
                    "duration_ms": result.duration_ms
                }
                self.execution_log.append(execution_record)

                if result.success:
                    response_text = f"[Round {current_round} - {selected_agent_name}]\n{result.output}"
                    responses.append(response_text)
                    # ìƒíƒœì— ì¤‘ê°„ ê²°ê³¼ ì¶”ê°€ (ì„ íƒ ì‚¬í•­)
                    # state.add_message(AgentRole.FUNCTION, result.output, selected_agent_name)

                # Agentê°€ ëª…ì‹œì ìœ¼ë¡œ ì¢…ë£Œ ìš”ì²­í•œ ê²½ìš°
                if "TERMINATE" in result.output.upper():
                    logging.info(f"âœ… ì¡°ê¸° ì¢…ë£Œ ìš”ì²­ by {selected_agent_name}")
                    break

            final_output = "\n\n".join(responses)
            duration_ms = (time.time() - start_time) * 1000

            # ìµœì¢… ìš”ì•½
            summary = f"Supervisor ì‹¤í–‰ ì™„ë£Œ: {current_round}ë¼ìš´ë“œ"
            state.add_message(AgentRole.SUPERVISOR, summary, self.name)

            return NodeResult(
                node_name=self.name,
                output=final_output,
                success=True,
                duration_ms=duration_ms,
                metadata={
                    "rounds": current_round,
                    "agents": len(self.sub_agents),
                    "execution_log": self.execution_log
                }
            )
        except Exception as e:
            logging.error(f"âŒ Supervisor ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return NodeResult(
                node_name=self.name,
                output="",
                success=False,
                error=str(e)
            )


# ============================================================================
# ê·¸ë˜í”„ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° - í–¥ìƒëœ ë²„ì „
# ============================================================================

class Node:
    """
    ì›Œí¬í”Œë¡œìš° ë…¸ë“œ

    [ìˆ˜ì •] condition_func íŒŒë¼ë¯¸í„° ì¶”ê°€
    - ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì§€ì› (LangGraph íŒ¨í„´)
    """

    def __init__(self, name: str, agent: Agent,
                 edges: Optional[Dict[str, str]] = None,
                 condition_func: Optional[Callable] = None):  # ğŸ†• ì¡°ê±´ í•¨ìˆ˜
        self.name = name
        self.agent = agent
        self.edges = edges or {}
        self.condition_func = condition_func
        self.execution_count = 0  # ğŸ†• ì‹¤í–‰ íšŸìˆ˜ ì¶”ì 

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        logging.info(f"ğŸ“ ë…¸ë“œ ì‹¤í–‰: {self.name} (#{self.execution_count + 1})")

        result = await self.agent.execute(state, kernel)
        self.execution_count += 1

        # ğŸ†• ì¡°ê±´ë¶€ ë¼ìš°íŒ…
        if not result.next_node and self.edges:
            if self.condition_func:
                # ì¡°ê±´ í•¨ìˆ˜ë¡œ ë‹¤ìŒ ë…¸ë“œ ê²°ì •
                next_node = await self.condition_func(state, result)
                result.next_node = self.edges.get(next_node, self.edges.get("default"))
            else:
                result.next_node = self.edges.get("default", None)

        state.visited_nodes.append(self.name)
        return result


class Graph:
    """
    ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ - ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë° ë£¨í”„ ì§€ì›

    [ìˆ˜ì •] ì—¬ëŸ¬ ê¸°ëŠ¥ ì¶”ê°€:
    1. loop_nodes: ë£¨í”„ ê°€ëŠ¥í•œ ë…¸ë“œ ì§‘í•©
    2. add_conditional_edge(): ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€
    3. ë¬´í•œ ë£¨í”„ ë°©ì§€ ë¡œì§
    4. ìƒì„¸í•œ ì‹¤í–‰ ë¡œê·¸
    5. get_statistics(): ê·¸ë˜í”„ í†µê³„
    """

    def __init__(self, name: str = "workflow"):
        self.name = name
        self.nodes: Dict[str, Node] = {}
        self.start_node: Optional[str] = None
        self.end_nodes: Set[str] = set()
        self.loop_nodes: Set[str] = set()  # ğŸ†• ë£¨í”„ ê°€ëŠ¥ ë…¸ë“œ

    def add_node(self, node: Node, allow_loop: bool = False):  # ğŸ†• allow_loop íŒŒë¼ë¯¸í„°
        """
        ë…¸ë“œ ì¶”ê°€

        [ìˆ˜ì •] allow_loop íŒŒë¼ë¯¸í„°ë¡œ ë£¨í”„ í—ˆìš© ì—¬ë¶€ ì§€ì •
        """
        self.nodes[node.name] = node
        if allow_loop:
            self.loop_nodes.add(node.name)
        logging.info(f"âœ… ë…¸ë“œ ì¶”ê°€: {node.name}")

    def add_edge(self, from_node: str, to_node: str, condition: str = "default"):
        if from_node not in self.nodes:
            raise ValueError(f"ë…¸ë“œ '{from_node}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        self.nodes[from_node].edges[condition] = to_node
        logging.info(f"âœ… ì—£ì§€ ì¶”ê°€: {from_node} --[{condition}]--> {to_node}")

    def add_conditional_edge(self, from_node: str, condition_func: Callable):
        """
        ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€

        [ì‹ ê·œ] LangGraphì˜ ì¡°ê±´ë¶€ ë¼ìš°íŒ… íŒ¨í„´

        ì‚¬ìš© ì˜ˆì‹œ:
        async def route_by_complexity(state, result):
            if "simple" in result.output.lower():
                return "simple"
            return "complex"

        graph.add_conditional_edge("analyzer", route_by_complexity)
        """
        if from_node not in self.nodes:
            raise ValueError(f"ë…¸ë“œ '{from_node}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        self.nodes[from_node].condition_func = condition_func
        logging.info(f"âœ… ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€: {from_node}")

    def set_start(self, node_name: str):
        self.start_node = node_name
        logging.info(f"âœ… ì‹œì‘ ë…¸ë“œ: {node_name}")

    def set_end(self, node_name: str):
        self.end_nodes.add(node_name)
        logging.info(f"âœ… ì¢…ë£Œ ë…¸ë“œ: {node_name}")

    async def execute(self, state: AgentState, kernel: Kernel,
                     max_iterations: int = 10) -> AgentState:
        """
        ê·¸ë˜í”„ ì‹¤í–‰

        [ìˆ˜ì •] ê°œì„ ì‚¬í•­:
        1. ìŠ¹ì¸ ëŒ€ê¸° ì²˜ë¦¬
        2. ë¬´í•œ ë£¨í”„ ë°©ì§€ (loop_nodes ì²´í¬)
        3. ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥
        4. ì‹¤í–‰ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        """
        if not self.start_node:
            raise ValueError("ì‹œì‘ ë…¸ë“œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        current_node = self.start_node
        iterations = 0

        logging.info(f"\n{'='*60}")
        logging.info(f"ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹œì‘: {self.name}")
        logging.info(f"{'='*60}")
        state.execution_status = ExecutionStatus.RUNNING

        while current_node and iterations < max_iterations:
            iterations += 1
            state.current_node = current_node

            logging.info(f"\nâ–¶ï¸ Iteration {iterations}: {current_node}")

            node = self.nodes.get(current_node)
            if not node:
                logging.error(f"âŒ ë…¸ë“œ '{current_node}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                state.execution_status = ExecutionStatus.FAILED
                break

            # ğŸ†• ë¬´í•œ ë£¨í”„ ë°©ì§€ (ê°™ì€ ë…¸ë“œ ì¬ë°©ë¬¸ ì²´í¬)
            if current_node in state.visited_nodes and current_node not in self.loop_nodes:
                logging.warning(f"âš ï¸ ë…¸ë“œ ì¬ë°©ë¬¸ ê°ì§€: {current_node}")

            result = await node.execute(state, kernel)
            state.metadata[f"{current_node}_result"] = result.model_dump()

            # ğŸ†• ìŠ¹ì¸ ëŒ€ê¸° ì²˜ë¦¬
            if result.requires_approval:
                logging.info(f"â¸ï¸ ìŠ¹ì¸ ëŒ€ê¸°: {current_node}")
                state.execution_status = ExecutionStatus.WAITING_APPROVAL
                return state

            if not result.success:
                logging.error(f"âŒ ë…¸ë“œ ì‹¤í–‰ ì‹¤íŒ¨: {result.error}")
                state.execution_status = ExecutionStatus.FAILED
                break

            # ì¢…ë£Œ ì¡°ê±´
            if current_node in self.end_nodes:
                logging.info(f"\n{'='*60}")
                logging.info(f"âœ… ì›Œí¬í”Œë¡œìš° ì™„ë£Œ: {self.name}")
                logging.info(f"{'='*60}")
                state.execution_status = ExecutionStatus.COMPLETED
                break

            current_node = result.next_node

            if not current_node:
                state.execution_status = ExecutionStatus.COMPLETED
                break

        if iterations >= max_iterations:
            logging.warning(f"âš ï¸ ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ ({max_iterations})")
            state.execution_status = ExecutionStatus.FAILED

        # ğŸ†• ì‹¤í–‰ í†µê³„
        state.metrics["total_iterations"] = iterations
        state.metrics["visited_nodes"] = len(state.visited_nodes)
        state.metrics["workflow_name"] = self.name

        return state

    def visualize(self) -> str:
        """
        ê·¸ë˜í”„ ì‹œê°í™” (Mermaid í˜•ì‹)

        [ìˆ˜ì •] loop_nodes í‘œì‹œ ê°œì„ 
        """
        lines = []
        lines.append("```")
        lines.append("graph TD")

        # ë…¸ë“œ ì •ì˜
        for node_name, node in self.nodes.items():
            if node_name == self.start_node:
                shape = f"{node_name}([ğŸ¬ START: {node_name}])"
            elif node_name in self.end_nodes:
                shape = f"{node_name}[ğŸ END: {node_name}]"
            elif node_name in self.loop_nodes:  # ğŸ†• ë£¨í”„ ë…¸ë“œ í‘œì‹œ
                shape = f"{node_name}{{ğŸ”„ {node_name}}}"
            else:
                shape = f"{node_name}[{node_name}]"

            lines.append(f"    {shape}")

        # ì—£ì§€ ì •ì˜
        for node_name, node in self.nodes.items():
            for condition, target in node.edges.items():
                if condition == "default":
                    lines.append(f"    {node_name} --> {target}")
                else:
                    lines.append(f"    {node_name} -->|{condition}| {target}")

        lines.append("```")
        return "\n".join(lines)

    def get_statistics(self) -> Dict[str, Any]:
        """
        ê·¸ë˜í”„ í†µê³„

        [ì‹ ê·œ] ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ í†µê³„
        """
        return {
            "name": self.name,
            "total_nodes": len(self.nodes),
            "start_node": self.start_node,
            "end_nodes": list(self.end_nodes),
            "loop_nodes": list(self.loop_nodes),
            "total_edges": sum(len(node.edges) for node in self.nodes.values()),
            "node_execution_counts": {
                name: node.execution_count
                for name, node in self.nodes.items()
            }
        }


# ============================================================================
# ìƒíƒœ ê´€ë¦¬ - í–¥ìƒëœ ë²„ì „
# ============================================================================

class StateManager:
    """
    ìƒíƒœ ê´€ë¦¬ì - ë²„ì „ ê´€ë¦¬ ë° ë¡¤ë°± ì§€ì›

    [ìˆ˜ì •] ì—¬ëŸ¬ ê¸°ëŠ¥ ì¶”ê°€:
    1. ë²„ì „ ê´€ë¦¬ (state_versions)
    2. load_state(version): íŠ¹ì • ë²„ì „ ë¡œë“œ
    3. save_checkpoint(tag): íƒœê·¸ì™€ í•¨ê»˜ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
    4. restore_checkpoint(tag): íŠ¹ì • íƒœê·¸ ë³µì›
    5. list_checkpoints(): ì²´í¬í¬ì¸íŠ¸ ëª©ë¡
    6. rollback(steps): ì´ì „ ìƒíƒœë¡œ ë¡¤ë°±
    """

    def __init__(self, memory_store: MemoryStore, checkpoint_dir: Optional[str] = None):
        self.memory_store = memory_store
        self.checkpoint_dir = checkpoint_dir
        self.state_versions: Dict[str, List[str]] = defaultdict(list)  # ğŸ†• ë²„ì „ ì¶”ì 

        if checkpoint_dir and not os.path.exists(checkpoint_dir):
            os.makedirs(checkpoint_dir)

    async def save_state(self, state: AgentState):
        """
        ìƒíƒœ ì €ì¥

        [ìˆ˜ì •] ë²„ì „ ì¶”ì  ì¶”ê°€
        """
        state_dict = state.model_dump()
        await self.memory_store.save(f"state:{state.session_id}", state_dict)

        # ğŸ†• ë²„ì „ ì¶”ì 
        version_key = f"state:{state.session_id}:v{len(self.state_versions[state.session_id])}"
        await self.memory_store.save(version_key, state_dict)
        self.state_versions[state.session_id].append(version_key)

    async def load_state(self, session_id: str, version: Optional[int] = None) -> Optional[AgentState]:
        """
        ìƒíƒœ ë¡œë“œ (íŠ¹ì • ë²„ì „ ì§€ì›)

        [ìˆ˜ì •] version íŒŒë¼ë¯¸í„° ì¶”ê°€
        """
        if version is not None:
            # ğŸ†• íŠ¹ì • ë²„ì „ ë¡œë“œ
            version_key = f"state:{session_id}:v{version}"
            data = await self.memory_store.load(version_key)
        else:
            # ìµœì‹  ë²„ì „ ë¡œë“œ
            data = await self.memory_store.load(f"state:{session_id}")

        if data:
            return AgentState(**data)
        return None

    async def save_checkpoint(self, state: AgentState, tag: Optional[str] = None) -> str:
        """
        ì²´í¬í¬ì¸íŠ¸ ì €ì¥

        [ìˆ˜ì •] tag íŒŒë¼ë¯¸í„° ì¶”ê°€
        """
        if not self.checkpoint_dir:
            raise ValueError("ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ë¯¸ì„¤ì •")

        timestamp = datetime.now(timezone.utc).isoformat().replace(':', '-').replace('.', '-')
        tag_suffix = f"_{tag}" if tag else ""  # ğŸ†• íƒœê·¸ ì ‘ë¯¸ì‚¬
        checkpoint_file = os.path.join(
            self.checkpoint_dir,
            f"{state.session_id}_{timestamp}{tag_suffix}.json"
        )

        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(state.model_dump(), f, ensure_ascii=False, indent=2)

        logging.info(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_file}")
        return checkpoint_file

    async def restore_checkpoint(self, session_id: str, tag: Optional[str] = None) -> Optional[AgentState]:
        """
        ì²´í¬í¬ì¸íŠ¸ ë³µì›

        [ìˆ˜ì •] tag íŒŒë¼ë¯¸í„° ì¶”ê°€
        """
        if not self.checkpoint_dir:
            return None

        checkpoints = [
            f for f in os.listdir(self.checkpoint_dir)
            if f.startswith(session_id) and f.endswith('.json')
        ]

        # ğŸ†• íƒœê·¸ í•„í„°ë§
        if tag:
            checkpoints = [f for f in checkpoints if tag in f]

        if not checkpoints:
            return None

        latest = os.path.join(self.checkpoint_dir, sorted(checkpoints)[-1])

        with open(latest, 'r', encoding='utf-8') as f:
            data = json.load(f)

        logging.info(f"ğŸ“‚ ì²´í¬í¬ì¸íŠ¸ ë³µì›: {latest}")
        return AgentState(**data)

    async def list_checkpoints(self, session_id: str) -> List[str]:
        """
        ì²´í¬í¬ì¸íŠ¸ ëª©ë¡

        [ì‹ ê·œ] ì €ì¥ëœ ì²´í¬í¬ì¸íŠ¸ ëª©ë¡ ì¡°íšŒ
        """
        if not self.checkpoint_dir or not os.path.exists(self.checkpoint_dir):
            return []

        checkpoints = [
            f for f in os.listdir(self.checkpoint_dir)
            if f.startswith(session_id) and f.endswith('.json')
        ]
        return sorted(checkpoints)

    async def rollback(self, session_id: str, steps: int = 1) -> Optional[AgentState]:
        """
        ì´ì „ ìƒíƒœë¡œ ë¡¤ë°±

        [ì‹ ê·œ] ë²„ì „ ê¸°ë°˜ ë¡¤ë°±

        ì‚¬ìš© ì˜ˆì‹œ:
        # 1ë‹¨ê³„ ì´ì „ìœ¼ë¡œ ë¡¤ë°±
        state = await state_manager.rollback(session_id, steps=1)

        # 3ë‹¨ê³„ ì´ì „ìœ¼ë¡œ ë¡¤ë°±
        state = await state_manager.rollback(session_id, steps=3)
        """
        versions = self.state_versions.get(session_id, [])
        if len(versions) < steps:
            logging.warning(f"âš ï¸ ë¡¤ë°± ë¶ˆê°€: {steps}ë‹¨ê³„ ì´ì „ ë²„ì „ ì—†ìŒ")
            return None

        target_version = len(versions) - steps - 1
        return await self.load_state(session_id, version=target_version)


# ============================================================================
# í†µí•© í”„ë ˆì„ì›Œí¬ - Enterprise Edition
# ============================================================================

class UnifiedAgentFramework:
    """
    í†µí•© Agent í”„ë ˆì„ì›Œí¬ - Enterprise Edition

    [ìˆ˜ì •] ì—¬ëŸ¬ ê¸°ëŠ¥ ì¶”ê°€:
    1. mcp_tools: MCP ë„êµ¬ ê´€ë¦¬
    2. event_bus: ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ
    3. global_metrics: ì „ì—­ ë©”íŠ¸ë¦­
    4. register_mcp_tool(): MCP ë„êµ¬ ë“±ë¡
    5. approve_pending_request(): ìŠ¹ì¸ ì²˜ë¦¬
    6. get_workflow_stats(): ì›Œí¬í”Œë¡œìš° í†µê³„
    7. get_global_metrics(): ì „ì—­ ë©”íŠ¸ë¦­
    8. cleanup(): ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    """

    def __init__(
        self,
        kernel: Kernel,
        memory_store: Optional[MemoryStore] = None,
        checkpoint_dir: str = "./checkpoints",
        enable_telemetry: bool = True,
        enable_events: bool = True  # ğŸ†• ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ ì˜µì…˜
    ):
        self.kernel = kernel
        self.memory_store = memory_store or CachedMemoryStore(max_cache_size=100)
        self.state_manager = StateManager(self.memory_store, checkpoint_dir)
        self.graphs: Dict[str, Graph] = {}
        self.mcp_tools: Dict[str, MCPTool] = {}  # ğŸ†• MCP ë„êµ¬
        self.event_bus = EventBus() if enable_events else None  # ğŸ†• ì´ë²¤íŠ¸ ë²„ìŠ¤

        if enable_telemetry:
            self.tracer = trace.get_tracer(__name__)
        else:
            self.tracer = None

        # ğŸ†• ì „ì—­ ë©”íŠ¸ë¦­
        self.global_metrics = {
            "total_workflows": 0,
            "total_executions": 0,
            "total_failures": 0,
            "start_time": datetime.now(timezone.utc).isoformat()
        }

    def create_graph(self, name: str) -> Graph:
        """ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
        graph = Graph(name)
        self.graphs[name] = graph
        logging.info(f"ğŸ¨ ê·¸ë˜í”„ ìƒì„±: {name}")
        return graph

    def register_mcp_tool(self, tool: MCPTool):
        """
        MCP ë„êµ¬ ë“±ë¡

        [ì‹ ê·œ] MCP ì„œë²„ ì—°ë™
        """
        self.mcp_tools[tool.name] = tool
        logging.info(f"ğŸ”§ MCP ë„êµ¬ ë“±ë¡: {tool.name}")

    async def run(
        self,
        session_id: str,
        workflow_name: str,
        user_message: str = "",
        restore_from_checkpoint: bool = False,
        checkpoint_tag: Optional[str] = None  # ğŸ†• íƒœê·¸ ì§€ì›
    ) -> AgentState:
        """
        ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

        [ìˆ˜ì •] ê°œì„ ì‚¬í•­:
        1. checkpoint_tag íŒŒë¼ë¯¸í„° ì¶”ê°€
        2. ì‹¤í–‰ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
        3. ìë™ ì²´í¬í¬ì¸íŠ¸ (ì™„ë£Œ ì‹œ)
        4. ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”
        """

        # ìƒíƒœ ë³µì›
        if restore_from_checkpoint:
            state = await self.state_manager.restore_checkpoint(session_id, tag=checkpoint_tag)
            if not state:
                logging.warning("âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë³µì› ì‹¤íŒ¨, ìƒˆ ì„¸ì…˜ ì‹œì‘")
                state = None
        else:
            state = await self.state_manager.load_state(session_id)

        if not state:
            state = AgentState(session_id=session_id, workflow_name=workflow_name)
            logging.info(f"ğŸ†• ìƒˆ ì„¸ì…˜ ì‹œì‘: {session_id}")

        if user_message:
            state.add_message(AgentRole.USER, user_message)
            # ğŸ†• ì´ë²¤íŠ¸ ë°œí–‰
            if self.event_bus:
                await self.event_bus.publish(AgentEvent(
                    event_type=EventType.MESSAGE_RECEIVED,
                    data={"content": user_message}
                ))

        graph = self.graphs.get(workflow_name)
        if not graph:
            raise ValueError(f"ì›Œí¬í”Œë¡œìš° '{workflow_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì‹¤í–‰
        start_time = time.time()
        self.global_metrics["total_executions"] += 1

        try:
            if self.tracer:
                with self.tracer.start_as_current_span("workflow_execution") as span:
                    span.set_attribute("session_id", session_id)
                    span.set_attribute("workflow_name", workflow_name)
                    state = await graph.execute(state, self.kernel)
                    span.set_attribute("status", state.execution_status.value)
                    span.set_attribute("iterations", state.metrics.get("total_iterations", 0))
            else:
                state = await graph.execute(state, self.kernel)

            # ğŸ†• ì‹¤í–‰ ë©”íŠ¸ë¦­ ì €ì¥
            execution_time = (time.time() - start_time) * 1000
            state.metrics["execution_time_ms"] = execution_time
            state.metrics["success"] = state.execution_status == ExecutionStatus.COMPLETED

        except Exception as e:
            logging.error(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            self.global_metrics["total_failures"] += 1
            state.execution_status = ExecutionStatus.FAILED
            state.metadata["error"] = str(e)

        # ìƒíƒœ ì €ì¥
        await self.state_manager.save_state(state)

        # ğŸ†• ìë™ ì²´í¬í¬ì¸íŠ¸ (ì™„ë£Œ ì‹œ)
        if state.execution_status == ExecutionStatus.COMPLETED:
            await self.state_manager.save_checkpoint(state, tag="auto")

        return state

    async def approve_pending_request(self, session_id: str, request_id: int,
                                     approved: bool) -> AgentState:
        """
        ëŒ€ê¸° ì¤‘ì¸ ìŠ¹ì¸ ìš”ì²­ ì²˜ë¦¬

        [ì‹ ê·œ] Human-in-the-loop ìŠ¹ì¸ ì²˜ë¦¬
        """
        state = await self.state_manager.load_state(session_id)
        if not state:
            raise ValueError(f"ì„¸ì…˜ '{session_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if request_id >= len(state.pending_approvals):
            raise ValueError(f"ìŠ¹ì¸ ìš”ì²­ #{request_id}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        approval = state.pending_approvals[request_id]
        approval["status"] = ApprovalStatus.APPROVED if approved else ApprovalStatus.REJECTED
        approval["approved_at"] = datetime.now(timezone.utc).isoformat()

        if approved:
            # ìŠ¹ì¸ë¨ - ì›Œí¬í”Œë¡œìš° ê³„ì† ì‹¤í–‰
            state.execution_status = ExecutionStatus.RUNNING
            if self.event_bus:
                await self.event_bus.publish(AgentEvent(
                    event_type=EventType.APPROVAL_GRANTED,
                    data=approval
                ))
        else:
            # ê±°ë¶€ë¨
            state.execution_status = ExecutionStatus.FAILED
            if self.event_bus:
                await self.event_bus.publish(AgentEvent(
                    event_type=EventType.APPROVAL_DENIED,
                    data=approval
                ))

        await self.state_manager.save_state(state)
        return state

    def visualize_workflow(self, workflow_name: str) -> str:
        """ì›Œí¬í”Œë¡œìš° ì‹œê°í™”"""
        graph = self.graphs.get(workflow_name)
        if not graph:
            return f"âŒ ì›Œí¬í”Œë¡œìš° '{workflow_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return graph.visualize()

    def get_workflow_stats(self, workflow_name: str) -> Dict[str, Any]:
        """
        ì›Œí¬í”Œë¡œìš° í†µê³„

        [ì‹ ê·œ] ê·¸ë˜í”„ ì‹¤í–‰ í†µê³„
        """
        graph = self.graphs.get(workflow_name)
        if not graph:
            return {}
        return graph.get_statistics()

    def get_global_metrics(self) -> Dict[str, Any]:
        """
        ì „ì—­ ë©”íŠ¸ë¦­

        [ì‹ ê·œ] í”„ë ˆì„ì›Œí¬ ì „ì²´ ë©”íŠ¸ë¦­
        """
        return {
            **self.global_metrics,
            "total_workflows": len(self.graphs),
            "total_mcp_tools": len(self.mcp_tools),
            "uptime_seconds": (
                datetime.now(timezone.utc) -
                datetime.fromisoformat(self.global_metrics["start_time"])
            ).total_seconds()
        }

    async def cleanup(self):
        """
        ë¦¬ì†ŒìŠ¤ ì •ë¦¬

        [ì‹ ê·œ] í”„ë ˆì„ì›Œí¬ ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ í•´ì œ
        """
        logging.info("ğŸ§¹ í”„ë ˆì„ì›Œí¬ ì •ë¦¬ ì‹œì‘")

        # MCP ë„êµ¬ ì—°ê²° í•´ì œ
        for tool in self.mcp_tools.values():
            await tool.disconnect()

        logging.info("âœ… í”„ë ˆì„ì›Œí¬ ì •ë¦¬ ì™„ë£Œ")


# ============================================================================
# OpenTelemetry ì„¤ì •
# ============================================================================

def setup_telemetry(service_name: str = "UnifiedAgentFramework",
                   enable_console: bool = False):
    """OpenTelemetry ì„¤ì •"""
    try:
        resource = Resource.create({"service.name": service_name})
        provider = TracerProvider(resource=resource)

        if enable_console:
            processor = BatchSpanProcessor(ConsoleSpanExporter())
            provider.add_span_processor(processor)

        trace.set_tracer_provider(provider)
        logging.info(f"âœ… OpenTelemetry ì„¤ì •: {service_name}")
    except Exception as e:
        logging.warning(f"âš ï¸ OpenTelemetry ì„¤ì • ì‹¤íŒ¨: {e}")


# ============================================================================
# ë°ëª¨ í•¨ìˆ˜ë“¤ - í•™ìŠµìš© 4ê°€ì§€ ë°ëª¨
# ============================================================================

async def demo_simple_chat(framework: UnifiedAgentFramework):
    """
    ë°ëª¨ 1: ë‹¨ìˆœ ëŒ€í™”

    [ì‹ ê·œ] ê°€ì¥ ê¸°ë³¸ì ì¸ ëŒ€í™”í˜• Agent

    í•™ìŠµ í¬ì¸íŠ¸:
    - SimpleAgentì˜ ê¸°ë³¸ ì‚¬ìš©ë²•
    - ë‹¨ìˆœí•œ ì‹œì‘->ì¢…ë£Œ í”Œë¡œìš°
    """
    print("\n" + "="*60)
    print("ğŸ“š ë°ëª¨ 1: ë‹¨ìˆœ ëŒ€í™” Agent")
    print("="*60)

    graph = framework.create_graph("simple_chat")

    assistant = SimpleAgent(
        name="assistant",
        system_prompt="You are a helpful AI assistant. Answer questions clearly and concisely.",
        model=DEFAULT_LLM_MODEL,
        enable_streaming=False,
        event_bus=framework.event_bus
    )

    graph.add_node(Node("assistant", assistant))
    graph.set_start("assistant")
    graph.set_end("assistant")

    print("\nì›Œí¬í”Œë¡œìš° êµ¬ì¡°:")
    print(framework.visualize_workflow("simple_chat"))


async def demo_routing_workflow(framework: UnifiedAgentFramework):
    """
    ë°ëª¨ 2: ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš°

    [ì‹ ê·œ] ì¸í…íŠ¸ ê¸°ë°˜ ë¼ìš°íŒ…

    í•™ìŠµ í¬ì¸íŠ¸:
    - RouterAgentë¡œ ë™ì  ë¼ìš°íŒ…
    - ì „ë¬¸í™”ëœ Agent í™œìš©
    - ë‹¤ì¤‘ ì¢…ë£Œ ë…¸ë“œ
    """
    print("\n" + "="*60)
    print("ğŸ“š ë°ëª¨ 2: ì¸í…íŠ¸ ê¸°ë°˜ ë¼ìš°íŒ…")
    print("="*60)

    graph = framework.create_graph("routing_workflow")

    # Router
    router = RouterAgent(
        name="router",
        system_prompt="Classify user intent accurately.",
        model=DEFAULT_LLM_MODEL,
        routes={
            "order": "order_agent",
            "support": "support_agent",
            "general": "general_agent"
        },
        event_bus=framework.event_bus
    )

    # Specialized Agents
    order_agent = SimpleAgent(
        name="order_agent",
        system_prompt="You are an order specialist. Help with ordering and purchases.",
        model=DEFAULT_LLM_MODEL,
        event_bus=framework.event_bus
    )

    support_agent = SimpleAgent(
        name="support_agent",
        system_prompt="You are a support specialist. Help troubleshoot and resolve issues.",
        model=DEFAULT_LLM_MODEL,
        event_bus=framework.event_bus
    )

    general_agent = SimpleAgent(
        name="general_agent",
        system_prompt="You are a general assistant. Answer various questions.",
        model=DEFAULT_LLM_MODEL,
        event_bus=framework.event_bus
    )

    # Build Graph
    graph.add_node(Node("router", router))
    graph.add_node(Node("order_agent", order_agent))
    graph.add_node(Node("support_agent", support_agent))
    graph.add_node(Node("general_agent", general_agent))

    graph.set_start("router")
    graph.set_end("order_agent")
    graph.set_end("support_agent")
    graph.set_end("general_agent")

    print("\nì›Œí¬í”Œë¡œìš° êµ¬ì¡°:")
    print(framework.visualize_workflow("routing_workflow"))


async def demo_supervisor_workflow(framework: UnifiedAgentFramework):
    """
    ë°ëª¨ 3: Supervisor íŒ¨í„´

    [ì‹ ê·œ] Microsoft AutoGenì˜ Supervisor íŒ¨í„´

    í•™ìŠµ í¬ì¸íŠ¸:
    - SupervisorAgentë¡œ ë©€í‹° ì—ì´ì „íŠ¸ ì¡°ìœ¨
    - ë¼ìš´ë“œ ê¸°ë°˜ í˜‘ì—…
    - ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
    """
    print("\n" + "="*60)
    print("ğŸ“š ë°ëª¨ 3: Supervisor Multi-Agent í˜‘ì—…")
    print("="*60)

    graph = framework.create_graph("supervisor_workflow")

    # Sub-agents
    research_agent = SimpleAgent(
        name="researcher",
        system_prompt="You are a research specialist. Gather and analyze information.",
        model=DEFAULT_LLM_MODEL,
        event_bus=framework.event_bus
    )

    writer_agent = SimpleAgent(
        name="writer",
        system_prompt="You are a content writer. Create clear, engaging content.",
        model=DEFAULT_LLM_MODEL,
        event_bus=framework.event_bus
    )

    # Supervisor
    supervisor = SupervisorAgent(
        name="supervisor",
        system_prompt="Coordinate research and writing tasks.",
        model=DEFAULT_LLM_MODEL,
        sub_agents=[research_agent, writer_agent],
        max_rounds=2,
        event_bus=framework.event_bus
    )

    graph.add_node(Node("supervisor", supervisor))
    graph.set_start("supervisor")
    graph.set_end("supervisor")

    print("\nì›Œí¬í”Œë¡œìš° êµ¬ì¡°:")
    print(framework.visualize_workflow("supervisor_workflow"))


async def demo_conditional_workflow(framework: UnifiedAgentFramework):
    """
    ë°ëª¨ 4: ì¡°ê±´ë¶€ ë¼ìš°íŒ…

    [ì‹ ê·œ] LangGraphì˜ ì¡°ê±´ë¶€ ì—£ì§€ íŒ¨í„´

    í•™ìŠµ í¬ì¸íŠ¸:
    - ì¡°ê±´ í•¨ìˆ˜ (condition_func)ë¡œ ë™ì  ë¼ìš°íŒ…
    - ë³µì¡ë„ ê¸°ë°˜ ì²˜ë¦¬ ê²½ë¡œ ë¶„ê¸°
    - ì¡°ê±´ë¶€ ì—£ì§€ ì‚¬ìš©ë²•
    """
    print("\n" + "="*60)
    print("ğŸ“š ë°ëª¨ 4: ì¡°ê±´ë¶€ ë¼ìš°íŒ… ë° ë£¨í”„")
    print("="*60)

    graph = framework.create_graph("conditional_workflow")

    # Agents
    analyzer = SimpleAgent(
        name="analyzer",
        system_prompt="Analyze the complexity of the user's question. Respond with SIMPLE or COMPLEX.",
        model=DEFAULT_LLM_MODEL,
        event_bus=framework.event_bus
    )

    simple_handler = SimpleAgent(
        name="simple_handler",
        system_prompt="Answer simple questions directly and briefly.",
        model=DEFAULT_LLM_MODEL,
        event_bus=framework.event_bus
    )

    complex_handler = SimpleAgent(
        name="complex_handler",
        system_prompt="Provide detailed, comprehensive answers to complex questions.",
        model=DEFAULT_LLM_MODEL,
        max_tokens=2000,
        event_bus=framework.event_bus
    )

    # Build Graph
    analyzer_node = Node("analyzer", analyzer, edges={"simple": "simple_handler", "complex": "complex_handler"})

    # ğŸ†• ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜
    async def route_by_complexity(state: AgentState, result: NodeResult) -> str:
        """ë³µì¡ë„ì— ë”°ë¼ ë¼ìš°íŒ…"""
        output_lower = result.output.lower()
        if "simple" in output_lower:
            return "simple"
        else:
            return "complex"

    analyzer_node.condition_func = route_by_complexity

    graph.add_node(analyzer_node)
    graph.add_node(Node("simple_handler", simple_handler))
    graph.add_node(Node("complex_handler", complex_handler))

    graph.set_start("analyzer")
    graph.set_end("simple_handler")
    graph.set_end("complex_handler")

    print("\nì›Œí¬í”Œë¡œìš° êµ¬ì¡°:")
    print(framework.visualize_workflow("conditional_workflow"))


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜ - í–¥ìƒëœ CLI
# ============================================================================

async def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜

    [ìˆ˜ì •] CLI ëª…ë ¹ì–´ í™•ì¥: 5ê°œ â†’ 12ê°œ

    ê¸°ì¡´ ëª…ë ¹ì–´:
    - exit, checkpoint, restore, visualize, switch

    ìƒˆ ëª…ë ¹ì–´:
    - rollback, stats, metrics, events, list
    - checkpoint [tag], restore [tag], rollback [steps]
    """
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler("agent_framework.log", encoding='utf-8'),  # ğŸ†• íŒŒì¼ ë¡œê¹…
            logging.StreamHandler()
        ]
    )
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("semantic_kernel").setLevel(logging.WARNING)

    # OpenTelemetry ì„¤ì •
    setup_telemetry("UnifiedAgentFramework-Enterprise", enable_console=False)

    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    api_key = os.getenv("OPEN_AI_KEY_5")
    endpoint = os.getenv("OPEN_AI_ENDPOINT_5")
    deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")

    if not all([api_key, endpoint, deployment_name]):
        raise ValueError("âŒ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ë¯¸ì„¤ì •: AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_DEPLOYMENT_NAME")

    print("\n" + "="*60)
    print("ğŸš€ Unified Agent Framework - Enterprise Edition")
    print("="*60)
    print(f"âœ… ì—”ë“œí¬ì¸íŠ¸: {endpoint}")
    print(f"âœ… ëª¨ë¸: {deployment_name}")
    print("="*60)

    # Kernel ì´ˆê¸°í™”
    kernel = Kernel()
    chat_service = AzureChatCompletion(
        deployment_name=deployment_name,
        api_key=api_key,
        endpoint=endpoint,
        service_id=DEFAULT_LLM_MODEL,  # ğŸ†• ì¤‘ì•™ ì„¤ì • ì‚¬ìš©
        api_version=DEFAULT_API_VERSION
    )
    kernel.add_service(chat_service)

    # Framework ì´ˆê¸°í™”
    framework = UnifiedAgentFramework(
        kernel=kernel,
        checkpoint_dir="./checkpoints",
        enable_telemetry=True,
        enable_events=True
    )

    # ğŸ†• ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
    if framework.event_bus:
        async def log_event(event: AgentEvent):
            logging.info(f"ğŸ“¢ ì´ë²¤íŠ¸: {event.event_type.value} - {event.agent_name or 'System'}")

        framework.event_bus.subscribe(EventType.AGENT_STARTED, log_event)
        framework.event_bus.subscribe(EventType.AGENT_COMPLETED, log_event)
        framework.event_bus.subscribe(EventType.APPROVAL_REQUESTED, log_event)

    # ë°ëª¨ ì›Œí¬í”Œë¡œìš° ìƒì„±
    await demo_simple_chat(framework)
    await demo_routing_workflow(framework)
    await demo_supervisor_workflow(framework)
    await demo_conditional_workflow(framework)

    # ì¸í„°ë™í‹°ë¸Œ ì„¸ì…˜
    print("\n" + "="*60)
    print("ğŸ’¬ ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ")
    print("="*60)
    print("ëª…ë ¹ì–´:")
    print("  - exit: ì¢…ë£Œ")
    print("  - checkpoint [tag]: ì²´í¬í¬ì¸íŠ¸ ì €ì¥")
    print("  - restore [tag]: ì²´í¬í¬ì¸íŠ¸ ë³µì›")
    print("  - rollback [steps]: ì´ì „ ìƒíƒœë¡œ ë¡¤ë°±")  # ğŸ†•
    print("  - visualize: í˜„ì¬ ì›Œí¬í”Œë¡œìš° ì‹œê°í™”")
    print("  - switch [workflow]: ì›Œí¬í”Œë¡œìš° ì „í™˜")
    print("  - stats: ì›Œí¬í”Œë¡œìš° í†µê³„")  # ğŸ†•
    print("  - metrics: ì „ì—­ ë©”íŠ¸ë¦­")  # ğŸ†•
    print("  - events [type]: ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬")  # ğŸ†•
    print("  - list: ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš° ëª©ë¡")  # ğŸ†•
    print("="*60 + "\n")

    session_id = f"session-{int(time.time())}"
    current_workflow = "simple_chat"

    try:
        while True:
            user_input = input(f"\n[{current_workflow}] User > ").strip()

            if not user_input:
                continue

            # ëª…ë ¹ì–´ ì²˜ë¦¬
            if user_input.lower() == "exit":
                print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤...")
                break

            elif user_input.lower().startswith("checkpoint"):
                parts = user_input.split()
                tag = parts[1] if len(parts) > 1 else None
                state = await framework.state_manager.load_state(session_id)
                if state:
                    checkpoint_file = await framework.state_manager.save_checkpoint(state, tag=tag)
                    print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {checkpoint_file}")
                else:
                    print("âŒ ì €ì¥í•  ìƒíƒœê°€ ì—†ìŠµë‹ˆë‹¤")
                continue

            elif user_input.lower().startswith("restore"):
                parts = user_input.split()
                tag = parts[1] if len(parts) > 1 else None
                state = await framework.state_manager.restore_checkpoint(session_id, tag=tag)
                if state:
                    print(f"âœ… ì²´í¬í¬ì¸íŠ¸ ë³µì› ì™„ë£Œ")
                else:
                    print("âŒ ë³µì›í•  ì²´í¬í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤")
                continue

            elif user_input.lower().startswith("rollback"):  # ğŸ†• ë¡¤ë°± ëª…ë ¹ì–´
                parts = user_input.split()
                steps = int(parts[1]) if len(parts) > 1 else 1
                state = await framework.state_manager.rollback(session_id, steps=steps)
                if state:
                    print(f"âœ… {steps}ë‹¨ê³„ ë¡¤ë°± ì™„ë£Œ")
                else:
                    print("âŒ ë¡¤ë°± ì‹¤íŒ¨")
                continue

            elif user_input.lower() == "visualize":
                print("\n" + framework.visualize_workflow(current_workflow))
                continue

            elif user_input.lower().startswith("switch"):
                parts = user_input.split()
                if len(parts) > 1:
                    workflow_name = parts[1]
                    if workflow_name in framework.graphs:
                        current_workflow = workflow_name
                        print(f"âœ… ì›Œí¬í”Œë¡œìš° ì „í™˜: {workflow_name}")
                    else:
                        print(f"âŒ ì›Œí¬í”Œë¡œìš° '{workflow_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                continue

            elif user_input.lower() == "stats":  # ğŸ†• í†µê³„ ëª…ë ¹ì–´
                stats = framework.get_workflow_stats(current_workflow)
                print("\nğŸ“Š ì›Œí¬í”Œë¡œìš° í†µê³„:")
                print(json.dumps(stats, indent=2, ensure_ascii=False))
                continue

            elif user_input.lower() == "metrics":  # ğŸ†• ë©”íŠ¸ë¦­ ëª…ë ¹ì–´
                metrics = framework.get_global_metrics()
                print("\nğŸ“ˆ ì „ì—­ ë©”íŠ¸ë¦­:")
                print(json.dumps(metrics, indent=2, ensure_ascii=False))
                continue

            elif user_input.lower().startswith("events"):  # ğŸ†• ì´ë²¤íŠ¸ ëª…ë ¹ì–´
                parts = user_input.split()
                event_type = parts[1] if len(parts) > 1 else None

                if framework.event_bus:
                    if event_type:
                        try:
                            et = EventType(event_type)
                            events = framework.event_bus.get_event_history(event_type=et, limit=10)
                        except ValueError:
                            print(f"âŒ ì˜ëª»ëœ ì´ë²¤íŠ¸ íƒ€ì…: {event_type}")
                            continue
                    else:
                        events = framework.event_bus.get_event_history(limit=10)

                    print(f"\nğŸ“œ ìµœê·¼ ì´ë²¤íŠ¸ ({len(events)}ê°œ):")
                    for event in events:
                        print(f"  - {event.timestamp}: {event.event_type.value} ({event.agent_name or 'System'})")
                else:
                    print("âŒ ì´ë²¤íŠ¸ ì‹œìŠ¤í…œì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
                continue

            elif user_input.lower() == "list":  # ğŸ†• ëª©ë¡ ëª…ë ¹ì–´
                print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì›Œí¬í”Œë¡œìš°:")
                for name in framework.graphs.keys():
                    marker = "ğŸ‘‰" if name == current_workflow else "  "
                    print(f"{marker} {name}")
                continue

            # ì¼ë°˜ ë©”ì‹œì§€ ì²˜ë¦¬
            try:
                print("\nâ³ ì²˜ë¦¬ ì¤‘...")
                state = await framework.run(
                    session_id=session_id,
                    workflow_name=current_workflow,
                    user_message=user_input
                )

                # ì‘ë‹µ ì¶œë ¥
                if state.messages:
                    last_message = state.messages[-1]
                    print(f"\n[{last_message.agent_name or 'AI'}] > {last_message.content}")

                # ìƒíƒœ ì •ë³´
                print(f"\nğŸ“ ìƒíƒœ: {state.execution_status.value}")
                print(f"ğŸ“Š ë…¸ë“œ: {state.current_node}")
                print(f"ğŸ“ˆ ë°©ë¬¸: {' â†’ '.join(state.visited_nodes[-5:])}")

                if state.metrics:
                    exec_time = state.metrics.get('execution_time_ms', 0)
                    iterations = state.metrics.get('total_iterations', 0)
                    print(f"â±ï¸ ì‹¤í–‰ ì‹œê°„: {exec_time:.2f}ms ({iterations} iterations)")

                # ğŸ†• ìŠ¹ì¸ ëŒ€ê¸° ì²˜ë¦¬
                if state.execution_status == ExecutionStatus.WAITING_APPROVAL:
                    print("\nâ¸ï¸ ìŠ¹ì¸ ëŒ€ê¸° ì¤‘:")
                    for i, approval in enumerate(state.pending_approvals):
                        print(f"  [{i}] {approval.get('description', 'N/A')}")
                        print(f"      Arguments: {approval.get('arguments', {})}")

                    approve_input = input("\nìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                    approved = approve_input == 'y'

                    state = await framework.approve_pending_request(
                        session_id,
                        request_id=0,
                        approved=approved
                    )
                    print(f"\n{'âœ… ìŠ¹ì¸ë¨' if approved else 'âŒ ê±°ë¶€ë¨'}")

            except Exception as e:
                logging.error(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
                print(f"\nâŒ ì˜¤ë¥˜: {e}")

    finally:
        # ì •ë¦¬
        await framework.cleanup()
        print("\nâœ… í”„ë ˆì„ì›Œí¬ ì¢…ë£Œ ì™„ë£Œ")


if __name__ == "__main__":
    asyncio.run(main())
