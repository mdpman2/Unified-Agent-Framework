#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Agent Framework - ë”¥ ë¦¬ì„œì¹˜ ëª¨ë“ˆ (Deep Research Module)

================================================================================
ðŸ“ íŒŒì¼ ìœ„ì¹˜: unified_agent/deep_research.py
ðŸ“‹ ì—­í• : ë‹¤ë‹¨ê³„ ìžìœ¨ ì—°êµ¬ ì—ì´ì „íŠ¸, Azure o3-deep-research í†µí•©
ðŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›” 13ì¼
ðŸ“¦ ë²„ì „: v4.1.0
âœ… í…ŒìŠ¤íŠ¸: test_v41_scenarios.py
================================================================================

ðŸŽ¯ ì£¼ìš” êµ¬ì„± ìš”ì†Œ:
    1. DeepResearchAgent - ë‹¤ë‹¨ê³„ ìžìœ¨ ì—°êµ¬ ìˆ˜í–‰ ì—ì´ì „íŠ¸
    2. ResearchPlan - ì—°êµ¬ ê³„íš ìˆ˜ë¦½ ë° ê´€ë¦¬
    3. SourceCollector - ì›¹/ë¬¸ì„œ ì†ŒìŠ¤ ìˆ˜ì§‘ ë° ê²€ì¦
    4. SynthesisEngine - ìˆ˜ì§‘ëœ ì •ë³´ ì¢…í•© ë° ë³´ê³ ì„œ ìƒì„±
    5. CitationManager - ì¶œì²˜ ê´€ë¦¬ ë° ì¸ë¼ì¸ ì¸ìš©

ðŸ”§ 2026ë…„ 2ì›” ê¸°ëŠ¥:
    - Azure Foundry Deep Research Tool í†µí•© (o3-deep-research ëª¨ë¸)
    - Grounding with Bing Searchë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì •ë³´ ìˆ˜ì§‘
    - ë‹¤ë‹¨ê³„ ì—°êµ¬ í”„ë¡œì„¸ìŠ¤: ê³„íš â†’ ìˆ˜ì§‘ â†’ ë¶„ì„ â†’ ì¢…í•© â†’ ê²€ì¦
    - PDCA Evaluator ì—°ë™ìœ¼ë¡œ ì—°êµ¬ í’ˆì§ˆ ìžë™ í‰ê°€
    - ì¶œì²˜ ì¸ìš© ë° ê²€ì¦ (Hallucination ë°©ì§€)
    - ì—°êµ¬ ì¤‘ê°„ ì‚°ì¶œë¬¼ ì²´í¬í¬ì¸íŠ¸ (Durable Agent ì—°ë™)

ðŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
    >>> from unified_agent.deep_research import (
    ...     DeepResearchAgent, ResearchConfig, ResearchPlan,
    ...     ResearchPhase, CitationManager
    ... )
    >>>
    >>> agent = DeepResearchAgent(ResearchConfig(
    ...     model="o3-deep-research",
    ...     max_sources=20,
    ...     search_provider="bing"
    ... ))
    >>> result = await agent.research("2026ë…„ AI Agent í”„ë ˆìž„ì›Œí¬ ìƒíƒœê³„ ë¶„ì„")
    >>> print(f"ë³´ê³ ì„œ: {result.report}")
    >>> print(f"ì¶œì²˜: {len(result.citations)}ê°œ")

âš ï¸ ì£¼ì˜ì‚¬í•­:
    - Deep ResearchëŠ” ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤ (ìˆ˜ ë¶„ ~ ìˆ˜ì‹­ ë¶„)
    - ì›¹ ê²€ìƒ‰ ê²°ê³¼ì˜ ì •í™•ì„±ì„ ë°˜ë“œì‹œ ê²€ì¦í•˜ì„¸ìš”
    - API ë¹„ìš©ì´ ë†’ì„ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ max_sourcesë¥¼ ì ì ˆížˆ ì„¤ì •í•˜ì„¸ìš”

ðŸ”— ê´€ë ¨ ë¬¸ì„œ:
    - Azure Deep Research Tool: https://learn.microsoft.com/azure/ai-foundry/agents/how-to/tools-classic/deep-research
    - OpenAI Deep Research: https://openai.com/index/deep-research/
"""

from __future__ import annotations

import asyncio
import logging
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum, unique
from typing import Any

__all__ = [
    # Enums
    "ResearchPhase",
    "SourceType",
    "ResearchStatus",
    "SearchProvider",
    # Config & Data Models
    "ResearchConfig",
    "ResearchPlan",
    "ResearchStep",
    "SourceDocument",
    "Citation",
    "ResearchResult",
    # Core Components
    "DeepResearchAgent",
    "SourceCollector",
    "SynthesisEngine",
    "CitationManager",
    "ResearchCheckpoint",
]

logger = logging.getLogger(__name__)

# ============================================================================
# Enums
# ============================================================================

@unique
class ResearchPhase(Enum):
    """ì—°êµ¬ ë‹¨ê³„"""
    PLANNING = "planning"             # ì—°êµ¬ ê³„íš ìˆ˜ë¦½
    QUERY_GENERATION = "query_gen"    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    SOURCE_COLLECTION = "collection"  # ì†ŒìŠ¤ ìˆ˜ì§‘
    ANALYSIS = "analysis"             # ë¶„ì„
    SYNTHESIS = "synthesis"           # ì¢…í•©
    VERIFICATION = "verification"     # ê²€ì¦
    REPORT_GENERATION = "report"      # ë³´ê³ ì„œ ìƒì„±
    COMPLETED = "completed"           # ì™„ë£Œ


@unique
class SourceType(Enum):
    """ì†ŒìŠ¤ ìœ í˜•"""
    WEB_PAGE = "web_page"             # ì›¹ íŽ˜ì´ì§€
    ACADEMIC_PAPER = "academic"       # í•™ìˆ  ë…¼ë¬¸
    NEWS_ARTICLE = "news"             # ë‰´ìŠ¤ ê¸°ì‚¬
    DOCUMENTATION = "documentation"   # ê¸°ìˆ  ë¬¸ì„œ
    BLOG_POST = "blog"               # ë¸”ë¡œê·¸
    REPORT = "report"                 # ë³´ê³ ì„œ
    SOCIAL_MEDIA = "social"           # ì†Œì…œ ë¯¸ë””ì–´
    VIDEO_TRANSCRIPT = "video"        # ë¹„ë””ì˜¤ íŠ¸ëžœìŠ¤í¬ë¦½íŠ¸


@unique
class ResearchStatus(Enum):
    """ì—°êµ¬ ìƒíƒœ"""
    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"


@unique
class SearchProvider(Enum):
    """ê²€ìƒ‰ í”„ë¡œë°”ì´ë”"""
    BING = "bing"                     # Grounding with Bing
    GOOGLE = "google"                 # Google Search
    ARXIV = "arxiv"                   # arXiv (í•™ìˆ )
    SEMANTIC_SCHOLAR = "semantic"     # Semantic Scholar
    WEB_SEARCH_TOOL = "web_search"   # OpenAI Web Search Tool


# ============================================================================
# Data Models
# ============================================================================

@dataclass(frozen=True, slots=True)
class ResearchConfig:
    """
    ë”¥ ë¦¬ì„œì¹˜ ì„¤ì •

    Attributes:
        model: ì‚¬ìš©í•  ëª¨ë¸ (o3-deep-research ê¶Œìž¥)
        max_sources: ìµœëŒ€ ìˆ˜ì§‘ ì†ŒìŠ¤ ìˆ˜
        max_queries: ìµœëŒ€ ê²€ìƒ‰ ì¿¼ë¦¬ ìˆ˜
        search_provider: ê²€ìƒ‰ í”„ë¡œë°”ì´ë”
        min_quality_score: ìµœì†Œ í’ˆì§ˆ ì ìˆ˜ (0.0~1.0)
        enable_verification: êµì°¨ ê²€ì¦ í™œì„±í™”
        enable_checkpointing: ì²´í¬í¬ì¸íŒ… í™œì„±í™”
        language: ì—°êµ¬ ì–¸ì–´
        timeout_minutes: ì „ì²´ íƒ€ìž„ì•„ì›ƒ (ë¶„)
    """
    model: str = "o3-deep-research"
    max_sources: int = 20
    max_queries: int = 10
    search_provider: SearchProvider = SearchProvider.BING
    min_quality_score: float = 0.6
    enable_verification: bool = True
    enable_checkpointing: bool = True
    language: str = "ko"
    timeout_minutes: int = 30


@dataclass(slots=True)
class ResearchStep:
    """
    ì—°êµ¬ ë‹¨ê³„ë³„ ì‚°ì¶œë¬¼

    Attributes:
        step_id: ë‹¨ê³„ ID
        phase: ì—°êµ¬ ë‹¨ê³„
        description: ë‹¨ê³„ ì„¤ëª…
        output: ë‹¨ê³„ ì‚°ì¶œë¬¼
        duration_seconds: ì†Œìš” ì‹œê°„
        metadata: ì¶”ê°€ ì •ë³´
    """
    step_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    phase: ResearchPhase = ResearchPhase.PLANNING
    description: str = ""
    output: str = ""
    duration_seconds: float = 0.0
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass(slots=True)
class SourceDocument:
    """
    ìˆ˜ì§‘ëœ ì†ŒìŠ¤ ë¬¸ì„œ

    Attributes:
        source_id: ì†ŒìŠ¤ ê³ ìœ  ID
        url: ì†ŒìŠ¤ URL
        title: ì†ŒìŠ¤ ì œëª©
        content: ì†ŒìŠ¤ ë‚´ìš© (ìš”ì•½ ë˜ëŠ” ì „ë¬¸)
        source_type: ì†ŒìŠ¤ ìœ í˜•
        relevance_score: ê´€ë ¨ì„± ì ìˆ˜ (0.0~1.0)
        credibility_score: ì‹ ë¢°ë„ ì ìˆ˜ (0.0~1.0)
        published_date: ë°œí–‰ì¼
        author: ì €ìž
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    """
    source_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    url: str = ""
    title: str = ""
    content: str = ""
    source_type: SourceType = SourceType.WEB_PAGE
    relevance_score: float = 0.0
    credibility_score: float = 0.0
    published_date: str = ""
    author: str = ""
    metadata: dict[str, Any] = field(default_factory=dict)

    @property
    def quality_score(self) -> float:
        """ì¢…í•© í’ˆì§ˆ ì ìˆ˜ (ê´€ë ¨ì„± 60% + ì‹ ë¢°ë„ 40%)"""
        return self.relevance_score * 0.6 + self.credibility_score * 0.4


@dataclass(slots=True)
class Citation:
    """
    ì¸ìš© ì •ë³´

    Attributes:
        citation_id: ì¸ìš© ID
        source: ì°¸ì¡° ì†ŒìŠ¤
        text_snippet: ì¸ìš©ëœ í…ìŠ¤íŠ¸
        context: ì¸ìš© ë§¥ë½
        position: ë³´ê³ ì„œ ë‚´ ìœ„ì¹˜ (ë¬¸ë‹¨ ë²ˆí˜¸)
    """
    citation_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    source: SourceDocument | None = None
    text_snippet: str = ""
    context: str = ""
    position: int = 0


@dataclass(slots=True)
class ResearchPlan:
    """
    ì—°êµ¬ ê³„íš

    Attributes:
        plan_id: ê³„íš ID
        topic: ì—°êµ¬ ì£¼ì œ
        objective: ì—°êµ¬ ëª©í‘œ
        sub_questions: í•˜ìœ„ ì—°êµ¬ ì§ˆë¬¸
        search_queries: ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡
        expected_sources: ì˜ˆìƒ ì†ŒìŠ¤ ìœ í˜•
        methodology: ì—°êµ¬ ë°©ë²•ë¡ 
    """
    plan_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    topic: str = ""
    objective: str = ""
    sub_questions: list[str] = field(default_factory=list)
    search_queries: list[str] = field(default_factory=list)
    expected_sources: list[SourceType] = field(default_factory=list)
    methodology: str = ""

    @property
    def total_queries(self) -> int:
        return len(self.search_queries)


@dataclass(slots=True)
class ResearchResult:
    """
    ë”¥ ë¦¬ì„œì¹˜ ìµœì¢… ê²°ê³¼

    Attributes:
        result_id: ê²°ê³¼ ID
        topic: ì—°êµ¬ ì£¼ì œ
        report: ìµœì¢… ë³´ê³ ì„œ (ë§ˆí¬ë‹¤ìš´)
        executive_summary: ìš”ì•½
        sources: ìˆ˜ì§‘ëœ ì†ŒìŠ¤ ëª©ë¡
        citations: ì¸ìš© ëª©ë¡
        plan: ì—°êµ¬ ê³„íš
        steps: ìˆ˜í–‰ëœ ì—°êµ¬ ë‹¨ê³„ ëª©ë¡
        quality_score: ì „ì²´ í’ˆì§ˆ ì ìˆ˜
        total_duration_seconds: ì´ ì†Œìš” ì‹œê°„
        status: ì—°êµ¬ ìƒíƒœ
    """
    result_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    topic: str = ""
    report: str = ""
    executive_summary: str = ""
    sources: list[SourceDocument] = field(default_factory=list)
    citations: list[Citation] = field(default_factory=list)
    plan: ResearchPlan | None = None
    steps: list[ResearchStep] = field(default_factory=list)
    quality_score: float = 0.0
    total_duration_seconds: float = 0.0
    status: ResearchStatus = ResearchStatus.NOT_STARTED


@dataclass(slots=True)
class ResearchCheckpoint:
    """
    ì—°êµ¬ ì²´í¬í¬ì¸íŠ¸ (ì¤‘ê°„ ì €ìž¥)

    Attributes:
        checkpoint_id: ì²´í¬í¬ì¸íŠ¸ ID
        research_id: ì—°êµ¬ ID
        phase: í˜„ìž¬ ë‹¨ê³„
        data: ì²´í¬í¬ì¸íŠ¸ ë°ì´í„°
        timestamp: ì €ìž¥ ì‹œê°
    """
    checkpoint_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    research_id: str = ""
    phase: ResearchPhase = ResearchPhase.PLANNING
    data: dict[str, Any] = field(default_factory=dict)
    timestamp: datetime = field(
        default_factory=lambda: datetime.now(timezone.utc)
    )


# ============================================================================
# Core Components
# ============================================================================

class SourceCollector:
    """
    ì†ŒìŠ¤ ìˆ˜ì§‘ê¸° (Source Collector)

    ì›¹ ê²€ìƒ‰, ë¬¸ì„œ ê²€ìƒ‰ì„ í†µí•´ ì—°êµ¬ ì†ŒìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤.

    ðŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> collector = SourceCollector(SearchProvider.BING)
        >>> sources = await collector.search("AI Agent í”„ë ˆìž„ì›Œí¬ ìµœì‹  ë™í–¥")
        >>> filtered = collector.filter_by_quality(sources, min_score=0.7)
    """

    def __init__(self, provider: SearchProvider = SearchProvider.BING) -> None:
        self._provider = provider
        self._collected: list[SourceDocument] = []

    async def search(
        self, query: str, max_results: int = 10
    ) -> list[SourceDocument]:
        """
        ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì†ŒìŠ¤ ìˆ˜ì§‘

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜

        Returns:
            ìˆ˜ì§‘ëœ SourceDocument ëª©ë¡
        """
        # ì‹œë®¬ë ˆì´ì…˜: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” Bing API / Web Search Tool í˜¸ì¶œ
        sources = []
        for i in range(min(max_results, 5)):
            source = SourceDocument(
                url=f"https://example.com/result-{i+1}",
                title=f"Research Result {i+1}: {query[:30]}...",
                content=f"Content about {query} from source {i+1}",
                source_type=SourceType.WEB_PAGE,
                relevance_score=0.9 - (i * 0.1),
                credibility_score=0.85 - (i * 0.05),
                published_date="2026-02",
            )
            sources.append(source)
            self._collected.append(source)

        logger.info(f"Collected {len(sources)} sources for query: {query[:50]}...")
        return sources

    def filter_by_quality(
        self, sources: list[SourceDocument], min_score: float = 0.6
    ) -> list[SourceDocument]:
        """í’ˆì§ˆ ê¸°ì¤€ìœ¼ë¡œ ì†ŒìŠ¤ í•„í„°ë§"""
        return [s for s in sources if s.quality_score >= min_score]

    def deduplicate(self, sources: list[SourceDocument]) -> list[SourceDocument]:
        """ì¤‘ë³µ ì†ŒìŠ¤ ì œê±° (URL ê¸°ì¤€)"""
        seen_urls: set[str] = set()
        unique = []
        for source in sources:
            if source.url not in seen_urls:
                seen_urls.add(source.url)
                unique.append(source)
        return unique

    @property
    def total_collected(self) -> int:
        return len(self._collected)


class CitationManager:
    """
    ì¸ìš© ê´€ë¦¬ìž (Citation Manager)

    ìˆ˜ì§‘ëœ ì†ŒìŠ¤ì˜ ì¸ìš©ì„ ê´€ë¦¬í•˜ê³  ì¸ë¼ì¸ ì¸ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ðŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> cm = CitationManager()
        >>> citation = cm.add_citation(source, "ì¸ìš©ëœ í…ìŠ¤íŠ¸", position=3)
        >>> formatted = cm.format_inline(citation)
        >>> bibliography = cm.generate_bibliography()
    """

    def __init__(self) -> None:
        self._citations: list[Citation] = []
        self._sources: dict[str, SourceDocument] = {}

    def add_citation(
        self, source: SourceDocument, text_snippet: str,
        context: str = "", position: int = 0
    ) -> Citation:
        """ì¸ìš© ì¶”ê°€"""
        self._sources[source.source_id] = source
        citation = Citation(
            source=source,
            text_snippet=text_snippet,
            context=context,
            position=position,
        )
        self._citations.append(citation)
        return citation

    def format_inline(self, citation: Citation) -> str:
        """ì¸ë¼ì¸ ì¸ìš© í˜•ì‹ ìƒì„±"""
        if citation.source:
            return f'[{citation.source.title}]({citation.source.url})'
        return f"[ì¶œì²˜ {citation.citation_id}]"

    def generate_bibliography(self) -> str:
        """ì°¸ê³ ë¬¸í—Œ ëª©ë¡ ìƒì„±"""
        lines = ["## ì°¸ê³ ë¬¸í—Œ\n"]
        for i, (_, source) in enumerate(self._sources.items(), 1):
            lines.append(
                f"{i}. [{source.title}]({source.url}) â€” "
                f"{source.author or 'ì €ìž ë¯¸ìƒ'}, {source.published_date}"
            )
        return "\n".join(lines)

    @property
    def citation_count(self) -> int:
        return len(self._citations)

    @property
    def source_count(self) -> int:
        return len(self._sources)


class SynthesisEngine:
    """
    ì¢…í•© ì—”ì§„ (Synthesis Engine)

    ìˆ˜ì§‘ëœ ì†ŒìŠ¤ë“¤ì„ ë¶„ì„í•˜ê³  ì¢…í•©í•˜ì—¬ ì—°êµ¬ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ðŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> engine = SynthesisEngine()
        >>> report = await engine.synthesize(
        ...     topic="AI Agent ë™í–¥",
        ...     sources=filtered_sources,
        ...     plan=research_plan
        ... )
    """

    def __init__(self) -> None:
        self._citation_manager = CitationManager()

    async def synthesize(
        self, topic: str, sources: list[SourceDocument],
        plan: ResearchPlan | None = None
    ) -> tuple[str, list[Citation]]:
        """
        ì†ŒìŠ¤ë¥¼ ì¢…í•©í•˜ì—¬ ë³´ê³ ì„œ ìƒì„±

        Args:
            topic: ì—°êµ¬ ì£¼ì œ
            sources: ìˆ˜ì§‘ëœ ì†ŒìŠ¤ ëª©ë¡
            plan: ì—°êµ¬ ê³„íš

        Returns:
            (ë³´ê³ ì„œ í…ìŠ¤íŠ¸, ì¸ìš© ëª©ë¡) íŠœí”Œ
        """
        # ì¸ìš© ìƒì„±
        for i, source in enumerate(sources):
            self._citation_manager.add_citation(
                source,
                text_snippet=source.content[:100],
                position=i + 1,
            )

        # ì‹œë®¬ë ˆì´ì…˜: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLMìœ¼ë¡œ ì¢…í•© ë³´ê³ ì„œ ìƒì„±
        sub_questions = ""
        if plan and plan.sub_questions:
            sub_questions = "\n".join(
                f"- {q}" for q in plan.sub_questions
            )

        report = f"""# {topic}

## ìš”ì•½
{topic}ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œìž…ë‹ˆë‹¤. ì´ {len(sources)}ê°œì˜ ì¶œì²˜ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

## ì—°êµ¬ ì§ˆë¬¸
{sub_questions or '- ì£¼ì œì— ëŒ€í•œ ì¢…í•© ë¶„ì„'}

## ë¶„ì„ ê²°ê³¼
ìˆ˜ì§‘ëœ {len(sources)}ê°œì˜ ì†ŒìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.

{chr(10).join(f'### ì¶œì²˜ {i+1}: {s.title}' + chr(10) + s.content for i, s in enumerate(sources[:5]))}

{self._citation_manager.generate_bibliography()}
"""
        return report, self._citation_manager._citations

    @property
    def citation_manager(self) -> CitationManager:
        return self._citation_manager


class DeepResearchAgent:
    """
    ë”¥ ë¦¬ì„œì¹˜ ì—ì´ì „íŠ¸ (Deep Research Agent)

    ë‹¤ë‹¨ê³„ ìžìœ¨ ì—°êµ¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ìž…ë‹ˆë‹¤.
    Azure Foundry Deep Research Tool(o3-deep-research)ê³¼ í†µí•©ë©ë‹ˆë‹¤.

    ì—°êµ¬ í”„ë¡œì„¸ìŠ¤:
        1. ðŸ“‹ Planning: ì—°êµ¬ ì§ˆë¬¸ ë¶„í•´, ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        2. ðŸ” Collection: ë‹¤ì¤‘ ì†ŒìŠ¤ ìˆ˜ì§‘ (Bing, í•™ìˆ  DB ë“±)
        3. ðŸ“Š Analysis: ì†ŒìŠ¤ í’ˆì§ˆ í‰ê°€ ë° í•µì‹¬ ì •ë³´ ì¶”ì¶œ
        4. ðŸ§© Synthesis: ìˆ˜ì§‘ ì •ë³´ ì¢…í•© ë° ë³´ê³ ì„œ ìƒì„±
        5. âœ… Verification: êµì°¨ ê²€ì¦ ë° íŒ©íŠ¸ ì²´í¬
        6. ðŸ“ Report: ìµœì¢… ë³´ê³ ì„œ + ì¸ìš© + ì°¸ê³ ë¬¸í—Œ

    ðŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> agent = DeepResearchAgent(ResearchConfig(
        ...     model="o3-deep-research",
        ...     max_sources=20,
        ...     enable_verification=True
        ... ))
        >>> result = await agent.research(
        ...     "2026ë…„ AI Agent í”„ë ˆìž„ì›Œí¬ ìƒíƒœê³„ ë¹„êµ ë¶„ì„"
        ... )
        >>> print(f"ë³´ê³ ì„œ ê¸¸ì´: {len(result.report)}ìž")
        >>> print(f"í’ˆì§ˆ ì ìˆ˜: {result.quality_score:.1%}")
        >>> print(f"ì†ŒìŠ¤ ìˆ˜: {len(result.sources)}ê°œ")
        >>> print(f"ì†Œìš” ì‹œê°„: {result.total_duration_seconds:.1f}ì´ˆ")
    """

    def __init__(self, config: ResearchConfig | None = None) -> None:
        self.config = config or ResearchConfig()
        self._collector = SourceCollector(self.config.search_provider)
        self._synthesis = SynthesisEngine()
        self._checkpoints: list[ResearchCheckpoint] = []
        self._research_history: list[ResearchResult] = []

    async def research(self, topic: str) -> ResearchResult:
        """
        ë”¥ ë¦¬ì„œì¹˜ ì‹¤í–‰

        Args:
            topic: ì—°êµ¬ ì£¼ì œ

        Returns:
            ResearchResult: ì—°êµ¬ ê²°ê³¼
        """
        start_time = time.monotonic()
        result = ResearchResult(topic=topic, status=ResearchStatus.IN_PROGRESS)
        steps: list[ResearchStep] = []

        try:
            # Phase 1: ì—°êµ¬ ê³„íš ìˆ˜ë¦½
            step_start = time.monotonic()
            plan = await self._plan_research(topic)
            result.plan = plan
            steps.append(ResearchStep(
                phase=ResearchPhase.PLANNING,
                description="ì—°êµ¬ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ",
                output=f"í•˜ìœ„ ì§ˆë¬¸ {len(plan.sub_questions)}ê°œ, ê²€ìƒ‰ ì¿¼ë¦¬ {len(plan.search_queries)}ê°œ",
                duration_seconds=time.monotonic() - step_start,
            ))
            self._save_checkpoint(result.result_id, ResearchPhase.PLANNING, {"plan": plan})

            # Phase 2: ì†ŒìŠ¤ ìˆ˜ì§‘
            step_start = time.monotonic()
            all_sources: list[SourceDocument] = []
            for query in plan.search_queries[:self.config.max_queries]:
                sources = await self._collector.search(query, max_results=5)
                all_sources.extend(sources)

            # ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ í•„í„°ë§
            all_sources = self._collector.deduplicate(all_sources)
            filtered = self._collector.filter_by_quality(
                all_sources, self.config.min_quality_score
            )
            result.sources = filtered[:self.config.max_sources]
            steps.append(ResearchStep(
                phase=ResearchPhase.SOURCE_COLLECTION,
                description=f"ì†ŒìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_sources)}ê°œ â†’ í•„í„°ë§ í›„ {len(result.sources)}ê°œ",
                output=f"ì´ {len(result.sources)}ê°œ ì†ŒìŠ¤",
                duration_seconds=time.monotonic() - step_start,
            ))
            self._save_checkpoint(result.result_id, ResearchPhase.SOURCE_COLLECTION, {
                "source_count": len(result.sources)
            })

            # Phase 3: ì¢…í•© ë° ë³´ê³ ì„œ ìƒì„±
            step_start = time.monotonic()
            report, citations = await self._synthesis.synthesize(
                topic, result.sources, plan
            )
            result.report = report
            result.citations = citations
            result.executive_summary = f"{topic}ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„. {len(result.sources)}ê°œ ì†ŒìŠ¤ ê¸°ë°˜."
            steps.append(ResearchStep(
                phase=ResearchPhase.SYNTHESIS,
                description="ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ",
                output=f"ë³´ê³ ì„œ {len(report)}ìž, ì¸ìš© {len(citations)}ê°œ",
                duration_seconds=time.monotonic() - step_start,
            ))

            # Phase 4: ê²€ì¦ (ì˜µì…˜)
            if self.config.enable_verification:
                step_start = time.monotonic()
                quality = await self._verify_research(result)
                result.quality_score = quality
                steps.append(ResearchStep(
                    phase=ResearchPhase.VERIFICATION,
                    description=f"í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ: {quality:.1%}",
                    output=f"í’ˆì§ˆ ì ìˆ˜: {quality:.1%}",
                    duration_seconds=time.monotonic() - step_start,
                ))

            result.status = ResearchStatus.COMPLETED

        except Exception as e:
            result.status = ResearchStatus.FAILED
            logger.error(f"Research failed: {e}")
            steps.append(ResearchStep(
                phase=ResearchPhase.COMPLETED,
                description=f"ì—°êµ¬ ì‹¤íŒ¨: {e}",
            ))

        result.steps = steps
        result.total_duration_seconds = time.monotonic() - start_time
        self._research_history.append(result)

        logger.info(
            f"Deep Research completed: topic='{topic[:30]}...', "
            f"sources={len(result.sources)}, quality={result.quality_score:.1%}, "
            f"duration={result.total_duration_seconds:.1f}s"
        )
        return result

    async def _plan_research(self, topic: str) -> ResearchPlan:
        """ì—°êµ¬ ê³„íš ìˆ˜ë¦½"""
        # ì‹œë®¬ë ˆì´ì…˜: ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” LLMì´ ì—°êµ¬ ì§ˆë¬¸ê³¼ ì¿¼ë¦¬ ìƒì„±
        plan = ResearchPlan(
            topic=topic,
            objective=f"{topic}ì— ëŒ€í•œ ì¢…í•©ì ì¸ ë¶„ì„ ë³´ê³ ì„œ ìž‘ì„±",
            sub_questions=[
                f"{topic}ì˜ í˜„ìž¬ ìƒíƒœëŠ”?",
                f"{topic}ì˜ ì£¼ìš” íŠ¸ë Œë“œëŠ”?",
                f"{topic}ì˜ ë¯¸ëž˜ ì „ë§ì€?",
            ],
            search_queries=[
                topic,
                f"{topic} ìµœì‹ ",
                f"{topic} ë¹„êµ ë¶„ì„",
                f"{topic} ì‚¬ë¡€",
            ],
            expected_sources=[
                SourceType.WEB_PAGE,
                SourceType.NEWS_ARTICLE,
                SourceType.DOCUMENTATION,
            ],
            methodology="ë‹¤ì¤‘ ì†ŒìŠ¤ ìˆ˜ì§‘ â†’ êµì°¨ ê²€ì¦ â†’ LLM ì¢…í•©",
        )
        return plan

    async def _verify_research(self, result: ResearchResult) -> float:
        """ì—°êµ¬ í’ˆì§ˆ ê²€ì¦"""
        score = 0.0
        checks = 0

        # 1. ì†ŒìŠ¤ ë‹¤ì–‘ì„± ê²€ì‚¬
        source_types = set(s.source_type for s in result.sources)
        if len(source_types) >= 2:
            score += 0.25
        checks += 1

        # 2. ì†ŒìŠ¤ í’ˆì§ˆ í‰ê·  ê²€ì‚¬
        if result.sources:
            avg_quality = sum(s.quality_score for s in result.sources) / len(result.sources)
            score += min(0.25, avg_quality * 0.3)
        checks += 1

        # 3. ì¸ìš© ì»¤ë²„ë¦¬ì§€ ê²€ì‚¬
        if result.citations and result.sources:
            coverage = len(result.citations) / len(result.sources)
            score += min(0.25, coverage * 0.25)
        checks += 1

        # 4. ë³´ê³ ì„œ ì™„ì„±ë„ ê²€ì‚¬
        if result.report and len(result.report) > 500:
            score += 0.25
        checks += 1

        return min(1.0, score)

    def _save_checkpoint(
        self, research_id: str, phase: ResearchPhase, data: dict[str, Any]
    ) -> None:
        """ì²´í¬í¬ì¸íŠ¸ ì €ìž¥"""
        if self.config.enable_checkpointing:
            checkpoint = ResearchCheckpoint(
                research_id=research_id,
                phase=phase,
                data=data,
            )
            self._checkpoints.append(checkpoint)

    @property
    def research_history(self) -> list[ResearchResult]:
        return self._research_history.copy()

    @property
    def checkpoints(self) -> list[ResearchCheckpoint]:
        return self._checkpoints.copy()
