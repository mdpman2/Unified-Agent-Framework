#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Agent Framework - ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ëª¨ë“ˆ (Open Weight Module)

================================================================================
ğŸ“ íŒŒì¼ ìœ„ì¹˜: unified_agent/open_weight.py
ğŸ“‹ ì—­í• : ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ì§€ì› (gpt-oss-120b/20b, Llama 4, Mistral ë“±)
ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›” 8ì¼
ğŸ“¦ ë²„ì „: v4.1.0
âœ… í…ŒìŠ¤íŠ¸: test_v41_all_scenarios.py
================================================================================

ğŸ¯ ì£¼ìš” êµ¬ì„± ìš”ì†Œ:
    1. OpenWeightAdapter - ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ì–´ëŒ‘í„°
    2. OSSModelConfig - ëª¨ë¸ë³„ ì„¤ì •
    3. OpenWeightRegistry - ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬

ğŸ”§ 2026ë…„ 2ì›” ê¸°ëŠ¥:
    - gpt-oss-120b / gpt-oss-20b (Apache 2.0 ë¼ì´ì„ ìŠ¤)
    - Llama 4 (10M ì»¨í…ìŠ¤íŠ¸), Phi-4, Mistral
    - Microsoft Foundry ê¸°ë°˜ í˜¸ìŠ¤íŒ…
    - OpenAI-compatible APIë¡œ í†µí•© ì ‘ê·¼

ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
    >>> from unified_agent.open_weight import OpenWeightAdapter, OSSModelConfig
    >>>
    >>> adapter = OpenWeightAdapter()
    >>> result = await adapter.generate(
    ...     model="gpt-oss-120b",
    ...     prompt="Pythonìœ¼ë¡œ ì›¹ ì„œë²„ êµ¬í˜„",
    ...     config=OSSModelConfig(max_tokens=4096)
    ... )
"""

from __future__ import annotations

import logging
import uuid
from dataclasses import dataclass, field
from enum import Enum
from typing import Any

__all__ = [
    "OSSLicense",
    "OSSModelConfig",
    "OSSModelInfo",
    "OpenWeightAdapter",
    "OpenWeightRegistry",
]

logger = logging.getLogger(__name__)

class OSSLicense(Enum):
    """ì˜¤í”ˆ ì†ŒìŠ¤ ë¼ì´ì„ ìŠ¤"""
    APACHE_2_0 = "Apache-2.0"
    MIT = "MIT"
    LLAMA_LICENSE = "Llama-License"
    MISTRAL_LICENSE = "Mistral-Research"

@dataclass(frozen=True, slots=True)
class OSSModelConfig:
    """
    ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ì„¤ì •

    Attributes:
        max_tokens: ìµœëŒ€ ì¶œë ¥ í† í°
        temperature: ìƒì„± ì˜¨ë„
        top_p: ìƒ˜í”Œë§ í™•ë¥ 
        endpoint: í˜¸ìŠ¤íŒ… ì—”ë“œí¬ì¸íŠ¸ URL
    """
    max_tokens: int = 4096
    temperature: float = 0.7
    top_p: float = 0.9
    endpoint: str | None = None

@dataclass(frozen=True, slots=True)
class OSSModelInfo:
    """ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ì •ë³´"""
    name: str = ""
    parameters: str = ""  # e.g., "120B", "20B"
    license: OSSLicense = OSSLicense.APACHE_2_0
    context_window: int = 0
    capabilities: list[str] = field(default_factory=list)

class OpenWeightRegistry:
    """
    ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬

    ================================================================================
    ğŸ“‹ ì—­í• : ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ê´€ë¦¬ ë° ê²€ìƒ‰
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    """

    # ê¸°ë³¸ ë“±ë¡ ëª¨ë¸ (2026ë…„ 2ì›” ê¸°ì¤€)
    _MODELS: dict[str, OSSModelInfo] = {
        "gpt-oss-120b": OSSModelInfo(
            name="gpt-oss-120b", parameters="120B",
            license=OSSLicense.APACHE_2_0, context_window=128_000,
            capabilities=["text-generation", "code", "reasoning"]
        ),
        "gpt-oss-20b": OSSModelInfo(
            name="gpt-oss-20b", parameters="20B",
            license=OSSLicense.APACHE_2_0, context_window=128_000,
            capabilities=["text-generation", "code"]
        ),
        "llama-4-maverick-17b-128e-instruct-fp8": OSSModelInfo(
            name="llama-4-maverick-17b", parameters="17B (128 Experts)",
            license=OSSLicense.LLAMA_LICENSE, context_window=1_000_000,
            capabilities=["text-generation", "multilingual"]
        ),
        "llama-4-scout-17b-16e-instruct": OSSModelInfo(
            name="llama-4-scout-17b", parameters="17B (16 Experts)",
            license=OSSLicense.LLAMA_LICENSE, context_window=10_000_000,
            capabilities=["text-generation", "multilingual", "long-context"]
        ),
    }

    @classmethod
    def list_models(cls) -> list[OSSModelInfo]:
        """ë“±ë¡ëœ ëª¨ë“  ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ëª©ë¡"""
        return list(cls._MODELS.values())

    @classmethod
    def get_model(cls, name: str) -> OSSModelInfo | None:
        """ëª¨ë¸ ì´ë¦„ìœ¼ë¡œ ì •ë³´ ì¡°íšŒ"""
        return cls._MODELS.get(name)

    @classmethod
    def register(cls, model: OSSModelInfo) -> None:
        """ì»¤ìŠ¤í…€ ëª¨ë¸ ë“±ë¡"""
        cls._MODELS[model.name] = model
        logger.info(f"[OpenWeightRegistry] ëª¨ë¸ ë“±ë¡: {model.name}")

class OpenWeightAdapter:
    """
    ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ ì–´ëŒ‘í„°

    ================================================================================
    ğŸ“‹ ì—­í• : ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ì„ OpenAI-compatible APIë¡œ í†µí•© ì‚¬ìš©
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================

    ì‚¬ìš© ì˜ˆì‹œ:
        >>> adapter = OpenWeightAdapter()
        >>> result = await adapter.generate(
        ...     model="gpt-oss-120b",
        ...     prompt="AI ì•„í‚¤í…ì²˜ ì„¤ê³„"
        ... )
    """

    def __init__(self, default_endpoint: str | None = None):
        self._default_endpoint = default_endpoint
        self._registry = OpenWeightRegistry()
        logger.info("[OpenWeightAdapter] ì´ˆê¸°í™”")

    def __repr__(self) -> str:
        return f"OpenWeightAdapter(models={len(self._registry.list_models())})"

    async def generate(
        self,
        model: str,
        prompt: str,
        config: OSSModelConfig | None = None
    ) -> dict[str, Any]:
        """
        ì˜¤í”ˆ ì›¨ì´íŠ¸ ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±

        OpenAI-compatible API í˜•ì‹ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.
        """
        cfg = config or OSSModelConfig()
        model_info = self._registry.get_model(model)

        logger.info(
            f"[OpenWeightAdapter] ìƒì„± ìš”ì²­: model={model}, "
            f"license={model_info.license.value if model_info else 'unknown'}"
        )

        return {
            "id": f"oss_{uuid.uuid4().hex[:12]}",
            "model": model,
            "output": f"[{model}] '{prompt}'ì— ëŒ€í•œ ì‘ë‹µ",
            "usage": {"prompt_tokens": len(prompt), "completion_tokens": cfg.max_tokens // 4},
        }
