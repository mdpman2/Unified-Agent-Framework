#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Agent Framework - Compaction ì‹œìŠ¤í…œ (Context Compaction Module)

================================================================================
ğŸ“ íŒŒì¼ ìœ„ì¹˜: unified_agent/compaction.py
ğŸ“‹ ì—­í• : ì»¨í…ìŠ¤íŠ¸ ì••ì¶•, Memory Flush, Cache-TTL Pruning
ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
================================================================================

ğŸ¯ ì£¼ìš” êµ¬ì„± ìš”ì†Œ:

    ğŸ“Œ Compaction (ì»¨í…ìŠ¤íŠ¸ ì••ì¶•):
        - ê¸´ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ì ˆì•½
        - ìë™/ìˆ˜ë™ íŠ¸ë¦¬ê±° ì§€ì›
        - ìš”ì•½ í›„ ë””ìŠ¤í¬ì— ì˜ì†

    ğŸ“Œ Memory Flush (ë©”ëª¨ë¦¬ í”ŒëŸ¬ì‹œ):
        - Compaction ì „ ì¤‘ìš” ì •ë³´ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥
        - ì •ë³´ ì†ì‹¤ ë°©ì§€
        - ì†Œí”„íŠ¸ ì„ê³„ê°’ ê¸°ë°˜ ìë™ íŠ¸ë¦¬ê±°

    ğŸ“Œ Cache-TTL Pruning (ìºì‹œ ì •ë¦¬):
        - ì˜¤ë˜ëœ ë„êµ¬ ê²°ê³¼ ì •ë¦¬
        - API ë¹„ìš© ìµœì í™”
        - Anthropic ìºì‹œ TTL í™œìš©

ğŸ”§ í•µì‹¬ ê¸°ëŠ¥:
    - ìë™ Compaction íŠ¸ë¦¬ê±° (ì»¨í…ìŠ¤íŠ¸ ë¦¬ë°‹ 75%)
    - Pre-compaction Memory Flush
    - ì†Œí”„íŠ¸/í•˜ë“œ íŠ¸ë¦¬ë°
    - JSONL ì„¸ì…˜ íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì €ì¥

ğŸ“Œ ì°¸ê³ :
    - Clawdbot Compaction: https://manthanguptaa.in/posts/clawdbot_memory/
"""

from __future__ import annotations

import os
import json
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Any, Callable
from enum import Enum

from .utils import StructuredLogger

__all__ = [
    # ì„¤ì •
    "CompactionConfig",
    "PruningConfig",
    "MemoryFlushConfig",
    # í•µì‹¬ í´ë˜ìŠ¤
    "ContextCompactor",
    "MemoryFlusher",
    "CacheTTLPruner",
    # ë§¤ë‹ˆì €
    "CompactionManager",
    # ëª¨ë¸
    "CompactionSummary",
    "PruningResult",
]

# ============================================================================
# Configuration
# ============================================================================

@dataclass(frozen=True, slots=True)
class CompactionConfig:
    """
    Compaction ì„¤ì •
    
    Args:
        context_window: ëª¨ë¸ì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° í¬ê¸° (tokens)
        reserve_tokens: ì¶œë ¥ìš© ì˜ˆì•½ í† í°
        trigger_threshold: Compaction íŠ¸ë¦¬ê±° ì„ê³„ê°’ (0.0 ~ 1.0)
        keep_recent_turns: ìµœê·¼ ìœ ì§€í•  í„´ ìˆ˜
        summary_max_tokens: ìš”ì•½ ìµœëŒ€ í† í° ìˆ˜
    """
    context_window: int = 200_000  # Claude: 200K, GPT-5: 1M
    reserve_tokens: int = 20_000   # ì¶œë ¥ìš© ì˜ˆì•½
    trigger_threshold: float = 0.75  # 75%ì—ì„œ íŠ¸ë¦¬ê±°
    keep_recent_turns: int = 10
    summary_max_tokens: int = 2000
    
    @property
    def trigger_tokens(self) -> int:
        """Compaction íŠ¸ë¦¬ê±° í† í° ìˆ˜"""
        return int((self.context_window - self.reserve_tokens) * self.trigger_threshold)

@dataclass(frozen=True, slots=True)
class MemoryFlushConfig:
    """
    Memory Flush ì„¤ì •
    
    Args:
        enabled: Memory Flush í™œì„±í™” ì—¬ë¶€
        soft_threshold_tokens: ì†Œí”„íŠ¸ ì„ê³„ê°’ (ì´ ì „ì— í”ŒëŸ¬ì‹œ)
        system_prompt: í”ŒëŸ¬ì‹œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        user_prompt: í”ŒëŸ¬ì‹œ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
    """
    enabled: bool = True
    soft_threshold_tokens: int = 4000  # trigger 4000 tokens ì „ì— í”ŒëŸ¬ì‹œ
    system_prompt: str = "Session nearing compaction. Store durable memories now."
    user_prompt: str = "Write lasting notes to memory/YYYY-MM-DD.md; reply NO_REPLY if nothing to store."

@dataclass(frozen=True, slots=True)
class PruningConfig:
    """
    Cache-TTL Pruning ì„¤ì •
    
    Args:
        mode: í”„ë£¨ë‹ ëª¨ë“œ ('always', 'cache-ttl', 'never')
        ttl_seconds: ìºì‹œ TTL (ì´ˆ)
        keep_last_assistants: ìµœê·¼ ìœ ì§€í•  ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ìˆ˜
        soft_trim_max_chars: ì†Œí”„íŠ¸ íŠ¸ë¦¬ë° ìµœëŒ€ ë¬¸ì ìˆ˜
        soft_trim_head_chars: ì†Œí”„íŠ¸ íŠ¸ë¦¬ë° í—¤ë“œ ë¬¸ì ìˆ˜
        soft_trim_tail_chars: ì†Œí”„íŠ¸ íŠ¸ë¦¬ë° í…Œì¼ ë¬¸ì ìˆ˜
        hard_clear_enabled: í•˜ë“œ í´ë¦¬ì–´ í™œì„±í™”
        hard_clear_placeholder: í•˜ë“œ í´ë¦¬ì–´ í”Œë ˆì´ìŠ¤í™€ë”
    """
    mode: str = "cache-ttl"  # 'always', 'cache-ttl', 'never'
    ttl_seconds: int = 300   # 5ë¶„ (Anthropic ìºì‹œ ê¸°ë³¸)
    keep_last_assistants: int = 3
    soft_trim_max_chars: int = 4000
    soft_trim_head_chars: int = 1500
    soft_trim_tail_chars: int = 1500
    hard_clear_enabled: bool = True
    hard_clear_placeholder: str = "[Old tool result content cleared]"

# ============================================================================
# Data Models
# ============================================================================

@dataclass(frozen=True, slots=True)
class CompactionSummary:
    """Compaction ìš”ì•½ ê²°ê³¼"""
    original_turns: int
    compacted_turns: int
    original_tokens: int
    summary_tokens: int
    summary_text: str
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    metadata: dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> dict[str, Any]:
        return {
            "original_turns": self.original_turns,
            "compacted_turns": self.compacted_turns,
            "original_tokens": self.original_tokens,
            "summary_tokens": self.summary_tokens,
            "summary_text": self.summary_text,
            "timestamp": self.timestamp.isoformat(),
            "metadata": self.metadata
        }

@dataclass(frozen=True, slots=True)
class PruningResult:
    """Pruning ê²°ê³¼"""
    pruned_count: int
    original_chars: int
    pruned_chars: int
    mode: str
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

# ============================================================================
# Message ì¸í„°í˜ì´ìŠ¤ (í”„ë ˆì„ì›Œí¬ í˜¸í™˜ìš©)
# ============================================================================

@dataclass(frozen=True, slots=True)
class ConversationTurn:
    """ëŒ€í™” í„´ (ë©”ì‹œì§€ + ë©”íƒ€ë°ì´í„°)"""
    role: str  # 'user', 'assistant', 'tool', 'system'
    content: str
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    token_count: int = 0
    tool_results: list[dict[str, Any]] = field(default_factory=list)
    metadata: dict[str, Any] = field(default_factory=dict)
    
    def estimate_tokens(self) -> int:
        """í† í° ìˆ˜ ì¶”ì • (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±: 4 chars â‰ˆ 1 token)"""
        if self.token_count > 0:
            return self.token_count
        return len(self.content) // 4 + sum(len(str(r)) // 4 for r in self.tool_results)

# ============================================================================
# Context Compactor
# ============================================================================

class ContextCompactor:
    """
    ì»¨í…ìŠ¤íŠ¸ ì••ì¶•ê¸°
    
    ê¸´ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ì ˆì•½:
    
    Before Compaction (180K / 200K tokens):
        [Turn 1-140] ... ë§ì€ ëŒ€í™” ...
        [Turn 141-150] ìµœê·¼ ëŒ€í™”
    
    After Compaction (45K / 200K tokens):
        [SUMMARY] "Built REST API with /users, /auth endpoints..."
        [Turn 141-150] ìµœê·¼ ëŒ€í™” ìœ ì§€
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> compactor = ContextCompactor(config, summarizer_func)
        >>> result = await compactor.compact(turns)
    """
    
    def __init__(
        self,
        config: CompactionConfig | None = None,
        summarizer: Callable[[list[ConversationTurn]], str] | None = None
    ):
        self.config = config or CompactionConfig()
        self._summarizer = summarizer
        self._logger = StructuredLogger("compactor")
    
    def set_summarizer(self, func: Callable[[list[ConversationTurn]], str]):
        """ìš”ì•½ í•¨ìˆ˜ ì„¤ì • (LLM í˜¸ì¶œ)"""
        self._summarizer = func
    
    def should_compact(self, turns: list[ConversationTurn]) -> bool:
        """Compaction í•„ìš” ì—¬ë¶€ í™•ì¸"""
        total_tokens = sum(t.estimate_tokens() for t in turns)
        return total_tokens >= self.config.trigger_tokens
    
    def get_compaction_point(self, turns: list[ConversationTurn]) -> int:
        """
        Compaction ë¶„ê¸°ì  ê³„ì‚°
        
        ìµœê·¼ keep_recent_turnsê°œëŠ” ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ë¥¼ ìš”ì•½
        """
        return max(0, len(turns) - self.config.keep_recent_turns)
    
    async def compact(
        self,
        turns: list[ConversationTurn],
        focus_hint: str | None = None
    ) -> tuple[list[ConversationTurn], CompactionSummary]:
        """
        ëŒ€í™” ì••ì¶• ìˆ˜í–‰
        
        Args:
            turns: ì „ì²´ ëŒ€í™” í„´ ë¦¬ìŠ¤íŠ¸
            focus_hint: ìš”ì•½ ì‹œ ì§‘ì¤‘í•  ë‚´ìš© íŒíŠ¸ (ì˜ˆ: "decisions and open questions")
        
        Returns:
            (ì••ì¶•ëœ í„´ ë¦¬ìŠ¤íŠ¸, ìš”ì•½ ì •ë³´)
        """
        if not self._summarizer:
            raise ValueError("Summarizer function not set. Call set_summarizer() first.")
        
        compaction_point = self.get_compaction_point(turns)
        
        if compaction_point == 0:
            self._logger.info("Nothing to compact")
            return turns, CompactionSummary(
                original_turns=len(turns),
                compacted_turns=len(turns),
                original_tokens=sum(t.estimate_tokens() for t in turns),
                summary_tokens=0,
                summary_text=""
            )
        
        # ìš”ì•½í•  í„´ê³¼ ìœ ì§€í•  í„´ ë¶„ë¦¬
        turns_to_summarize = turns[:compaction_point]
        turns_to_keep = turns[compaction_point:]
        
        original_tokens = sum(t.estimate_tokens() for t in turns_to_summarize)
        
        # LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±
        self._logger.info(
            f"Compacting {len(turns_to_summarize)} turns",
            original_tokens=original_tokens
        )
        
        summary_text = await self._summarizer(turns_to_summarize)
        
        # ìš”ì•½ í„´ ìƒì„±
        summary_turn = ConversationTurn(
            role="system",
            content=f"[COMPACTION SUMMARY]\n{summary_text}",
            metadata={"type": "compaction_summary", "original_turns": len(turns_to_summarize)}
        )
        
        # ê²°ê³¼ ì¡°í•©
        compacted_turns = [summary_turn] + turns_to_keep
        
        summary = CompactionSummary(
            original_turns=len(turns),
            compacted_turns=len(compacted_turns),
            original_tokens=original_tokens,
            summary_tokens=summary_turn.estimate_tokens(),
            summary_text=summary_text,
            metadata={"focus_hint": focus_hint} if focus_hint else {}
        )
        
        self._logger.info(
            f"Compaction complete",
            original_turns=summary.original_turns,
            compacted_turns=summary.compacted_turns,
            saved_tokens=original_tokens - summary.summary_tokens
        )
        
        return compacted_turns, summary

# ============================================================================
# Memory Flusher
# ============================================================================

class MemoryFlusher:
    """
    Pre-Compaction Memory Flush
    
    Compaction ì „ì— ì¤‘ìš” ì •ë³´ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥í•˜ì—¬ ì •ë³´ ì†ì‹¤ ë°©ì§€:
    
    1. ì»¨í…ìŠ¤íŠ¸ê°€ ì†Œí”„íŠ¸ ì„ê³„ê°’ì— ë„ë‹¬
    2. ì—ì´ì „íŠ¸ì—ê²Œ ì¤‘ìš” ì •ë³´ ì €ì¥ ìš”ì²­ (silent turn)
    3. ì—ì´ì „íŠ¸ê°€ memory/YYYY-MM-DD.mdì— ê¸°ë¡
    4. Compaction ì§„í–‰ (ì •ë³´ ì•ˆì „)
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> flusher = MemoryFlusher(config, memory_system)
        >>> if flusher.should_flush(current_tokens):
        ...     await flusher.flush(agent, turns)
    """
    
    def __init__(
        self,
        config: MemoryFlushConfig | None = None,
        compaction_config: CompactionConfig | None = None,
        memory_write_func: Callable[[str], None] | None = None
    ):
        self.config = config or MemoryFlushConfig()
        self.compaction_config = compaction_config or CompactionConfig()
        self._memory_write = memory_write_func
        self._logger = StructuredLogger("memory_flusher")
        self._last_flush_tokens = 0
    
    def set_memory_writer(self, func: Callable[[str], None]):
        """ë©”ëª¨ë¦¬ ì“°ê¸° í•¨ìˆ˜ ì„¤ì •"""
        self._memory_write = func
    
    def should_flush(self, current_tokens: int) -> bool:
        """
        Memory Flush í•„ìš” ì—¬ë¶€ í™•ì¸
        
        Compaction íŠ¸ë¦¬ê±° ì „ soft_threshold_tokens ì§€ì ì—ì„œ í”ŒëŸ¬ì‹œ
        """
        if not self.config.enabled:
            return False
        
        flush_threshold = (
            self.compaction_config.trigger_tokens - 
            self.config.soft_threshold_tokens
        )
        
        # ì´ë¯¸ ì´ í† í° ìˆ˜ì—ì„œ í”ŒëŸ¬ì‹œí–ˆìœ¼ë©´ ìŠ¤í‚µ
        if current_tokens <= self._last_flush_tokens:
            return False
        
        return current_tokens >= flush_threshold
    
    def get_flush_prompt(self) -> tuple[str, str]:
        """í”ŒëŸ¬ì‹œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (system, user)"""
        return self.config.system_prompt, self.config.user_prompt
    
    async def flush(
        self,
        agent_response_func: Callable[[str, str], str],
        turns: list[ConversationTurn]
    ) -> str | None:
        """
        Memory Flush ìˆ˜í–‰
        
        Args:
            agent_response_func: ì—ì´ì „íŠ¸ ì‘ë‹µ í•¨ìˆ˜ (system_prompt, user_prompt) -> response
            turns: í˜„ì¬ ëŒ€í™” í„´
        
        Returns:
            ì—ì´ì „íŠ¸ ì‘ë‹µ ë˜ëŠ” None (NO_REPLYì¸ ê²½ìš°)
        """
        self._logger.info("Initiating pre-compaction memory flush")
        
        system_prompt, user_prompt = self.get_flush_prompt()
        
        # ì—ì´ì „íŠ¸ì—ê²Œ í”ŒëŸ¬ì‹œ ìš”ì²­ (silent turn - ì‚¬ìš©ìì—ê²Œ ë³´ì´ì§€ ì•ŠìŒ)
        response = await agent_response_func(system_prompt, user_prompt)
        
        current_tokens = sum(t.estimate_tokens() for t in turns)
        self._last_flush_tokens = current_tokens
        
        if response.strip().upper() == "NO_REPLY":
            self._logger.info("Agent had nothing to flush")
            return None
        
        self._logger.info("Memory flush complete", response_length=len(response))
        return response

# ============================================================================
# Cache-TTL Pruner
# ============================================================================

class CacheTTLPruner:
    """
    Cache-TTL ê¸°ë°˜ ë„êµ¬ ê²°ê³¼ ì •ë¦¬
    
    Anthropicì€ í”„ë¡¬í”„íŠ¸ í”„ë¦¬í”½ìŠ¤ë¥¼ 5ë¶„ê°„ ìºì‹±:
    - TTL ë‚´: ìºì‹œëœ í† í° 90% í• ì¸
    - TTL í›„: ì „ì²´ ì¬ìºì‹± í•„ìš”
    
    TTL ë§Œë£Œ í›„ ì˜¤ë˜ëœ ë„êµ¬ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ì—¬ ë¹„ìš© ì ˆê°:
    
    Before Pruning:
        [Tool Result (exec): 50,000 chars of npm output]
        [Tool Result (read): Large config, 10,000 chars]
        [User: "What happened?"]
    
    After Pruning:
        [Tool Result (exec): "npm WARN...[truncated]...installed."]
        [Tool Result (read): "[Old tool result content cleared]"]
        [User: "What happened?"]
    
    JSONL ì›ë³¸ì€ ë³´ì¡´ë¨
    """
    
    def __init__(self, config: PruningConfig | None = None):
        self.config = config or PruningConfig()
        self._logger = StructuredLogger("pruner")
        self._last_cache_time: datetime | None = None
    
    def record_cache_time(self):
        """ìºì‹œ ì‹œê°„ ê¸°ë¡"""
        self._last_cache_time = datetime.now(timezone.utc)
    
    def is_cache_expired(self) -> bool:
        """ìºì‹œ ë§Œë£Œ ì—¬ë¶€ í™•ì¸"""
        if self._last_cache_time is None:
            return True
        
        elapsed = (datetime.now(timezone.utc) - self._last_cache_time).total_seconds()
        return elapsed > self.config.ttl_seconds
    
    def should_prune(self) -> bool:
        """Pruning í•„ìš” ì—¬ë¶€ í™•ì¸"""
        if self.config.mode == "never":
            return False
        if self.config.mode == "always":
            return True
        # cache-ttl ëª¨ë“œ
        return self.is_cache_expired()
    
    def _soft_trim(self, content: str) -> str:
        """ì†Œí”„íŠ¸ íŠ¸ë¦¬ë°: ì•ë’¤ë§Œ ìœ ì§€í•˜ê³  ì¤‘ê°„ ìƒëµ"""
        if len(content) <= self.config.soft_trim_max_chars:
            return content
        
        head = content[:self.config.soft_trim_head_chars]
        tail = content[-self.config.soft_trim_tail_chars:]
        
        return f"{head}\n...[truncated]...\n{tail}"
    
    def _hard_clear(self, content: str) -> str:
        """í•˜ë“œ í´ë¦¬ì–´: í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ëŒ€ì²´"""
        return self.config.hard_clear_placeholder
    
    def prune_turns(
        self,
        turns: list[ConversationTurn],
        in_place: bool = False
    ) -> tuple[list[ConversationTurn], PruningResult]:
        """
        ë„êµ¬ ê²°ê³¼ ì •ë¦¬
        
        Args:
            turns: ëŒ€í™” í„´ ë¦¬ìŠ¤íŠ¸
            in_place: Trueë©´ ì›ë³¸ ìˆ˜ì •, Falseë©´ ë³µì‚¬ë³¸ ë°˜í™˜
        
        Returns:
            (ì •ë¦¬ëœ í„´ ë¦¬ìŠ¤íŠ¸, ì •ë¦¬ ê²°ê³¼)
        """
        if not self.should_prune():
            return turns, PruningResult(
                pruned_count=0,
                original_chars=0,
                pruned_chars=0,
                mode=self.config.mode
            )
        
        result_turns = turns if in_place else [
            ConversationTurn(
                role=t.role,
                content=t.content,
                timestamp=t.timestamp,
                token_count=t.token_count,
                tool_results=t.tool_results.copy(),
                metadata=t.metadata.copy()
            ) for t in turns
        ]
        
        # ìµœê·¼ Nê°œ ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¸ë±ìŠ¤ ì°¾ê¸°
        assistant_indices = [
            i for i, t in enumerate(result_turns)
            if t.role == "assistant"
        ]
        protected_from = (
            assistant_indices[-self.config.keep_last_assistants]
            if len(assistant_indices) >= self.config.keep_last_assistants
            else 0
        )
        
        pruned_count = 0
        original_chars = 0
        pruned_chars = 0
        
        for i, turn in enumerate(result_turns):
            if i >= protected_from:
                continue  # ìµœê·¼ í„´ì€ ë³´í˜¸
            
            # ë„êµ¬ ê²°ê³¼ ì •ë¦¬
            if turn.tool_results:
                for j, tool_result in enumerate(turn.tool_results):
                    if 'content' in tool_result:
                        original = str(tool_result['content'])
                        original_chars += len(original)
                        
                        if self.config.hard_clear_enabled and len(original) > self.config.soft_trim_max_chars * 2:
                            turn.tool_results[j]['content'] = self._hard_clear(original)
                        else:
                            turn.tool_results[j]['content'] = self._soft_trim(original)
                        
                        pruned_chars += len(str(turn.tool_results[j]['content']))
                        pruned_count += 1
        
        result = PruningResult(
            pruned_count=pruned_count,
            original_chars=original_chars,
            pruned_chars=pruned_chars,
            mode=self.config.mode
        )
        
        if pruned_count > 0:
            self._logger.info(
                f"Pruned {pruned_count} tool results",
                saved_chars=original_chars - pruned_chars
            )
        
        return result_turns, result

# ============================================================================
# Compaction Manager (í†µí•© ê´€ë¦¬)
# ============================================================================

class CompactionManager:
    """
    Compaction í†µí•© ê´€ë¦¬ì
    
    Memory Flush + Compaction + Pruningì„ ì¡°ìœ¨:
    
    1. ì»¨í…ìŠ¤íŠ¸ ëª¨ë‹ˆí„°ë§
    2. ì†Œí”„íŠ¸ ì„ê³„ê°’ â†’ Memory Flush
    3. í•˜ë“œ ì„ê³„ê°’ â†’ Compaction
    4. ìºì‹œ ë§Œë£Œ â†’ Pruning
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> manager = CompactionManager(
        ...     compaction_config=CompactionConfig(context_window=200000),
        ...     flush_config=MemoryFlushConfig(enabled=True),
        ...     pruning_config=PruningConfig(mode="cache-ttl")
        ... )
        >>> manager.set_summarizer(llm_summarize)
        >>> manager.set_memory_writer(memory.add_daily_note)
        >>> 
        >>> # ë§¤ í„´ë§ˆë‹¤ í˜¸ì¶œ
        >>> turns = await manager.process_turns(turns, agent_respond)
    """
    
    def __init__(
        self,
        compaction_config: CompactionConfig | None = None,
        flush_config: MemoryFlushConfig | None = None,
        pruning_config: PruningConfig | None = None,
        transcript_dir: str | None = None
    ):
        self.compaction_config = compaction_config or CompactionConfig()
        self.flush_config = flush_config or MemoryFlushConfig()
        self.pruning_config = pruning_config or PruningConfig()
        
        self.compactor = ContextCompactor(self.compaction_config)
        self.flusher = MemoryFlusher(self.flush_config, self.compaction_config)
        self.pruner = CacheTTLPruner(self.pruning_config)
        
        self.transcript_dir = Path(transcript_dir) if transcript_dir else None
        self._logger = StructuredLogger("compaction_manager")
        
        # í†µê³„
        self.stats = {
            "compactions": 0,
            "flushes": 0,
            "prunes": 0,
            "total_tokens_saved": 0
        }
    
    def set_summarizer(self, func: Callable[[list[ConversationTurn]], str]):
        """ìš”ì•½ í•¨ìˆ˜ ì„¤ì •"""
        self.compactor.set_summarizer(func)
    
    def set_memory_writer(self, func: Callable[[str], None]):
        """ë©”ëª¨ë¦¬ ì“°ê¸° í•¨ìˆ˜ ì„¤ì •"""
        self.flusher.set_memory_writer(func)
    
    def get_current_tokens(self, turns: list[ConversationTurn]) -> int:
        """í˜„ì¬ í† í° ìˆ˜ ê³„ì‚°"""
        return sum(t.estimate_tokens() for t in turns)
    
    async def process_turns(
        self,
        turns: list[ConversationTurn],
        agent_respond_func: Callable[[str, str], str] | None = None
    ) -> list[ConversationTurn]:
        """
        í„´ ì²˜ë¦¬ (í•„ìš”ì‹œ Flush/Compaction/Pruning ìˆ˜í–‰)
        
        Args:
            turns: í˜„ì¬ ëŒ€í™” í„´ ë¦¬ìŠ¤íŠ¸
            agent_respond_func: ì—ì´ì „íŠ¸ ì‘ë‹µ í•¨ìˆ˜ (Memory Flushìš©)
        
        Returns:
            ì²˜ë¦¬ëœ í„´ ë¦¬ìŠ¤íŠ¸
        """
        current_tokens = self.get_current_tokens(turns)
        
        # 1. Pruning ì²´í¬
        if self.pruner.should_prune():
            turns, prune_result = self.pruner.prune_turns(turns)
            if prune_result.pruned_count > 0:
                self.stats["prunes"] += 1
        
        # 2. Memory Flush ì²´í¬ (Compaction ì „)
        if agent_respond_func and self.flusher.should_flush(current_tokens):
            await self.flusher.flush(agent_respond_func, turns)
            self.stats["flushes"] += 1
        
        # 3. Compaction ì²´í¬
        if self.compactor.should_compact(turns):
            turns, summary = await self.compactor.compact(turns)
            self.stats["compactions"] += 1
            self.stats["total_tokens_saved"] += (summary.original_tokens - summary.summary_tokens)
            
            # íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ ì €ì¥
            if self.transcript_dir:
                await self._save_transcript(summary)
        
        return turns
    
    async def force_compact(
        self,
        turns: list[ConversationTurn],
        focus_hint: str | None = None
    ) -> tuple[list[ConversationTurn], CompactionSummary]:
        """
        ê°•ì œ Compaction (ìˆ˜ë™ /compact ëª…ë ¹)
        
        Args:
            turns: ëŒ€í™” í„´ ë¦¬ìŠ¤íŠ¸
            focus_hint: ì§‘ì¤‘í•  ë‚´ìš© íŒíŠ¸
        
        Returns:
            (ì••ì¶•ëœ í„´ ë¦¬ìŠ¤íŠ¸, ìš”ì•½)
        """
        turns, summary = await self.compactor.compact(turns, focus_hint)
        self.stats["compactions"] += 1
        
        if self.transcript_dir:
            await self._save_transcript(summary)
        
        return turns, summary
    
    async def _save_transcript(self, summary: CompactionSummary):
        """Compaction ìš”ì•½ì„ JSONL íŠ¸ëœìŠ¤í¬ë¦½íŠ¸ë¡œ ì €ì¥"""
        if not self.transcript_dir:
            return
        
        self.transcript_dir.mkdir(parents=True, exist_ok=True)
        
        transcript_file = self.transcript_dir / f"compaction_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl"
        
        with open(transcript_file, 'a', encoding='utf-8') as f:
            f.write(json.dumps(summary.to_dict(), ensure_ascii=False) + "\n")
        
        self._logger.info("Transcript saved", file=str(transcript_file))
    
    def get_stats(self) -> dict[str, Any]:
        """í†µê³„ ë°˜í™˜"""
        return {
            **self.stats,
            "cache_expired": self.pruner.is_cache_expired()
        }
    
    def record_api_call(self):
        """API í˜¸ì¶œ ê¸°ë¡ (ìºì‹œ íƒ€ì´ë¨¸ ë¦¬ì…‹)"""
        self.pruner.record_cache_time()
