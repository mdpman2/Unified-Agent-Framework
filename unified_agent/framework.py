#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Agent Framework - í”„ë ˆì„ì›Œí¬ ë©”ì¸ ëª¨ë“ˆ

UnifiedAgentFramework í´ë˜ìŠ¤ ë° ë°ëª¨/ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
"""

from __future__ import annotations

import asyncio
import json
import time
import logging
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Callable, TYPE_CHECKING

from opentelemetry import trace

from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion

from .config import (
    FrameworkConfig, DEFAULT_LLM_MODEL, SUPPORTED_MODELS,
    supports_temperature, create_execution_settings
)
from .exceptions import ConfigurationError
from .models import (
    AgentRole, AgentState, ExecutionStatus, ApprovalStatus,
    TeamConfiguration, TeamAgent, PlanStep, MPlan, PlanStepStatus,
    WebSocketMessageType, StreamingMessage, RAICategory
)
from .memory import MemoryStore, CachedMemoryStore, StateManager
from .events import EventType, EventBus, AgentEvent
from .skills import SkillManager
from .tools import MCPTool
from .agents import SimpleAgent, RouterAgent, SupervisorAgent, ProxyAgent
from .workflow import Node, Graph
from .orchestration import OrchestrationManager, AgentFactory
from .utils import StructuredLogger, RAIValidator, setup_telemetry

# v3.3 Agent Lightning í†µí•©
from .tracer import AgentTracer, SpanKind, get_tracer, set_tracer
from .hooks import HookManager, HookEvent, get_hook_manager, set_hook_manager
from .reward import emit_reward, RewardManager

# v3.4 Extensions í†µí•©
from .extensions import Extensions, ExtensionsConfig

# v4.0 í•µì‹¬ ëª¨ë“ˆ (ì§€ì—° ì„í¬íŠ¸ ì•„ë‹Œ ì§ì ‘ ì„í¬íŠ¸ â€” TYPE_CHECKING ë¶ˆí•„ìš”)
from .responses_api import ResponsesClient, ConversationState
from .video_generation import VideoGenerator, VideoConfig
from .image_generation import ImageGenerator, ImageConfig
from .open_weight import OpenWeightAdapter, OSSModelConfig
from .universal_bridge import UniversalAgentBridge, BridgeProtocol

# v4.0 í”„ë ˆì„ì›Œí¬ ë¸Œë¦¿ì§€ (ì§€ì—° ì„í¬íŠ¸ â€” get_bridge()ì—ì„œ ë¡œë“œ)

__all__ = [
    "UnifiedAgentFramework",
    "quick_run",
    "create_framework",
]

# ê¸°ë³¸ ìŠ¤í‚¬ ë””ë ‰í† ë¦¬
BUILTIN_SKILLS_DIR = Path(__file__).parent.parent / "skills"

# ============================================================================
# UnifiedAgentFramework - í†µí•© ì—ì´ì „íŠ¸ í”„ë ˆì„ì›Œí¬
# ============================================================================

class UnifiedAgentFramework:
    """
    í†µí•© Agent í”„ë ˆì„ì›Œí¬ - Enterprise Edition

    ê°„í¸í•œ ì‚¬ìš©ë²•:
        # 1. ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²• (í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ)
        framework = UnifiedAgentFramework.create()

        # 2. ì„¤ì • ê°ì²´ ì‚¬ìš©
        config = FrameworkConfig.from_env()
        framework = UnifiedAgentFramework.create(config)

        # 3. ë¹ ë¥¸ ì§ˆì˜ì‘ë‹µ
        response = await framework.quick_chat("ì•ˆë…•í•˜ì„¸ìš”!")

        # 4. ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        state = await framework.run("session-1", "simple_chat", "ì§ˆë¬¸ì…ë‹ˆë‹¤")

        # 5. Skills ê¸°ë°˜ ì—ì´ì „íŠ¸
        agent = framework.create_skilled_agent("coder", skills=["python-expert"])

    ì£¼ìš” ê¸°ëŠ¥:
    - MCP ë„êµ¬ ê´€ë¦¬
    - ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ (Pub-Sub)
    - ì „ì—­ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    - ì²´í¬í¬ì¸íŠ¸ ë° ë¡¤ë°±
    - Human-in-the-loop ìŠ¹ì¸
    - Skills ì‹œìŠ¤í…œ (Anthropic íŒ¨í„´)
    """

    def __init__(
        self,
        kernel: Kernel,
        config: FrameworkConfig | None = None,
        memory_store: MemoryStore | None = None,
        checkpoint_dir: str = "./checkpoints",
        enable_telemetry: bool = True,
        enable_events: bool = True,
        skill_dirs: list[str] | None = None,
        load_builtin_skills: bool = True,
        extensions_config: ExtensionsConfig | None = None,
    ):
        """
        í”„ë ˆì„ì›Œí¬ ì´ˆê¸°í™”

        Args:
            kernel: Semantic Kernel ì¸ìŠ¤í„´ìŠ¤
            config: í”„ë ˆì„ì›Œí¬ ì„¤ì •
            memory_store: ë©”ëª¨ë¦¬ ì €ì¥ì†Œ
            checkpoint_dir: ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
            enable_telemetry: í…”ë ˆë©”íŠ¸ë¦¬ í™œì„±í™” ì—¬ë¶€
            enable_events: ì´ë²¤íŠ¸ ì‹œìŠ¤í…œ í™œì„±í™” ì—¬ë¶€
            skill_dirs: ìŠ¤í‚¬ ë””ë ‰í† ë¦¬ ëª©ë¡
            load_builtin_skills: ê¸°ë³¸ ìŠ¤í‚¬ ë¡œë“œ ì—¬ë¶€
            extensions_config: v3.4 í™•ì¥ ëª¨ë“ˆ ì„¤ì •
        """
        self.kernel = kernel
        self.config = config or FrameworkConfig()
        self.memory_store = memory_store or CachedMemoryStore(max_cache_size=self.config.max_cache_size)
        self.state_manager = StateManager(self.memory_store, checkpoint_dir)
        self.graphs: dict[str, Graph] = {}
        self.mcp_tools: dict[str, MCPTool] = {}
        self.event_bus = EventBus() if enable_events else None

        # Skills ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.skill_manager = SkillManager(skill_dirs)
        if load_builtin_skills:
            self._load_builtin_skills()

        # v3.3 Agent Lightning í†µí•©
        self.agent_tracer = AgentTracer(name="unified-agent-framework")
        set_tracer(self.agent_tracer)
        
        # v3.3 Hook Manager í†µí•©
        self.hook_manager = HookManager()
        set_hook_manager(self.hook_manager)
        
        # v3.3 Reward Manager í†µí•©
        self.reward_manager = RewardManager()
        
        # v3.4 Extensions í†µí•© (Prompt Cache, Durable, Concurrent, AgentTool, Thinking, MCP)
        self.extensions = Extensions(
            framework=self,
            config=extensions_config or ExtensionsConfig()
        )

        if enable_telemetry:
            self.tracer = trace.get_tracer(__name__)
        else:
            self.tracer = None

        self.global_metrics = {
            "total_workflows": 0,
            "total_executions": 0,
            "total_failures": 0,
            "start_time": datetime.now(timezone.utc).isoformat()
        }

    def _load_builtin_skills(self):
        """ê¸°ë³¸ ì œê³µ ìŠ¤í‚¬ ë¡œë“œ (SKILL.md íŒŒì¼ ê¸°ë°˜)"""
        if BUILTIN_SKILLS_DIR.exists():
            loaded = self.skill_manager.load_skills_from_directory(str(BUILTIN_SKILLS_DIR))
            logging.info(f"ğŸ“š SKILL.md ê¸°ë°˜ ìŠ¤í‚¬ {loaded}ê°œ ë¡œë“œ ì™„ë£Œ (from {BUILTIN_SKILLS_DIR})")
        else:
            logging.warning(f"âš ï¸ ê¸°ë³¸ ìŠ¤í‚¬ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {BUILTIN_SKILLS_DIR}")
            logging.info("ğŸ’¡ 'skills' ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•˜ê³  SKILL.md íŒŒì¼ì„ ì¶”ê°€í•˜ì„¸ìš”.")

    def _create_kernel(self) -> Kernel:
        """Kernel ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ë‚´ë¶€ ë©”ì„œë“œ)"""
        kernel = Kernel()
        chat_service = AzureChatCompletion(
            deployment_name=self.config.deployment_name,
            api_key=self.config.api_key,
            endpoint=self.config.endpoint,
            service_id=self.config.deployment_name,
            api_version=self.config.api_version
        )
        kernel.add_service(chat_service)
        return kernel

    @classmethod
    def create(
        cls,
        config: FrameworkConfig | None = None,
        skill_dirs: list[str] | None = None,
        load_builtin_skills: bool = True,
        extensions_config: ExtensionsConfig | None = None,
    ) -> 'UnifiedAgentFramework':
        """
        í”„ë ˆì„ì›Œí¬ ê°„í¸ ìƒì„± (ê¶Œì¥)

        ì‚¬ìš©ë²•:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ë¡œë“œ
            framework = UnifiedAgentFramework.create()

            # ì»¤ìŠ¤í…€ ì„¤ì • + ìŠ¤í‚¬ ë””ë ‰í† ë¦¬
            framework = UnifiedAgentFramework.create(
                skill_dirs=["./my_skills", "./team_skills"]
            )
            
            # v3.4 í™•ì¥ ëª¨ë“ˆ ì„¤ì •
            framework = UnifiedAgentFramework.create(
                extensions_config=ExtensionsConfig(
                    enable_cache=True,
                    enable_mcp=True
                )
            )
        """
        if config is None:
            config = FrameworkConfig.from_env()

        config.validate()

        # Kernel ì´ˆê¸°í™”
        kernel = Kernel()
        chat_service = AzureChatCompletion(
            deployment_name=config.deployment_name,
            api_key=config.api_key,
            endpoint=config.endpoint,
            service_id=config.deployment_name,
            api_version=config.api_version
        )
        kernel.add_service(chat_service)

        return cls(
            kernel=kernel,
            config=config,
            checkpoint_dir=config.checkpoint_dir,
            enable_telemetry=config.enable_telemetry,
            enable_events=config.enable_events,
            skill_dirs=skill_dirs,
            load_builtin_skills=load_builtin_skills,
            extensions_config=extensions_config,
        )

    async def quick_chat(self, message: str, system_prompt: str = "You are a helpful assistant.") -> str:
        """
        ë¹ ë¥¸ ì§ˆì˜ì‘ë‹µ (ì›Œí¬í”Œë¡œìš° ì—†ì´)

        ì‚¬ìš©ë²•:
            response = await framework.quick_chat("íŒŒì´ì¬ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?")
            print(response)
        """
        # v3.3: ìë™ ì¶”ì  ì‹œì‘
        with self.agent_tracer.span("quick_chat", SpanKind.WORKFLOW) as span:
            span.set_attribute("user.message", message[:100])  # ì²˜ìŒ 100ìë§Œ
            
            # v3.3: Hook ì´ë²¤íŠ¸ ë°œí–‰
            await self.hook_manager.emit(HookEvent.TRACE_START, {"message": message})
            
            if "_quick_chat" not in self.graphs:
                self.create_simple_workflow("_quick_chat", system_prompt)

            session_id = f"quick-{int(time.time())}"
            state = await self.run(session_id, "_quick_chat", message)

            response = ""
            for msg in reversed(state.messages):
                if msg.role == AgentRole.ASSISTANT:
                    response = msg.content
                    break
            
            # v3.3: ì‘ë‹µ ì •ë³´ ì¶”ì 
            span.set_attribute("response.length", len(response))
            
            # v3.3: Hook ì´ë²¤íŠ¸ ë°œí–‰
            await self.hook_manager.emit(HookEvent.TRACE_END, {"response_length": len(response)})
            
            return response

    def create_simple_workflow(self, name: str, system_prompt: str = "You are a helpful assistant.") -> Graph:
        """ê°„ë‹¨í•œ ëŒ€í™” ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        graph = self.create_graph(name)

        agent = SimpleAgent(
            name="assistant",
            system_prompt=system_prompt,
            model=self.config.model,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens,
            enable_streaming=self.config.enable_streaming,
            event_bus=self.event_bus,
            service_id=self.config.deployment_name
        )

        graph.add_node(Node("assistant", agent))
        graph.set_start("assistant")
        graph.set_end("assistant")

        return graph

    def create_router_workflow(self, name: str, routes: dict[str, dict[str, str]]) -> Graph:
        """ë¼ìš°íŒ… ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        graph = self.create_graph(name)

        router = RouterAgent(
            name="router",
            system_prompt="Classify user intent accurately.",
            model=self.config.model,
            routes={k: f"{k}_agent" for k in routes.keys()},
            event_bus=self.event_bus,
            service_id=self.config.deployment_name
        )
        graph.add_node(Node("router", router))
        graph.set_start("router")

        for route_name, route_config in routes.items():
            agent = SimpleAgent(
                name=f"{route_name}_agent",
                system_prompt=route_config.get("prompt", f"You handle {route_name} inquiries."),
                model=self.config.model,
                event_bus=self.event_bus,
                service_id=self.config.deployment_name
            )
            graph.add_node(Node(f"{route_name}_agent", agent))
            graph.set_end(f"{route_name}_agent")

        return graph

    def create_skilled_agent(
        self,
        name: str,
        skills: list[str] | None = None,
        base_prompt: str = "",
        auto_detect_skills: bool = True
    ) -> SimpleAgent:
        """Skills ê¸°ë°˜ ì—ì´ì „íŠ¸ ìƒì„±"""
        skill_objects = []
        if skills:
            for skill_name in skills:
                skill = self.skill_manager.get_skill(skill_name)
                if skill:
                    skill_objects.append(skill)
                else:
                    logging.warning(f"ìŠ¤í‚¬ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {skill_name}")

        system_prompt = self.skill_manager.build_system_prompt(
            skill_objects,
            base_prompt=base_prompt,
            include_full=True
        )

        agent = SimpleAgent(
            name=name,
            system_prompt=system_prompt,
            model=self.config.model,
            temperature=self.config.temperature,
            max_tokens=self.config.max_tokens,
            enable_streaming=self.config.enable_streaming,
            event_bus=self.event_bus,
            service_id=self.config.deployment_name
        )

        agent._auto_detect_skills = auto_detect_skills
        agent._skill_manager = self.skill_manager

        return agent

    def create_skill_workflow(
        self,
        name: str,
        skills: list[str],
        base_prompt: str = "You are a helpful assistant."
    ) -> Graph:
        """Skills ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        graph = self.create_graph(name)

        agent = self.create_skilled_agent(
            name="skilled_assistant",
            skills=skills,
            base_prompt=base_prompt
        )

        graph.add_node(Node("skilled_assistant", agent))
        graph.set_start("skilled_assistant")
        graph.set_end("skilled_assistant")

        return graph

    async def smart_chat(
        self,
        message: str,
        base_prompt: str = "You are a helpful assistant.",
        max_skills: int = 2
    ) -> str:
        """ìŠ¤ë§ˆíŠ¸ ì§ˆì˜ì‘ë‹µ - ì¿¼ë¦¬ì— ë§ëŠ” ìŠ¤í‚¬ ìë™ í™œì„±í™”"""
        matched_skills = self.skill_manager.match_skills(
            message,
            threshold=0.2,
            max_skills=max_skills
        )

        if matched_skills:
            skill_names = [s.name for s in matched_skills]
            logging.info(f"ğŸ¯ ë§¤ì¹­ëœ ìŠ¤í‚¬: {', '.join(skill_names)}")

        workflow_name = f"_smart_chat_{int(time.time())}"
        self.create_skill_workflow(
            workflow_name,
            skills=[s.name for s in matched_skills],
            base_prompt=base_prompt
        )

        session_id = f"smart-{int(time.time())}"
        state = await self.run(session_id, workflow_name, message)

        for msg in reversed(state.messages):
            if msg.role == AgentRole.ASSISTANT:
                return msg.content
        return ""

    def create_team_workflow(
        self,
        team_config: TeamConfiguration,
        name: str | None = None
    ) -> Graph:
        """Team ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ìƒì„± (Microsoft Pattern)"""
        workflow_name = name or f"team_{team_config.name}"
        graph = self.create_graph(workflow_name)

        factory = AgentFactory(framework=self)
        agents = factory.create_team(team_config)

        if team_config.orchestration_mode == "supervisor":
            supervisor = SupervisorAgent(
                name="team_supervisor",
                system_prompt=f"You supervise the {team_config.name} team. {team_config.description}",
                model=self.config.model,
                sub_agents=list(agents.values()),
                max_rounds=team_config.max_rounds,
                event_bus=self.event_bus,
                service_id=self.config.deployment_name
            )
            graph.add_node(Node("team_supervisor", supervisor))
            graph.set_start("team_supervisor")
            graph.set_end("team_supervisor")

        elif team_config.orchestration_mode == "sequential":
            agent_list = list(agents.items())
            for i, (agent_name, agent) in enumerate(agent_list):
                node = Node(agent_name, agent)
                graph.add_node(node)

                if i == 0:
                    graph.set_start(agent_name)
                if i == len(agent_list) - 1:
                    graph.set_end(agent_name)
                if i > 0:
                    prev_name = agent_list[i-1][0]
                    graph.add_edge(prev_name, agent_name)

        else:
            first_agent = list(agents.values())[0] if agents else None
            if first_agent:
                graph.add_node(Node(first_agent.name, first_agent))
                graph.set_start(first_agent.name)
                graph.set_end(first_agent.name)

        return graph

    def create_orchestration_manager(
        self,
        team_config: TeamConfiguration,
        require_plan_approval: bool = False,
        ws_callback: Callable | None = None
    ) -> OrchestrationManager:
        """OrchestrationManager ìƒì„± (Microsoft Pattern)"""
        return OrchestrationManager(
            team_config=team_config,
            framework=self,
            kernel=self.kernel,
            require_plan_approval=require_plan_approval,
            rai_validator=RAIValidator(),
            ws_callback=ws_callback
        )

    def create_agent_factory(self) -> AgentFactory:
        """AgentFactory ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        return AgentFactory(framework=self)

    def create_proxy_agent(
        self,
        name: str = "clarifier",
        clarification_callback: Callable | None = None
    ) -> ProxyAgent:
        """ProxyAgent ìƒì„± (Microsoft Pattern)"""
        return ProxyAgent(
            name=name,
            system_prompt="You help clarify user requests when needed.",
            model=self.config.model,
            event_bus=self.event_bus,
            service_id=self.config.deployment_name,
            clarification_callback=clarification_callback
        )

    def create_rai_validator(self, strict_mode: bool = False) -> RAIValidator:
        """RAI ê²€ì¦ê¸° ìƒì„±"""
        return RAIValidator(strict_mode=strict_mode)

    def create_graph(self, name: str) -> Graph:
        """ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
        graph = Graph(name)
        self.graphs[name] = graph
        logging.info(f"ğŸ¨ ê·¸ë˜í”„ ìƒì„±: {name}")
        return graph

    def register_mcp_tool(self, tool: MCPTool) -> None:
        """MCP ë„êµ¬ ë“±ë¡"""
        self.mcp_tools[tool.name] = tool
        logging.info(f"ğŸ”§ MCP ë„êµ¬ ë“±ë¡: {tool.name}")

    async def run(
        self,
        session_id: str,
        workflow_name: str,
        user_message: str = "",
        restore_from_checkpoint: bool = False,
        checkpoint_tag: str | None = None
    ) -> AgentState:
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        # ìƒíƒœ ë³µì›
        if restore_from_checkpoint:
            state = await self.state_manager.restore_checkpoint(session_id, tag=checkpoint_tag)
            if not state:
                logging.warning("âš ï¸ ì²´í¬í¬ì¸íŠ¸ ë³µì› ì‹¤íŒ¨, ìƒˆ ì„¸ì…˜ ì‹œì‘")
                state = None
        else:
            state = await self.state_manager.load_state(session_id)

        if not state:
            state = AgentState(session_id=session_id, workflow_name=workflow_name)
            logging.info(f"ğŸ†• ìƒˆ ì„¸ì…˜ ì‹œì‘: {session_id}")

        if user_message:
            state.add_message(AgentRole.USER, user_message)
            if self.event_bus:
                await self.event_bus.publish(AgentEvent(
                    event_type=EventType.MESSAGE_RECEIVED,
                    data={"content": user_message}
                ))

        graph = self.graphs.get(workflow_name)
        if not graph:
            raise ValueError(f"ì›Œí¬í”Œë¡œìš° '{workflow_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        start_time = time.time()
        self.global_metrics["total_executions"] += 1

        try:
            if self.tracer:
                with self.tracer.start_as_current_span("workflow_execution") as span:
                    span.set_attribute("session_id", session_id)
                    span.set_attribute("workflow_name", workflow_name)
                    state = await graph.execute(state, self.kernel)
                    span.set_attribute("status", state.execution_status.value)
                    span.set_attribute("iterations", state.metrics.get("total_iterations", 0))
            else:
                state = await graph.execute(state, self.kernel)

            execution_time = (time.time() - start_time) * 1000
            state.metrics["execution_time_ms"] = execution_time
            state.metrics["success"] = state.execution_status == ExecutionStatus.COMPLETED

        except Exception as e:
            logging.error(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            self.global_metrics["total_failures"] += 1
            state.execution_status = ExecutionStatus.FAILED
            state.metadata["error"] = str(e)

        await self.state_manager.save_state(state)

        if state.execution_status == ExecutionStatus.COMPLETED:
            await self.state_manager.save_checkpoint(state, tag="auto")

        return state

    async def approve_pending_request(
        self,
        session_id: str,
        request_id: int,
        approved: bool
    ) -> AgentState:
        """ëŒ€ê¸° ì¤‘ì¸ ìŠ¹ì¸ ìš”ì²­ ì²˜ë¦¬"""
        state = await self.state_manager.load_state(session_id)
        if not state:
            raise ValueError(f"ì„¸ì…˜ '{session_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        if request_id >= len(state.pending_approvals):
            raise ValueError(f"ìŠ¹ì¸ ìš”ì²­ #{request_id}ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        approval = state.pending_approvals[request_id]
        approval["status"] = ApprovalStatus.APPROVED if approved else ApprovalStatus.REJECTED
        approval["approved_at"] = datetime.now(timezone.utc).isoformat()

        if approved:
            state.execution_status = ExecutionStatus.RUNNING
            if self.event_bus:
                await self.event_bus.publish(AgentEvent(
                    event_type=EventType.APPROVAL_GRANTED,
                    data=approval
                ))
        else:
            state.execution_status = ExecutionStatus.FAILED
            if self.event_bus:
                await self.event_bus.publish(AgentEvent(
                    event_type=EventType.APPROVAL_DENIED,
                    data=approval
                ))

        await self.state_manager.save_state(state)
        return state

    def visualize_workflow(self, workflow_name: str) -> str:
        """ì›Œí¬í”Œë¡œìš° ì‹œê°í™”"""
        graph = self.graphs.get(workflow_name)
        if not graph:
            return f"âŒ ì›Œí¬í”Œë¡œìš° '{workflow_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return graph.visualize()

    def get_workflow_stats(self, workflow_name: str) -> dict[str, Any]:
        """ì›Œí¬í”Œë¡œìš° í†µê³„"""
        graph = self.graphs.get(workflow_name)
        if not graph:
            return {}
        return graph.get_statistics()

    def get_global_metrics(self) -> dict[str, Any]:
        """ì „ì—­ ë©”íŠ¸ë¦­"""
        return {
            **self.global_metrics,
            "total_workflows": len(self.graphs),
            "total_mcp_tools": len(self.mcp_tools),
            "uptime_seconds": (
                datetime.now(timezone.utc) -
                datetime.fromisoformat(self.global_metrics["start_time"])
            ).total_seconds()
        }

    async def cleanup(self) -> None:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logging.info("ğŸ§¹ í”„ë ˆì„ì›Œí¬ ì •ë¦¬ ì‹œì‘")

        for tool in self.mcp_tools.values():
            await tool.disconnect()
        
        # v3.4 Extensions ì •ë¦¬
        if self.extensions:
            await self.extensions.cleanup()

        logging.info("âœ… í”„ë ˆì„ì›Œí¬ ì •ë¦¬ ì™„ë£Œ")

    # ========================================================================
    # v4.0 íŒ©í† ë¦¬ ë©”ì„œë“œ â€” ìƒˆë¡œìš´ í•µì‹¬ ê¸°ëŠ¥ í¸ì˜ ì ‘ê·¼
    # ========================================================================

    def create_responses_client(self, config: 'ResponseConfig' | None = None) -> ResponsesClient:
        """
        v4.0 Responses API í´ë¼ì´ì–¸íŠ¸ ìƒì„±

        ì‚¬ìš©ë²•:
            client = framework.create_responses_client()
            response = await client.create("ì§ˆë¬¸ì…ë‹ˆë‹¤")
        """
        from .responses_api import ResponseConfig as RC
        return ResponsesClient(config=config)

    def create_video_generator(self) -> VideoGenerator:
        """
        v4.0 ë¹„ë””ì˜¤ ìƒì„±ê¸° ìƒì„±

        ì‚¬ìš©ë²•:
            gen = framework.create_video_generator()
            result = await gen.generate("A sunset over the ocean")
        """
        return VideoGenerator()

    def create_image_generator(self) -> ImageGenerator:
        """
        v4.0 ì´ë¯¸ì§€ ìƒì„±ê¸° ìƒì„±

        ì‚¬ìš©ë²•:
            gen = framework.create_image_generator()
            result = await gen.generate("A futuristic city")
        """
        return ImageGenerator()

    def create_open_weight_adapter(self, default_endpoint: str | None = None) -> OpenWeightAdapter:
        """
        v4.0 ì˜¤í”ˆ ê°€ì¤‘ì¹˜ ëª¨ë¸ ì–´ëŒ‘í„° ìƒì„±

        ì‚¬ìš©ë²•:
            adapter = framework.create_open_weight_adapter()
            response = await adapter.generate(model="gpt-oss-120b", prompt="Hello!")
        """
        return OpenWeightAdapter(default_endpoint=default_endpoint)

    def create_universal_bridge(self) -> UniversalAgentBridge:
        """
        v4.0 Universal Agent Bridge ìƒì„±

        ì‚¬ìš©ë²•:
            bridge = framework.create_universal_bridge()
            bridge.register("semantic-kernel", SemanticKernelAgentBridge())
            result = await bridge.run(framework="semantic-kernel", task="ë¶„ì„í•´ì¤˜")
        """
        return UniversalAgentBridge()

    def get_bridge(self, protocol: str) -> Any:
        """
        v4.0 í”„ë ˆì„ì›Œí¬ ë¸Œë¦¿ì§€ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜

        ì§€ì› í”„ë¡œí† ì½œ: semantic-kernel, openai-agents,
                      google-adk, crewai, ag2, ms-agent, a2a

        ì‚¬ìš©ë²•:
            bridge = framework.get_bridge("crewai")
            result = await bridge.run(task="ë°ì´í„°ë¥¼ ë¶„ì„í•´ì¤˜")
        """
        # ì§€ì—° ì„í¬íŠ¸ â€” í•„ìš”í•œ ë¸Œë¦¿ì§€ë§Œ ë¡œë“œí•˜ì—¬ ì‹œì‘ ì‹œê°„ ìµœì í™”
        from .sk_agent_bridge import SemanticKernelAgentBridge
        from .openai_agents_bridge import OpenAIAgentsBridge
        from .google_adk_bridge import GoogleADKBridge
        from .crewai_bridge import CrewAIBridge
        from .ag2_bridge import AG2Bridge
        from .ms_agent_bridge import MicrosoftAgentBridge
        from .a2a_bridge import A2ABridge

        bridge_map: dict[str, type] = {
            "semantic-kernel": SemanticKernelAgentBridge,
            "openai-agents": OpenAIAgentsBridge,
            "google-adk": GoogleADKBridge,
            "crewai": CrewAIBridge,
            "ag2": AG2Bridge,
            "ms-agent": MicrosoftAgentBridge,
            "a2a": A2ABridge,
        }
        cls = bridge_map.get(protocol)
        if cls is None:
            raise ConfigurationError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¦¿ì§€ í”„ë¡œí† ì½œ: '{protocol}'. "
                f"ì§€ì› ëª©ë¡: {', '.join(bridge_map)}"
            )
        return cls()

# ============================================================================
# ê°„í¸ ì‚¬ìš© í•¨ìˆ˜
# ============================================================================

async def quick_run(message: str, system_prompt: str = "You are a helpful assistant.") -> str:
    """
    ê°€ì¥ ê°„ë‹¨í•œ ì‚¬ìš©ë²• - í•œ ì¤„ë¡œ AI ì‘ë‹µ ë°›ê¸°

    ì‚¬ìš©ë²•:
        import asyncio
        from unified_agent import quick_run

        response = asyncio.run(quick_run("íŒŒì´ì¬ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?"))
        print(response)
    """
    framework = UnifiedAgentFramework.create()
    return await framework.quick_chat(message, system_prompt)

def create_framework(
    model: str = None,
    temperature: float = 0.7,
    **kwargs
) -> UnifiedAgentFramework:
    """
    í”„ë ˆì„ì›Œí¬ ê°„í¸ ìƒì„±

    ì‚¬ìš©ë²•:
        from unified_agent import create_framework

        framework = create_framework(model="gpt-4o", temperature=0.5)
    """
    config = FrameworkConfig.from_env()
    if model is not None:
        config.model = model
    config.temperature = temperature

    for key, value in kwargs.items():
        if hasattr(config, key):
            setattr(config, key, value)

    return UnifiedAgentFramework.create(config)
