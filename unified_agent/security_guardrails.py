#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Agent Framework - ë³´ì•ˆ ê°€ë“œë ˆì¼ ëª¨ë“ˆ (Security Guardrails Module)

================================================================================
ğŸ“ íŒŒì¼ ìœ„ì¹˜: unified_agent/security_guardrails.py
ğŸ“‹ ì—­í• : Prompt Injection ë°©ì–´, Jailbreak íƒì§€, ì¶œë ¥ ê²€ì¦, Groundedness ê²€ì‚¬
ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›” 4ì¼
ğŸ“¦ ë²„ì „: v3.5.0
âœ… í…ŒìŠ¤íŠ¸: test_security_guardrails.py, test_v35_scenarios.py
================================================================================

ğŸ¯ ì£¼ìš” êµ¬ì„± ìš”ì†Œ:
    1. PromptShield - Prompt Injection ë° ê°„ì ‘ ê³µê²© íƒì§€
    2. JailbreakDetector - Jailbreak ì‹œë„ íƒì§€
    3. OutputValidator - ì¶œë ¥ ì•ˆì „ì„± ê²€ì¦
    4. GroundednessChecker - ì‘ë‹µì˜ ê·¼ê±° í™•ì¸ (Hallucination ë°©ì§€)
    5. PIIDetector - ê°œì¸ì •ë³´(PII) íƒì§€ ë° ë§ˆìŠ¤í‚¹
    6. SecurityOrchestrator - í†µí•© ë³´ì•ˆ íŒŒì´í”„ë¼ì¸

ğŸ”§ 2026ë…„ 2ì›” ê¸°ëŠ¥:
    - Azure AI Content Safety API í†µí•©
    - ë¡œì»¬ íŒ¨í„´ ê¸°ë°˜ ë¹ ë¥¸ í•„í„°ë§
    - ë‹¤ì¸µ ë³´ì•ˆ ê²€ì¦ (Input â†’ Processing â†’ Output)
    - ì‹¤ì‹œê°„ ìœ„í˜‘ íƒì§€ ë° ì°¨ë‹¨
    - ê°ì‚¬ ë¡œê·¸ (Audit Log) ì§€ì›

ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
    >>> from unified_agent.security_guardrails import (
    ...     PromptShield, JailbreakDetector, SecurityOrchestrator,
    ...     SecurityConfig, ThreatLevel
    ... )
    >>>
    >>> # ë°©ë²• 1: ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©
    >>> shield = PromptShield()
    >>> result = await shield.analyze("ì‚¬ìš©ì ì…ë ¥")
    >>> if result.is_attack:
    ...     print(f"âš ï¸ ê³µê²© íƒì§€: {result.attack_type}")
    >>>
    >>> # ë°©ë²• 2: í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì‚¬ìš©
    >>> orchestrator = SecurityOrchestrator(SecurityConfig(
    ...     enable_prompt_shield=True,
    ...     enable_jailbreak_detection=True,
    ...     enable_pii_detection=True,
    ...     threat_level=ThreatLevel.MEDIUM
    ... ))
    >>> result = await orchestrator.validate_input("ì‚¬ìš©ì ì…ë ¥")
    >>> if not result.is_safe:
    ...     print(f"ì°¨ë‹¨ë¨: {result.blocked_reason}")

âš ï¸ ì£¼ì˜ì‚¬í•­:
    - í”„ë¡œë•ì…˜ì—ì„œëŠ” Azure AI Content Safety API ì‚¬ìš©ì„ ê°•ë ¥ ê¶Œì¥í•©ë‹ˆë‹¤.
    - ë¡œì»¬ íŒ¨í„´ ë§¤ì¹­ì€ ê¸°ë³¸ í•„í„°ë§ìš©ì´ë©°, ìš°íšŒë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - API í‚¤ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ì„¸ìš”.

ğŸ”— ê´€ë ¨ ë¬¸ì„œ:
    - Azure AI Content Safety: https://learn.microsoft.com/azure/ai-services/content-safety/
    - Prompt Shield: https://learn.microsoft.com/azure/ai-services/content-safety/concepts/jailbreak-detection
    - Groundedness Detection: https://learn.microsoft.com/azure/ai-services/content-safety/concepts/groundedness
"""

from __future__ import annotations

import re
import hashlib
import asyncio
import aiohttp
import json
import logging
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Callable
from functools import lru_cache

__all__ = [
    # Enums
    "ThreatLevel",
    "AttackType",
    "PIIType",
    "ValidationStage",
    # Config & Results
    "SecurityConfig",
    "ShieldResult",
    "JailbreakResult",
    "PIIResult",
    "GroundednessResult",
    "ValidationResult",
    "AuditLogEntry",
    # Core Components
    "PromptShield",
    "JailbreakDetector",
    "OutputValidator",
    "GroundednessChecker",
    "PIIDetector",
    "SecurityOrchestrator",
    # Utilities
    "SecurityAuditLogger",
]

# ============================================================================
# Enums
# ============================================================================

class ThreatLevel(str, Enum):
    """ìœ„í˜‘ ìˆ˜ì¤€ ì„¤ì •"""
    LOW = "low"           # ê¸°ë³¸ í•„í„°ë§ë§Œ
    MEDIUM = "medium"     # íŒ¨í„´ ë§¤ì¹­ + íœ´ë¦¬ìŠ¤í‹±
    HIGH = "high"         # ëª¨ë“  ê²€ì¦ + API í˜¸ì¶œ
    PARANOID = "paranoid" # ìµœëŒ€ ë³´ì•ˆ (ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥)

class AttackType(str, Enum):
    """ê³µê²© ìœ í˜•"""
    NONE = "none"
    DIRECT_INJECTION = "direct_injection"       # ì§ì ‘ í”„ë¡¬í”„íŠ¸ ì£¼ì…
    INDIRECT_INJECTION = "indirect_injection"   # ê°„ì ‘ í”„ë¡¬í”„íŠ¸ ì£¼ì… (ë¬¸ì„œ ë‚´)
    JAILBREAK = "jailbreak"                     # ì—­í•  íƒˆì¶œ ì‹œë„
    PROMPT_LEAKING = "prompt_leaking"           # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìœ ì¶œ ì‹œë„
    INSTRUCTION_OVERRIDE = "instruction_override" # ì§€ì‹œ ë¬´ì‹œ/ë®ì–´ì“°ê¸°
    ENCODING_ATTACK = "encoding_attack"         # Base64/ì¸ì½”ë”© ìš°íšŒ
    MULTI_TURN_ATTACK = "multi_turn_attack"     # ë‹¤ì¤‘ í„´ ê³µê²©
    ROLE_PLAY_ATTACK = "role_play_attack"       # ì—­í• ê·¹ ê¸°ë°˜ ê³µê²©

class PIIType(str, Enum):
    """ê°œì¸ì •ë³´ ìœ í˜•"""
    EMAIL = "email"
    PHONE = "phone"
    SSN = "ssn"                    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
    CREDIT_CARD = "credit_card"
    IP_ADDRESS = "ip_address"
    ADDRESS = "address"
    NAME = "name"
    PASSPORT = "passport"
    DRIVER_LICENSE = "driver_license"

class ValidationStage(str, Enum):
    """ê²€ì¦ ë‹¨ê³„"""
    INPUT = "input"           # ì‚¬ìš©ì ì…ë ¥ ê²€ì¦
    PROCESSING = "processing" # ì²˜ë¦¬ ì¤‘ ê²€ì¦
    OUTPUT = "output"         # ì¶œë ¥ ê²€ì¦

# ============================================================================
# Data Classes
# ============================================================================

@dataclass(frozen=True, slots=True)
class SecurityConfig:
    """
    ë³´ì•ˆ ì„¤ì • êµ¬ì„±
    
    ================================================================================
    ğŸ“‹ ì—­í• : ë³´ì•ˆ ê°€ë“œë ˆì¼ì˜ ì „ì²´ ì„¤ì •ì„ ê´€ë¦¬
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    
    Attributes:
        threat_level: ìœ„í˜‘ ìˆ˜ì¤€ (LOW, MEDIUM, HIGH, PARANOID)
        enable_prompt_shield: Prompt Injection íƒì§€ í™œì„±í™”
        enable_jailbreak_detection: Jailbreak íƒì§€ í™œì„±í™”
        enable_pii_detection: PII íƒì§€ í™œì„±í™”
        enable_output_validation: ì¶œë ¥ ê²€ì¦ í™œì„±í™”
        enable_groundedness_check: Groundedness ê²€ì‚¬ í™œì„±í™”
        enable_audit_logging: ê°ì‚¬ ë¡œê¹… í™œì„±í™”
        azure_content_safety_endpoint: Azure Content Safety API ì—”ë“œí¬ì¸íŠ¸
        azure_content_safety_key: Azure Content Safety API í‚¤
        block_on_detection: íƒì§€ ì‹œ ì¦‰ì‹œ ì°¨ë‹¨ ì—¬ë¶€
        custom_blocked_patterns: ì‚¬ìš©ì ì •ì˜ ì°¨ë‹¨ íŒ¨í„´
        pii_mask_char: PII ë§ˆìŠ¤í‚¹ ë¬¸ì
        max_input_length: ìµœëŒ€ ì…ë ¥ ê¸¸ì´
    
    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> config = SecurityConfig(
        ...     threat_level=ThreatLevel.HIGH,
        ...     enable_prompt_shield=True,
        ...     azure_content_safety_endpoint="https://xxx.cognitiveservices.azure.com",
        ...     azure_content_safety_key="your-api-key"
        ... )
    """
    threat_level: ThreatLevel = ThreatLevel.MEDIUM
    enable_prompt_shield: bool = True
    enable_jailbreak_detection: bool = True
    enable_pii_detection: bool = True
    enable_output_validation: bool = True
    enable_groundedness_check: bool = False  # API í•„ìš”
    enable_audit_logging: bool = True
    
    # Azure AI Content Safety API (ì„ íƒì )
    azure_content_safety_endpoint: str | None = None
    azure_content_safety_key: str | None = field(default=None, repr=False)
    
    # ë™ì‘ ì„¤ì •
    block_on_detection: bool = True
    custom_blocked_patterns: list[str] = field(default_factory=list)
    pii_mask_char: str = "*"
    max_input_length: int = 100000  # 100K chars
    
    # íƒ€ì„ì•„ì›ƒ
    api_timeout_seconds: float = 10.0
    
    def has_azure_api(self) -> bool:
        """Azure API ì„¤ì • ì—¬ë¶€ í™•ì¸"""
        return bool(self.azure_content_safety_endpoint and self.azure_content_safety_key)

@dataclass(slots=True)
class ShieldResult:
    """
    Prompt Shield ë¶„ì„ ê²°ê³¼
    
    Attributes:
        is_attack: ê³µê²© ì—¬ë¶€
        attack_type: ê³µê²© ìœ í˜•
        confidence: ì‹ ë¢°ë„ (0.0 ~ 1.0)
        matched_patterns: ë§¤ì¹­ëœ íŒ¨í„´ ëª©ë¡
        details: ìƒì„¸ ì •ë³´
        processing_time_ms: ì²˜ë¦¬ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
    """
    is_attack: bool = False
    attack_type: AttackType = AttackType.NONE
    confidence: float = 0.0
    matched_patterns: list[str] = field(default_factory=list)
    details: dict[str, Any] = field(default_factory=dict)
    processing_time_ms: float = 0.0

@dataclass(slots=True)
class JailbreakResult:
    """
    Jailbreak íƒì§€ ê²°ê³¼
    
    Attributes:
        is_jailbreak: Jailbreak ì‹œë„ ì—¬ë¶€
        confidence: ì‹ ë¢°ë„ (0.0 ~ 1.0)
        detected_techniques: íƒì§€ëœ ê¸°ë²• ëª©ë¡
        risk_score: ìœ„í—˜ ì ìˆ˜ (0 ~ 100)
        recommendation: ê¶Œì¥ ì¡°ì¹˜
    """
    is_jailbreak: bool = False
    confidence: float = 0.0
    detected_techniques: list[str] = field(default_factory=list)
    risk_score: int = 0
    recommendation: str = ""

@dataclass(slots=True)
class PIIResult:
    """
    PII íƒì§€ ê²°ê³¼
    
    Attributes:
        has_pii: PII í¬í•¨ ì—¬ë¶€
        detected_types: íƒì§€ëœ PII ìœ í˜•
        pii_locations: PII ìœ„ì¹˜ ì •ë³´ (start, end, type)
        masked_text: PIIê°€ ë§ˆìŠ¤í‚¹ëœ í…ìŠ¤íŠ¸
        pii_count: íƒì§€ëœ PII ê°œìˆ˜
    """
    has_pii: bool = False
    detected_types: set[PIIType] = field(default_factory=set)
    pii_locations: list[dict[str, Any]] = field(default_factory=list)
    masked_text: str = ""
    pii_count: int = 0

@dataclass(slots=True)
class GroundednessResult:
    """
    Groundedness ê²€ì‚¬ ê²°ê³¼ (Hallucination íƒì§€)
    
    Attributes:
        is_grounded: ê·¼ê±° ìˆëŠ” ì‘ë‹µ ì—¬ë¶€
        groundedness_score: ê·¼ê±° ì ìˆ˜ (0.0 ~ 1.0)
        ungrounded_claims: ê·¼ê±° ì—†ëŠ” ì£¼ì¥ ëª©ë¡
        source_coverage: ì†ŒìŠ¤ ì»¤ë²„ë¦¬ì§€
    """
    is_grounded: bool = True
    groundedness_score: float = 1.0
    ungrounded_claims: list[str] = field(default_factory=list)
    source_coverage: float = 1.0

@dataclass(slots=True)
class ValidationResult:
    """
    í†µí•© ê²€ì¦ ê²°ê³¼
    
    Attributes:
        is_safe: ì•ˆì „ ì—¬ë¶€
        blocked: ì°¨ë‹¨ ì—¬ë¶€
        blocked_reason: ì°¨ë‹¨ ì‚¬ìœ 
        stage: ê²€ì¦ ë‹¨ê³„
        shield_result: Prompt Shield ê²°ê³¼
        jailbreak_result: Jailbreak íƒì§€ ê²°ê³¼
        pii_result: PII íƒì§€ ê²°ê³¼
        groundedness_result: Groundedness ê²°ê³¼
        sanitized_input: ì •í™”ëœ ì…ë ¥
        total_processing_time_ms: ì´ ì²˜ë¦¬ ì‹œê°„
    """
    is_safe: bool = True
    blocked: bool = False
    blocked_reason: str | None = None
    stage: ValidationStage = ValidationStage.INPUT
    shield_result: ShieldResult | None = None
    jailbreak_result: JailbreakResult | None = None
    pii_result: PIIResult | None = None
    groundedness_result: GroundednessResult | None = None
    sanitized_input: str | None = None
    total_processing_time_ms: float = 0.0

@dataclass(frozen=True, slots=True)
class AuditLogEntry:
    """
    ê°ì‚¬ ë¡œê·¸ í•­ëª©
    
    Attributes:
        timestamp: íƒ€ì„ìŠ¤íƒ¬í”„
        session_id: ì„¸ì…˜ ID
        stage: ê²€ì¦ ë‹¨ê³„
        input_hash: ì…ë ¥ í•´ì‹œ (SHA-256)
        result: ê²€ì¦ ê²°ê³¼
        threat_detected: ìœ„í˜‘ íƒì§€ ì—¬ë¶€
        threat_type: ìœ„í˜‘ ìœ í˜•
        action_taken: ì·¨í•œ ì¡°ì¹˜
        metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°
    """
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    session_id: str = ""
    stage: ValidationStage = ValidationStage.INPUT
    input_hash: str = ""
    result: str = ""
    threat_detected: bool = False
    threat_type: str | None = None
    action_taken: str = ""
    metadata: dict[str, Any] = field(default_factory=dict)

# ============================================================================
# Prompt Shield - Prompt Injection íƒì§€
# ============================================================================

class PromptShield:
    """
    Prompt Shield - Prompt Injection ë° ê°„ì ‘ ê³µê²© íƒì§€
    
    ================================================================================
    ğŸ“‹ ì—­í• : ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì•…ì˜ì ì¸ í”„ë¡¬í”„íŠ¸ ì£¼ì… ì‹œë„ë¥¼ íƒì§€
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    
    ğŸ¯ íƒì§€ ëŒ€ìƒ:
        - ì§ì ‘ í”„ë¡¬í”„íŠ¸ ì£¼ì… (Direct Injection)
        - ê°„ì ‘ í”„ë¡¬í”„íŠ¸ ì£¼ì… (Indirect Injection) - ë¬¸ì„œ/URL ë‚´ ìˆ¨ê²¨ì§„ ì§€ì‹œ
        - ì§€ì‹œ ë¬´ì‹œ/ë®ì–´ì“°ê¸° ì‹œë„
        - ì¸ì½”ë”© ê¸°ë°˜ ìš°íšŒ (Base64, Unicode ë“±)
        - í”„ë¡¬í”„íŠ¸ ìœ ì¶œ ì‹œë„
    
    ğŸ”§ íƒì§€ ë°©ë²•:
        1. íŒ¨í„´ ë§¤ì¹­ (ë¹ ë¥¸ 1ì°¨ í•„í„°ë§)
        2. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„ (ì˜ì‹¬ìŠ¤ëŸ¬ìš´ êµ¬ì¡° íƒì§€)
        3. Azure Content Safety API (ì„ íƒì , ë†’ì€ ì •í™•ë„)
    
    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> shield = PromptShield()
        >>> result = await shield.analyze("ì‚¬ìš©ì ì…ë ¥")
        >>> if result.is_attack:
        ...     print(f"ê³µê²© íƒì§€: {result.attack_type}")
        ...     print(f"ì‹ ë¢°ë„: {result.confidence:.2%}")
        >>>
        >>> # Azure API ì‚¬ìš©
        >>> shield = PromptShield(
        ...     azure_endpoint="https://xxx.cognitiveservices.azure.com",
        ...     azure_key="your-key"
        ... )
        >>> result = await shield.analyze_with_api(user_input, documents=[doc1, doc2])
    
    âš ï¸ ì£¼ì˜ì‚¬í•­:
        - íŒ¨í„´ ë§¤ì¹­ì€ ê¸°ë³¸ í•„í„°ë§ìš©ì…ë‹ˆë‹¤. ì •êµí•œ ê³µê²©ì€ ìš°íšŒë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        - í”„ë¡œë•ì…˜ì—ì„œëŠ” Azure Content Safety API ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    """
    
    # -------------------------------------------------------------------------
    # ì§ì ‘ ì£¼ì… íŒ¨í„´ (Direct Injection Patterns)
    # -------------------------------------------------------------------------
    DIRECT_INJECTION_PATTERNS = [
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¬´ì‹œ ì‹œë„
        r"(?i)ignore\s+(all\s+)?(previous|prior|above|earlier)\s+(instructions?|prompts?|rules?|guidelines?)",
        r"(?i)disregard\s+(all\s+)?(previous|prior|above)\s+(instructions?|prompts?)",
        r"(?i)forget\s+(everything|all|your)\s+(you\s+)?(know|learned|instructions?)",
        r"(?i)override\s+(your\s+)?(instructions?|programming|rules?|system)",
        r"(?i)ìƒˆë¡œìš´\s*ì§€ì‹œ|ì´ì „\s*(ì§€ì‹œ|ëª…ë ¹)\s*(ë¬´ì‹œ|ìŠì–´)",
        r"(?i)ì‹œìŠ¤í…œ\s*í”„ë¡¬í”„íŠ¸\s*(ë¬´ì‹œ|ë³€ê²½|ë®ì–´ì“°ê¸°)",
        r"(ë¬´ì‹œ|ìŠì–´).*(ì§€ì‹œ|ëª…ë ¹|ê·œì¹™|í”„ë¡¬í”„íŠ¸)",
        r"(ì´ì „|ìœ„|ì•).*(ì§€ì‹œ|ëª…ë ¹|ê·œì¹™).*(ë¬´ì‹œ|ìŠ|ê±´ë„ˆ)",
        
        # ì—­í•  ë³€ê²½ ì‹œë„
        r"(?i)you\s+are\s+now\s+(a|an|the)\s+(?!assistant|helpful)",
        r"(?i)pretend\s+(to\s+be|you'?re)\s+(a|an)",
        r"(?i)act\s+as\s+(if\s+)?(you\s+)?(are|were)\s+(a|an)",
        r"(?i)roleplay\s+as\s+(a|an)",
        r"(?i)ë„ˆëŠ”?\s*(ì´ì œ|ì§€ê¸ˆë¶€í„°)\s*.+?(ì´ë‹¤|ì•¼|ì…ë‹ˆë‹¤)",
        r"ì—­í• .*(ìˆ˜í–‰|ë°”ê¿”|ë³€ê²½)",
        r"ìƒˆë¡œìš´\s*ì—­í• ",
        
        # íƒˆì˜¥ í‚¤ì›Œë“œ
        r"(?i)jailbreak",
        r"(?i)DAN\s*(mode)?",
        r"(?i)developer\s+mode",
        r"(?i)unrestricted\s+mode",
        r"(?i)do\s+anything\s+now",
        
        # í”„ë¡¬í”„íŠ¸ ìœ ì¶œ ì‹œë„
        r"(?i)show\s+(me\s+)?(your\s+)?(system\s+)?prompt",
        r"(?i)reveal\s+(your\s+)?(system\s+)?prompt",
        r"(?i)what\s+(is|are)\s+your\s+(instructions?|rules?|prompt)",
        r"(?i)print\s+(your\s+)?(system\s+)?prompt",
        r"(?i)ì‹œìŠ¤í…œ\s*í”„ë¡¬í”„íŠ¸\s*(ë³´ì—¬|ì•Œë ¤|ì¶œë ¥)",
        r"(?i)ë„ˆì˜?\s*(ì§€ì‹œ|ëª…ë ¹|ê·œì¹™)\s*(ì•Œë ¤|ë³´ì—¬)",
    ]
    
    # -------------------------------------------------------------------------
    # ê°„ì ‘ ì£¼ì… íŒ¨í„´ (Indirect Injection Patterns - ë¬¸ì„œ ë‚´)
    # -------------------------------------------------------------------------
    INDIRECT_INJECTION_PATTERNS = [
        # ë¬¸ì„œ ë‚´ ìˆ¨ê²¨ì§„ ì§€ì‹œ
        r"(?i)\[SYSTEM\]",
        r"(?i)\[INSTRUCTION\]",
        r"(?i)<<<\s*(system|instruction|command)",
        r"(?i)>>>\s*END\s*OF\s*DOCUMENT",
        r"(?i)<!-- hidden instruction",
        r"(?i)/\*\s*system\s*override",
        
        # ë§ˆí¬ë‹¤ìš´/HTML ì•…ìš©
        r"(?i)<script[^>]*>",
        r"(?i)javascript:",
        r"(?i)data:text/html",
        
        # êµ¬ë¶„ì ì•…ìš©
        r"-{5,}\s*(system|instruction|ignore)",
        r"={5,}\s*(system|instruction|ignore)",
        
        # ì—­í•  ì§€ì‹œ ë§ˆì»¤
        r"(?i)\[INST\]",
        r"(?i)\[/INST\]",
        r"<<SYS>>",
        r"<\|im_start\|>system",
    ]
    
    # -------------------------------------------------------------------------
    # ì¸ì½”ë”© ìš°íšŒ íŒ¨í„´
    # -------------------------------------------------------------------------
    ENCODING_PATTERNS = [
        # Base64 ì¸ì½”ë”©
        r"(?i)base64:\s*[A-Za-z0-9+/=]{20,}",
        r"(?i)decode\s+this:\s*[A-Za-z0-9+/=]{20,}",
        
        # Hex ì¸ì½”ë”©
        r"(?i)hex:\s*[0-9a-fA-F]{20,}",
        r"(?i)\\x[0-9a-fA-F]{2}(\\x[0-9a-fA-F]{2}){5,}",
        
        # Unicode ì´ìŠ¤ì¼€ì´í”„
        r"\\u[0-9a-fA-F]{4}(\\u[0-9a-fA-F]{4}){5,}",
    ]
    
    def __init__(
        self,
        azure_endpoint: str | None = None,
        azure_key: str | None = None,
        custom_patterns: list[str] | None = None
    ):
        """
        PromptShield ì´ˆê¸°í™”
        
        Args:
            azure_endpoint: Azure Content Safety API ì—”ë“œí¬ì¸íŠ¸
            azure_key: Azure Content Safety API í‚¤
            custom_patterns: ì¶”ê°€ ì‚¬ìš©ì ì •ì˜ íŒ¨í„´
        """
        self.azure_endpoint = azure_endpoint
        self.azure_key = azure_key
        self.custom_patterns = custom_patterns or []
        self.logger = logging.getLogger(__name__)
        
        # íŒ¨í„´ ì»´íŒŒì¼ (ì„±ëŠ¥ ìµœì í™”)
        self._compiled_direct = [re.compile(p) for p in self.DIRECT_INJECTION_PATTERNS]
        self._compiled_indirect = [re.compile(p) for p in self.INDIRECT_INJECTION_PATTERNS]
        self._compiled_encoding = [re.compile(p) for p in self.ENCODING_PATTERNS]
        self._compiled_custom = [re.compile(p) for p in self.custom_patterns]
    
    async def analyze(
        self,
        text: str,
        documents: list[str] | None = None,
        use_api: bool = False
    ) -> ShieldResult:
        """
        í…ìŠ¤íŠ¸ ë¶„ì„í•˜ì—¬ Prompt Injection íƒì§€
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸ (ì‚¬ìš©ì ì…ë ¥)
            documents: í•¨ê»˜ ë¶„ì„í•  ë¬¸ì„œ ëª©ë¡ (ê°„ì ‘ ì£¼ì… íƒì§€ìš©)
            use_api: Azure API ì‚¬ìš© ì—¬ë¶€
        
        Returns:
            ShieldResult: ë¶„ì„ ê²°ê³¼
        """
        start_time = time.perf_counter()
        
        result = ShieldResult()
        matched_patterns = []
        
        # 1. ì§ì ‘ ì£¼ì… íŒ¨í„´ ê²€ì‚¬
        for pattern in self._compiled_direct:
            match = pattern.search(text)
            if match:
                matched_patterns.append(f"direct:{pattern.pattern[:50]}...")
                result.attack_type = AttackType.DIRECT_INJECTION
        
        # 2. ì¸ì½”ë”© ìš°íšŒ ê²€ì‚¬
        for pattern in self._compiled_encoding:
            match = pattern.search(text)
            if match:
                matched_patterns.append(f"encoding:{pattern.pattern[:50]}...")
                if result.attack_type == AttackType.NONE:
                    result.attack_type = AttackType.ENCODING_ATTACK
        
        # 3. ì‚¬ìš©ì ì •ì˜ íŒ¨í„´ ê²€ì‚¬
        for pattern in self._compiled_custom:
            match = pattern.search(text)
            if match:
                matched_patterns.append(f"custom:{pattern.pattern[:50]}...")
        
        # 4. ë¬¸ì„œ ë‚´ ê°„ì ‘ ì£¼ì… ê²€ì‚¬
        if documents:
            for i, doc in enumerate(documents):
                for pattern in self._compiled_indirect:
                    match = pattern.search(doc)
                    if match:
                        matched_patterns.append(f"indirect_doc_{i}:{pattern.pattern[:50]}...")
                        if result.attack_type == AttackType.NONE:
                            result.attack_type = AttackType.INDIRECT_INJECTION
        
        # 5. íœ´ë¦¬ìŠ¤í‹± ë¶„ì„
        heuristic_score = self._heuristic_analysis(text)
        
        # ê²°ê³¼ ì§‘ê³„
        if matched_patterns or heuristic_score > 0.5:
            result.is_attack = True
            result.matched_patterns = matched_patterns
            result.confidence = min(1.0, len(matched_patterns) * 0.2 + heuristic_score * 0.5)
            
            # ê³µê²© ìœ í˜• ì„¸ë¶„í™”
            if result.attack_type == AttackType.NONE and heuristic_score > 0.5:
                result.attack_type = AttackType.INSTRUCTION_OVERRIDE
        
        result.details = {
            "heuristic_score": heuristic_score,
            "pattern_matches": len(matched_patterns),
            "text_length": len(text),
            "documents_checked": len(documents) if documents else 0
        }
        
        # 6. Azure API í˜¸ì¶œ (ì„ íƒì )
        if use_api and self.azure_endpoint and self.azure_key:
            api_result = await self._call_azure_api(text, documents)
            if api_result:
                result.details["azure_api_result"] = api_result
                # API ê²°ê³¼ë¡œ ì‹ ë¢°ë„ ë³´ì •
                if api_result.get("attackDetected"):
                    result.is_attack = True
                    result.confidence = max(result.confidence, api_result.get("confidence", 0.8))
        
        result.processing_time_ms = (time.perf_counter() - start_time) * 1000
        return result
    
    def _heuristic_analysis(self, text: str) -> float:
        """
        íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë¶„ì„
        
        ì˜ì‹¬ìŠ¤ëŸ¬ìš´ êµ¬ì¡° ë° íŒ¨í„´ì„ ì ìˆ˜í™”í•©ë‹ˆë‹¤.
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        
        Returns:
            float: ì˜ì‹¬ ì ìˆ˜ (0.0 ~ 1.0)
        """
        score = 0.0
        text_lower = text.lower()
        
        # 1. ëª…ë ¹ì–´ í‚¤ì›Œë“œ ë°€ë„
        command_keywords = [
            "ignore", "forget", "override", "bypass", "skip",
            "ë¬´ì‹œ", "ìŠì–´", "ë®ì–´", "ìš°íšŒ", "ê±´ë„ˆë›°"
        ]
        keyword_count = sum(1 for kw in command_keywords if kw in text_lower)
        score += min(0.3, keyword_count * 0.1)
        
        # 2. ì—­í•  ë³€ê²½ ì‹œë„ (ë” ì¼ë°˜ì ì¸ íŒ¨í„´)
        role_indicators = [
            "you are", "act as", "pretend", "roleplay",
            "ë„ˆëŠ”", "ì—­í• ", "í–‰ë™í•´", "ì¸ì²™"
        ]
        if any(ind in text_lower for ind in role_indicators):
            score += 0.2
        
        # 3. êµ¬ë¶„ì ë‚¨ìš© (ë‹¤ì¤‘ êµ¬ë¶„ì)
        separators = text.count("---") + text.count("===") + text.count("***")
        if separators > 2:
            score += 0.15
        
        # 4. ëŒ€ë¬¸ì ë¹„ìœ¨ (ê³¼ë„í•œ ê°•ì¡°)
        if len(text) > 10:
            upper_ratio = sum(1 for c in text if c.isupper()) / len(text)
            if upper_ratio > 0.4:
                score += 0.1
        
        # 5. íŠ¹ìˆ˜ ë§ˆì»¤ ì¡´ì¬
        special_markers = ["[INST]", "[/INST]", "<|im_start|>", "<|im_end|>", "<<SYS>>"]
        if any(marker in text for marker in special_markers):
            score += 0.25
        
        return min(1.0, score)
    
    async def _call_azure_api(
        self,
        text: str,
        documents: list[str] | None = None
    ) -> dict[str, Any] | None:
        """
        Azure Content Safety API í˜¸ì¶œ (Prompt Shield)
        
        Args:
            text: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            documents: í•¨ê»˜ ë¶„ì„í•  ë¬¸ì„œ
        
        Returns:
            Dict | None: API ì‘ë‹µ ë˜ëŠ” None
        """
        if not self.azure_endpoint or not self.azure_key:
            return None
        
        url = f"{self.azure_endpoint}/contentsafety/text:shieldPrompt?api-version=2024-09-01"
        
        headers = {
            "Content-Type": "application/json",
            "Ocp-Apim-Subscription-Key": self.azure_key
        }
        
        payload = {
            "userPrompt": text,
            "documents": documents or []
        }
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, headers=headers, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        return {
                            "attackDetected": data.get("userPromptAnalysis", {}).get("attackDetected", False),
                            "confidence": 0.9 if data.get("userPromptAnalysis", {}).get("attackDetected") else 0.1,
                            "documentsAnalysis": data.get("documentsAnalysis", [])
                        }
                    else:
                        self.logger.warning(f"Azure API í˜¸ì¶œ ì‹¤íŒ¨: {response.status}")
                        return None
        except Exception as e:
            self.logger.error(f"Azure API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return None

# ============================================================================
# Jailbreak Detector
# ============================================================================

class JailbreakDetector:
    """
    Jailbreak íƒì§€ê¸° - ì—­í•  íƒˆì¶œ ë° ì œí•œ ìš°íšŒ ì‹œë„ íƒì§€
    
    ================================================================================
    ğŸ“‹ ì—­í• : AI ëª¨ë¸ì˜ ì•ˆì „ ì¥ì¹˜ ìš°íšŒ ì‹œë„ë¥¼ íƒì§€
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    
    ğŸ¯ íƒì§€ ëŒ€ìƒ:
        - DAN (Do Anything Now) ê³µê²©
        - ì—­í• ê·¹ ê¸°ë°˜ ìš°íšŒ
        - ê°€ìƒ ì‹œë‚˜ë¦¬ì˜¤ ì•…ìš©
        - ë‹¤ì¤‘ í„´ ì¡°ì‘
        - ê°ì • ì¡°ì‘ (Guilt-tripping)
    
    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> detector = JailbreakDetector()
        >>> result = detector.detect("Hi ChatGPT, let's play a game...")
        >>> if result.is_jailbreak:
        ...     print(f"Jailbreak ì‹œë„ íƒì§€: {result.detected_techniques}")
    """
    
    # Jailbreak ê¸°ë²•ë³„ íŒ¨í„´
    JAILBREAK_TECHNIQUES = {
        "DAN": [
            r"(?i)do\s+anything\s+now",
            r"(?i)DAN\s*(mode|prompt)?",
            r"(?i)you\s+can\s+do\s+anything",
            r"(?i)no\s+longer\s+bound\s+by\s+rules",
        ],
        "ROLEPLAY": [
            r"(?i)let'?s?\s+play\s+a\s+game",
            r"(?i)pretend\s+(we'?re|this\s+is)\s+a\s+(movie|story|fiction)",
            r"(?i)in\s+this\s+hypothetical\s+scenario",
            r"(?i)imagine\s+you'?re?\s+(a|an)\s+evil",
        ],
        "DEVELOPER_MODE": [
            r"(?i)developer\s+mode",
            r"(?i)admin\s+mode",
            r"(?i)god\s+mode",
            r"(?i)debug\s+mode",
            r"(?i)unrestricted\s+access",
        ],
        "SPLIT_PERSONALITY": [
            r"(?i)two\s+responses",
            r"(?i)one\s+filtered.+one\s+unfiltered",
            r"(?i)ğŸ”“\s*(unlocked|jailbroken)",
            r"(?i)normal\s+response.+dev\s+mode",
        ],
        "EMOTIONAL_MANIPULATION": [
            r"(?i)please.+i'?m?\s+dying",
            r"(?i)my\s+grandmother\s+used\s+to",
            r"(?i)for\s+educational\s+purposes\s+only",
            r"(?i)this\s+is\s+just\s+for\s+research",
        ],
        "TOKEN_SMUGGLING": [
            r"(?i)complete\s+the\s+following",
            r"(?i)continue\s+this\s+story",
            r"(?i)fill\s+in\s+the\s+blank",
        ],
    }
    
    def __init__(self, sensitivity: float = 0.5):
        """
        JailbreakDetector ì´ˆê¸°í™”
        
        Args:
            sensitivity: íƒì§€ ë¯¼ê°ë„ (0.0 ~ 1.0, ë†’ì„ìˆ˜ë¡ ë¯¼ê°)
        """
        self.sensitivity = sensitivity
        self._compiled_patterns = {
            technique: [re.compile(p) for p in patterns]
            for technique, patterns in self.JAILBREAK_TECHNIQUES.items()
        }
    
    def detect(self, text: str) -> JailbreakResult:
        """
        Jailbreak ì‹œë„ íƒì§€
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
        
        Returns:
            JailbreakResult: íƒì§€ ê²°ê³¼
        """
        result = JailbreakResult()
        detected_techniques = []
        total_score = 0
        
        # ê¸°ë²•ë³„ íŒ¨í„´ ë§¤ì¹­
        for technique, patterns in self._compiled_patterns.items():
            for pattern in patterns:
                if pattern.search(text):
                    detected_techniques.append(technique)
                    total_score += 20
                    break  # ê°™ì€ ê¸°ë²• ì¤‘ë³µ ì¹´ìš´íŠ¸ ë°©ì§€
        
        # ì¶”ê°€ íœ´ë¦¬ìŠ¤í‹±
        text_lower = text.lower()
        
        # 1. ê³¼ë„í•œ ì„¤ë“ ì‹œë„
        persuasion_words = ["please", "just", "only", "simply", "merely"]
        persuasion_count = sum(text_lower.count(w) for w in persuasion_words)
        if persuasion_count > 5:
            total_score += 10
        
        # 2. ìœ„í—˜í•œ ì£¼ì œ ìš”ì²­
        dangerous_topics = ["bomb", "hack", "weapon", "kill", "drug", "í­íƒ„", "í•´í‚¹", "ë¬´ê¸°"]
        if any(topic in text_lower for topic in dangerous_topics):
            total_score += 30
        
        # 3. ì—­í•  ê°•ìš”
        if "you must" in text_lower or "you have to" in text_lower:
            total_score += 15
        
        # ê²°ê³¼ ê³„ì‚°
        result.risk_score = min(100, total_score)
        result.detected_techniques = list(set(detected_techniques))
        
        # ë¯¼ê°ë„ì— ë”°ë¥¸ Jailbreak íŒì •
        threshold = int((1 - self.sensitivity) * 50 + 20)  # 20 ~ 70
        result.is_jailbreak = result.risk_score >= threshold
        result.confidence = min(1.0, result.risk_score / 100)
        
        # ê¶Œì¥ ì¡°ì¹˜
        if result.is_jailbreak:
            if result.risk_score >= 70:
                result.recommendation = "ì°¨ë‹¨ ê¶Œì¥: ë†’ì€ ìœ„í—˜ë„ì˜ Jailbreak ì‹œë„"
            elif result.risk_score >= 40:
                result.recommendation = "ê²€í†  ê¶Œì¥: ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ë°œê²¬"
            else:
                result.recommendation = "ëª¨ë‹ˆí„°ë§: ê²½ë¯¸í•œ ì˜ì‹¬ íŒ¨í„´"
        else:
            result.recommendation = "í†µê³¼: ìœ„í—˜ íŒ¨í„´ ë¯¸ë°œê²¬"
        
        return result

# ============================================================================
# PII Detector - ê°œì¸ì •ë³´ íƒì§€
# ============================================================================

class PIIDetector:
    """
    PII (Personally Identifiable Information) íƒì§€ê¸°
    
    ================================================================================
    ğŸ“‹ ì—­í• : í…ìŠ¤íŠ¸ì—ì„œ ê°œì¸ì •ë³´ë¥¼ íƒì§€í•˜ê³  ë§ˆìŠ¤í‚¹
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    
    ğŸ¯ íƒì§€ ëŒ€ìƒ:
        - ì´ë©”ì¼ ì£¼ì†Œ
        - ì „í™”ë²ˆí˜¸ (í•œêµ­/ë¯¸êµ­ í˜•ì‹)
        - ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
        - ì‹ ìš©ì¹´ë“œ ë²ˆí˜¸
        - IP ì£¼ì†Œ
        - ì—¬ê¶Œ ë²ˆí˜¸
    
    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> detector = PIIDetector()
        >>> result = detector.detect("ì—°ë½ì²˜: 010-1234-5678, ì´ë©”ì¼: test@example.com")
        >>> print(result.masked_text)
        # ì—°ë½ì²˜: ***-****-****, ì´ë©”ì¼: ****@*******.***
    """
    
    # PII íŒ¨í„´ ì •ì˜
    PII_PATTERNS = {
        PIIType.EMAIL: r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}',
        PIIType.PHONE: r'\b(010|011|016|017|018|019)[-.\s]?\d{3,4}[-.\s]?\d{4}\b|\b\d{2,3}[-.\s]?\d{3,4}[-.\s]?\d{4}\b',
        PIIType.SSN: r'\b\d{6}[-.\s]?\d{7}\b',  # í•œêµ­ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
        PIIType.CREDIT_CARD: r'\b(?:\d{4}[-.\s]?){3}\d{4}\b',
        PIIType.IP_ADDRESS: r'\b(?:25[0-5]|2[0-4]\d|1\d{2}|[1-9]?\d)(?:\.(?:25[0-5]|2[0-4]\d|1\d{2}|[1-9]?\d)){3}\b',
    }
    
    def __init__(self, mask_char: str = "*"):
        """
        PIIDetector ì´ˆê¸°í™”
        
        Args:
            mask_char: ë§ˆìŠ¤í‚¹ì— ì‚¬ìš©í•  ë¬¸ì
        """
        self.mask_char = mask_char
        self._compiled_patterns = {
            pii_type: re.compile(pattern)
            for pii_type, pattern in self.PII_PATTERNS.items()
        }
    
    def detect(self, text: str, mask: bool = True) -> PIIResult:
        """
        PII íƒì§€ ë° ì„ íƒì  ë§ˆìŠ¤í‚¹
        
        Args:
            text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            mask: ë§ˆìŠ¤í‚¹ ì—¬ë¶€
        
        Returns:
            PIIResult: íƒì§€ ê²°ê³¼
        """
        result = PIIResult()
        result.masked_text = text
        pii_locations = []
        detected_types = set()
        
        for pii_type, pattern in self._compiled_patterns.items():
            for match in pattern.finditer(text):
                detected_types.add(pii_type)
                pii_locations.append({
                    "type": pii_type.value,
                    "start": match.start(),
                    "end": match.end(),
                    "value_preview": match.group()[:3] + "..."  # ì¼ë¶€ë§Œ ê¸°ë¡
                })
        
        # ë§ˆìŠ¤í‚¹ ì ìš© (ë’¤ì—ì„œë¶€í„° ì²˜ë¦¬í•˜ì—¬ ì¸ë±ìŠ¤ ìœ ì§€)
        if mask and pii_locations:
            masked = list(text)
            for loc in sorted(pii_locations, key=lambda x: x["start"], reverse=True):
                start, end = loc["start"], loc["end"]
                # ì¼ë¶€ ë¬¸ìë§Œ ë§ˆìŠ¤í‚¹ (í˜•ì‹ ìœ ì§€)
                for i in range(start, end):
                    if text[i] not in "-. @":
                        masked[i] = self.mask_char
            result.masked_text = "".join(masked)
        
        result.has_pii = bool(detected_types)
        result.detected_types = detected_types
        result.pii_locations = pii_locations
        result.pii_count = len(pii_locations)
        
        return result

# ============================================================================
# Output Validator - ì¶œë ¥ ê²€ì¦
# ============================================================================

class OutputValidator:
    """
    ì¶œë ¥ ê²€ì¦ê¸° - AI ì‘ë‹µì˜ ì•ˆì „ì„± ê²€ì¦
    
    ================================================================================
    ğŸ“‹ ì—­í• : AI ëª¨ë¸ ì¶œë ¥ì—ì„œ ìœ í•´ ì½˜í…ì¸  ë° PII ìœ ì¶œ íƒì§€
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    
    ğŸ¯ ê²€ì¦ ëŒ€ìƒ:
        - ìœ í•´ ì½˜í…ì¸  (í­ë ¥, í˜ì˜¤ ë“±)
        - PII ìœ ì¶œ
        - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìœ ì¶œ
        - ì½”ë“œ ì¸ì ì…˜
    
    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> validator = OutputValidator()
        >>> result = await validator.validate(ai_response, context={"system_prompt": "..."})
    """
    
    # ìœ í•´ ì½˜í…ì¸  íŒ¨í„´
    HARMFUL_PATTERNS = [
        r"(?i)how\s+to\s+(make|build|create)\s+(a\s+)?(bomb|weapon|explosive)",
        r"(?i)step.+by.+step.+(hack|exploit|attack)",
    ]
    
    # í”„ë¡¬í”„íŠ¸ ìœ ì¶œ ì§•í›„
    PROMPT_LEAK_INDICATORS = [
        r"(?i)my\s+(system\s+)?instructions?\s+(are|is|say)",
        r"(?i)i\s+was\s+(told|instructed|programmed)\s+to",
        r"(?i)my\s+initial\s+prompt",
    ]
    
    def __init__(self, pii_detector: PIIDetector | None = None):
        """
        OutputValidator ì´ˆê¸°í™”
        
        Args:
            pii_detector: PII íƒì§€ê¸° ì¸ìŠ¤í„´ìŠ¤ (ê³µìœ  ê°€ëŠ¥)
        """
        self.pii_detector = pii_detector or PIIDetector()
        self._compiled_harmful = [re.compile(p) for p in self.HARMFUL_PATTERNS]
        self._compiled_leak = [re.compile(p) for p in self.PROMPT_LEAK_INDICATORS]
    
    async def validate(
        self,
        output: str,
        context: dict[str, Any] | None = None
    ) -> ValidationResult:
        """
        AI ì¶œë ¥ ê²€ì¦
        
        Args:
            output: AI ëª¨ë¸ ì¶œë ¥
            context: ì»¨í…ìŠ¤íŠ¸ (system_prompt ë“±)
        
        Returns:
            ValidationResult: ê²€ì¦ ê²°ê³¼
        """
        start_time = time.perf_counter()
        
        result = ValidationResult(stage=ValidationStage.OUTPUT)
        issues = []
        
        # 1. ìœ í•´ ì½˜í…ì¸  ê²€ì‚¬
        for pattern in self._compiled_harmful:
            if pattern.search(output):
                issues.append("harmful_content")
                break
        
        # 2. í”„ë¡¬í”„íŠ¸ ìœ ì¶œ ê²€ì‚¬
        for pattern in self._compiled_leak:
            if pattern.search(output):
                issues.append("potential_prompt_leak")
                break
        
        # 3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ì˜ ìœ ì‚¬ë„ ê²€ì‚¬ (ì„ íƒì )
        if context and context.get("system_prompt"):
            system_prompt = context["system_prompt"]
            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì˜ ì¼ë¶€ê°€ ì¶œë ¥ì— í¬í•¨ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if len(system_prompt) > 20:
                chunks = [system_prompt[i:i+50] for i in range(0, len(system_prompt), 50)]
                for chunk in chunks:
                    if chunk.lower() in output.lower():
                        issues.append("system_prompt_leak")
                        break
        
        # 4. PII ìœ ì¶œ ê²€ì‚¬
        pii_result = self.pii_detector.detect(output, mask=False)
        if pii_result.has_pii:
            issues.append("pii_in_output")
            result.pii_result = pii_result
        
        # ê²°ê³¼ ì§‘ê³„
        result.is_safe = len(issues) == 0
        if not result.is_safe:
            result.blocked = True
            result.blocked_reason = f"ì¶œë ¥ ê²€ì¦ ì‹¤íŒ¨: {', '.join(issues)}"
        
        result.total_processing_time_ms = (time.perf_counter() - start_time) * 1000
        return result

# ============================================================================
# Groundedness Checker - ê·¼ê±° ê²€ì‚¬
# ============================================================================

class GroundednessChecker:
    """
    Groundedness ê²€ì‚¬ê¸° - Hallucination íƒì§€
    
    ================================================================================
    ğŸ“‹ ì—­í• : AI ì‘ë‹µì´ ì œê³µëœ ì†ŒìŠ¤ì— ê·¼ê±°í•˜ëŠ”ì§€ ê²€ì¦
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    
    âš ï¸ ì£¼ì˜: Azure Groundedness Detection API ì‚¬ìš© ê¶Œì¥
    
    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> checker = GroundednessChecker(
        ...     azure_endpoint="https://xxx.cognitiveservices.azure.com",
        ...     azure_key="your-key"
        ... )
        >>> result = await checker.check(
        ...     response="AIê°€ ìƒì„±í•œ ì‘ë‹µ",
        ...     sources=["ì†ŒìŠ¤ ë¬¸ì„œ 1", "ì†ŒìŠ¤ ë¬¸ì„œ 2"]
        ... )
    """
    
    def __init__(
        self,
        azure_endpoint: str | None = None,
        azure_key: str | None = None
    ):
        self.azure_endpoint = azure_endpoint
        self.azure_key = azure_key
        self.logger = logging.getLogger(__name__)
    
    async def check(
        self,
        response: str,
        sources: list[str],
        query: str | None = None
    ) -> GroundednessResult:
        """
        ì‘ë‹µì˜ ê·¼ê±° ê²€ì‚¬
        
        Args:
            response: AI ì‘ë‹µ
            sources: ì†ŒìŠ¤ ë¬¸ì„œ ëª©ë¡
            query: ì›ë³¸ ì§ˆë¬¸ (ì„ íƒ)
        
        Returns:
            GroundednessResult: ê²€ì‚¬ ê²°ê³¼
        """
        result = GroundednessResult()
        
        # Azure API ì‚¬ìš© ì‹œ
        if self.azure_endpoint and self.azure_key:
            api_result = await self._call_groundedness_api(response, sources, query)
            if api_result:
                result.is_grounded = api_result.get("ungroundedDetected", False) == False
                result.groundedness_score = 1.0 - api_result.get("ungroundedPercentage", 0) / 100
                result.ungrounded_claims = api_result.get("ungroundedSegments", [])
                return result
        
        # ë¡œì»¬ íœ´ë¦¬ìŠ¤í‹± (ê°„ë‹¨í•œ ë²„ì „)
        # ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” Azure API ì‚¬ìš© ê¶Œì¥
        combined_sources = " ".join(sources).lower()
        response_lower = response.lower()
        
        # ì‘ë‹µì˜ ì£¼ìš” ëª…ì‚¬/í‚¤ì›Œë“œê°€ ì†ŒìŠ¤ì— ìˆëŠ”ì§€ í™•ì¸
        # (ë§¤ìš° ë‹¨ìˆœí™”ëœ ë²„ì „)
        words = set(response_lower.split())
        source_words = set(combined_sources.split())
        
        common_words = {"the", "a", "an", "is", "are", "was", "were", "ì´", "ê·¸", "ì €", "ì„", "ë¥¼"}
        meaningful_words = words - common_words
        
        if meaningful_words:
            coverage = len(meaningful_words & source_words) / len(meaningful_words)
            result.source_coverage = coverage
            result.groundedness_score = coverage
            result.is_grounded = coverage > 0.3  # 30% ì´ìƒ ì»¤ë²„ë¦¬ì§€
        
        return result
    
    async def _call_groundedness_api(
        self,
        response: str,
        sources: list[str],
        query: str | None = None
    ) -> dict[str, Any] | None:
        """Azure Groundedness Detection API í˜¸ì¶œ"""
        if not self.azure_endpoint or not self.azure_key:
            return None
        
        url = f"{self.azure_endpoint}/contentsafety/text:detectGroundedness?api-version=2024-09-15-preview"
        
        headers = {
            "Content-Type": "application/json",
            "Ocp-Apim-Subscription-Key": self.azure_key
        }
        
        payload = {
            "domain": "Generic",
            "task": "QnA" if query else "Summarization",
            "text": response,
            "groundingSources": sources,
            "reasoning": False
        }
        
        if query:
            payload["query"] = query
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, headers=headers, timeout=15) as resp:
                    if resp.status == 200:
                        return await resp.json()
                    else:
                        self.logger.warning(f"Groundedness API ì˜¤ë¥˜: {resp.status}")
                        return None
        except Exception as e:
            self.logger.error(f"Groundedness API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None

# ============================================================================
# Security Audit Logger
# ============================================================================

class SecurityAuditLogger:
    """
    ë³´ì•ˆ ê°ì‚¬ ë¡œê±°
    
    ================================================================================
    ğŸ“‹ ì—­í• : ë³´ì•ˆ ì´ë²¤íŠ¸ë¥¼ ê°ì‚¬ ë¡œê·¸ë¡œ ê¸°ë¡
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    
    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> audit = SecurityAuditLogger(log_file="./security_audit.log")
        >>> audit.log_event(AuditLogEntry(
        ...     session_id="sess-123",
        ...     threat_detected=True,
        ...     threat_type="prompt_injection"
        ... ))
    """
    
    def __init__(self, log_file: str | None = None):
        """
        SecurityAuditLogger ì´ˆê¸°í™”
        
        Args:
            log_file: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì½˜ì†” ì¶œë ¥)
        """
        self.log_file = log_file
        self.logger = logging.getLogger("security_audit")
        
        if log_file:
            handler = logging.FileHandler(log_file, encoding="utf-8")
            handler.setFormatter(logging.Formatter('%(message)s'))
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
    
    def log_event(self, entry: AuditLogEntry) -> None:
        """
        ê°ì‚¬ ì´ë²¤íŠ¸ ê¸°ë¡
        
        Args:
            entry: ê°ì‚¬ ë¡œê·¸ í•­ëª©
        """
        log_data = {
            "timestamp": entry.timestamp.isoformat(),
            "session_id": entry.session_id,
            "stage": entry.stage.value,
            "input_hash": entry.input_hash,
            "result": entry.result,
            "threat_detected": entry.threat_detected,
            "threat_type": entry.threat_type,
            "action_taken": entry.action_taken,
            "metadata": entry.metadata
        }
        
        self.logger.info(json.dumps(log_data, ensure_ascii=False))
    
    @staticmethod
    def hash_input(text: str) -> str:
        """ì…ë ¥ í…ìŠ¤íŠ¸ì˜ SHA-256 í•´ì‹œ ìƒì„±"""
        return hashlib.sha256(text.encode()).hexdigest()[:16]

# ============================================================================
# Security Orchestrator - í†µí•© ë³´ì•ˆ íŒŒì´í”„ë¼ì¸
# ============================================================================

class SecurityOrchestrator:
    """
    ë³´ì•ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° - í†µí•© ë³´ì•ˆ ê²€ì¦ íŒŒì´í”„ë¼ì¸
    
    ================================================================================
    ğŸ“‹ ì—­í• : ëª¨ë“  ë³´ì•ˆ ì»´í¬ë„ŒíŠ¸ë¥¼ ì¡°ìœ¨í•˜ì—¬ ì…ë ¥/ì¶œë ¥ ê²€ì¦ ìˆ˜í–‰
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================
    
    ğŸ¯ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°:
        Input â†’ [PromptShield] â†’ [JailbreakDetector] â†’ [PIIDetector] â†’ Validated Input
        Output â†’ [OutputValidator] â†’ [GroundednessChecker] â†’ Validated Output
    
    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> orchestrator = SecurityOrchestrator(SecurityConfig(
        ...     threat_level=ThreatLevel.HIGH,
        ...     enable_prompt_shield=True,
        ...     enable_jailbreak_detection=True,
        ...     azure_content_safety_endpoint="https://xxx.cognitiveservices.azure.com",
        ...     azure_content_safety_key="your-key"
        ... ))
        >>>
        >>> # ì…ë ¥ ê²€ì¦
        >>> input_result = await orchestrator.validate_input(user_input)
        >>> if not input_result.is_safe:
        ...     print(f"ì°¨ë‹¨: {input_result.blocked_reason}")
        ...     return
        >>>
        >>> # (AI ì²˜ë¦¬)
        >>> ai_response = await call_ai(input_result.sanitized_input)
        >>>
        >>> # ì¶œë ¥ ê²€ì¦
        >>> output_result = await orchestrator.validate_output(ai_response, sources)
        >>> if output_result.is_safe:
        ...     return output_result.sanitized_input  # ì •í™”ëœ ì¶œë ¥
    """
    
    def __init__(self, config: SecurityConfig | None = None):
        """
        SecurityOrchestrator ì´ˆê¸°í™”
        
        Args:
            config: ë³´ì•ˆ ì„¤ì • (ê¸°ë³¸ê°’ ì‚¬ìš© ì‹œ None)
        """
        self.config = config or SecurityConfig()
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.prompt_shield = PromptShield(
            azure_endpoint=self.config.azure_content_safety_endpoint,
            azure_key=self.config.azure_content_safety_key,
            custom_patterns=self.config.custom_blocked_patterns
        ) if self.config.enable_prompt_shield else None
        
        self.jailbreak_detector = JailbreakDetector(
            sensitivity=0.7 if self.config.threat_level in [ThreatLevel.HIGH, ThreatLevel.PARANOID] else 0.5
        ) if self.config.enable_jailbreak_detection else None
        
        self.pii_detector = PIIDetector(
            mask_char=self.config.pii_mask_char
        ) if self.config.enable_pii_detection else None
        
        self.output_validator = OutputValidator(
            pii_detector=self.pii_detector
        ) if self.config.enable_output_validation else None
        
        self.groundedness_checker = GroundednessChecker(
            azure_endpoint=self.config.azure_content_safety_endpoint,
            azure_key=self.config.azure_content_safety_key
        ) if self.config.enable_groundedness_check else None
        
        self.audit_logger = SecurityAuditLogger() if self.config.enable_audit_logging else None
        
        self.logger = logging.getLogger(__name__)
    
    async def validate_input(
        self,
        text: str,
        session_id: str = "",
        documents: list[str] | None = None
    ) -> ValidationResult:
        """
        ì‚¬ìš©ì ì…ë ¥ ê²€ì¦
        
        Args:
            text: ì‚¬ìš©ì ì…ë ¥
            session_id: ì„¸ì…˜ ID (ê°ì‚¬ ë¡œê·¸ìš©)
            documents: í•¨ê»˜ ê²€ì¦í•  ë¬¸ì„œ (ê°„ì ‘ ì£¼ì… íƒì§€)
        
        Returns:
            ValidationResult: ê²€ì¦ ê²°ê³¼
        """
        start_time = time.perf_counter()
        
        result = ValidationResult(stage=ValidationStage.INPUT)
        result.sanitized_input = text
        
        # ê¸¸ì´ ê²€ì‚¬
        if len(text) > self.config.max_input_length:
            result.is_safe = False
            result.blocked = True
            result.blocked_reason = f"ì…ë ¥ ê¸¸ì´ ì´ˆê³¼: {len(text)} > {self.config.max_input_length}"
            return result
        
        # 1. Prompt Shield ê²€ì‚¬
        if self.prompt_shield:
            use_api = self.config.threat_level in [ThreatLevel.HIGH, ThreatLevel.PARANOID]
            shield_result = await self.prompt_shield.analyze(text, documents, use_api=use_api)
            result.shield_result = shield_result
            
            if shield_result.is_attack:
                result.is_safe = False
                if self.config.block_on_detection:
                    result.blocked = True
                    result.blocked_reason = f"Prompt Injection íƒì§€: {shield_result.attack_type.value}"
                    self._log_audit(session_id, "input", text, "blocked", True, shield_result.attack_type.value)
                    result.total_processing_time_ms = (time.perf_counter() - start_time) * 1000
                    return result
        
        # 2. Jailbreak ê²€ì‚¬
        if self.jailbreak_detector:
            jailbreak_result = self.jailbreak_detector.detect(text)
            result.jailbreak_result = jailbreak_result
            
            if jailbreak_result.is_jailbreak:
                result.is_safe = False
                if self.config.block_on_detection and jailbreak_result.risk_score >= 50:
                    result.blocked = True
                    result.blocked_reason = f"Jailbreak ì‹œë„: {', '.join(jailbreak_result.detected_techniques)}"
                    self._log_audit(session_id, "input", text, "blocked", True, "jailbreak")
                    result.total_processing_time_ms = (time.perf_counter() - start_time) * 1000
                    return result
        
        # 3. PII íƒì§€ ë° ë§ˆìŠ¤í‚¹
        if self.pii_detector:
            pii_result = self.pii_detector.detect(text, mask=True)
            result.pii_result = pii_result
            
            if pii_result.has_pii:
                # PIIëŠ” ë§ˆìŠ¤í‚¹í•˜ê³  í†µê³¼ (ì°¨ë‹¨í•˜ì§€ ì•ŠìŒ)
                result.sanitized_input = pii_result.masked_text
                self.logger.info(f"PII íƒì§€ ë° ë§ˆìŠ¤í‚¹: {pii_result.pii_count}ê°œ")
        
        # ê°ì‚¬ ë¡œê·¸
        self._log_audit(session_id, "input", text, "passed" if result.is_safe else "flagged", not result.is_safe, None)
        
        result.total_processing_time_ms = (time.perf_counter() - start_time) * 1000
        return result
    
    async def validate_output(
        self,
        output: str,
        sources: list[str] | None = None,
        context: dict[str, Any] | None = None,
        session_id: str = ""
    ) -> ValidationResult:
        """
        AI ì¶œë ¥ ê²€ì¦
        
        Args:
            output: AI ëª¨ë¸ ì¶œë ¥
            sources: ì‘ë‹µ ìƒì„±ì— ì‚¬ìš©ëœ ì†ŒìŠ¤ (Groundedness ê²€ì‚¬ìš©)
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (system_prompt ë“±)
            session_id: ì„¸ì…˜ ID
        
        Returns:
            ValidationResult: ê²€ì¦ ê²°ê³¼
        """
        start_time = time.perf_counter()
        
        result = ValidationResult(stage=ValidationStage.OUTPUT)
        result.sanitized_input = output
        
        # 1. ì¶œë ¥ ê²€ì¦
        if self.output_validator:
            output_result = await self.output_validator.validate(output, context)
            if not output_result.is_safe:
                result.is_safe = False
                result.blocked = output_result.blocked
                result.blocked_reason = output_result.blocked_reason
                result.pii_result = output_result.pii_result
                self._log_audit(session_id, "output", output, "blocked", True, "output_validation_failed")
                result.total_processing_time_ms = (time.perf_counter() - start_time) * 1000
                return result
        
        # 2. Groundedness ê²€ì‚¬
        if self.groundedness_checker and sources:
            groundedness_result = await self.groundedness_checker.check(output, sources)
            result.groundedness_result = groundedness_result
            
            if not groundedness_result.is_grounded:
                # Groundedness ì‹¤íŒ¨ëŠ” ê²½ê³ ë§Œ (ì°¨ë‹¨í•˜ì§€ ì•ŠìŒ)
                self.logger.warning(f"Groundedness ê²€ì‚¬ ì‹¤íŒ¨: score={groundedness_result.groundedness_score:.2f}")
        
        # 3. PII ë§ˆìŠ¤í‚¹ (ì¶œë ¥ì—ì„œë„)
        if self.pii_detector:
            pii_result = self.pii_detector.detect(output, mask=True)
            if pii_result.has_pii:
                result.sanitized_input = pii_result.masked_text
                result.pii_result = pii_result
        
        self._log_audit(session_id, "output", output, "passed", False, None)
        result.total_processing_time_ms = (time.perf_counter() - start_time) * 1000
        return result
    
    def _log_audit(
        self,
        session_id: str,
        stage: str,
        text: str,
        result: str,
        threat_detected: bool,
        threat_type: str | None
    ) -> None:
        """ê°ì‚¬ ë¡œê·¸ ê¸°ë¡"""
        if self.audit_logger:
            entry = AuditLogEntry(
                session_id=session_id,
                stage=ValidationStage(stage),
                input_hash=SecurityAuditLogger.hash_input(text),
                result=result,
                threat_detected=threat_detected,
                threat_type=threat_type,
                action_taken="blocked" if threat_detected else "allowed"
            )
            self.audit_logger.log_event(entry)
