#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Concurrent Orchestration ì‹œìŠ¤í…œ - Fan-out/Fan-in íŒ¨í„´

================================================================================
ğŸ“‹ ì—­í• : ë³‘ë ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰ ë° ê²°ê³¼ ì§‘ê³„
ğŸ“… ë²„ì „: 3.4.0 (2026ë…„ 2ì›”)
ğŸ“¦ ì˜ê°: LangGraph Fan-out, Azure Durable Functions Fan-out/Fan-in
================================================================================

ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:
    - Fan-out: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
    - Fan-in: ê²°ê³¼ ìˆ˜ì§‘ ë° ì§‘ê³„
    - ì¡°ê±´ë¶€ ë³‘ë ¬í™”
    - ë™ì  ì—ì´ì „íŠ¸ ì„ íƒ
    - ê²°ê³¼ ì§‘ê³„ ì „ëµ (first, all, majority, weighted)
    - íƒ€ì„ì•„ì›ƒ ë° ì—ëŸ¬ ì²˜ë¦¬

ğŸ“Œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ë‹¤ì¤‘ ì „ë¬¸ê°€ ì˜ê²¬ ìˆ˜ì§‘
    - ë³‘ë ¬ API í˜¸ì¶œ
    - Map-Reduce íŒ¨í„´
    - ì•™ìƒë¸” ì—ì´ì „íŠ¸

ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
    >>> from unified_agent import (
    ...     ConcurrentOrchestrator, FanOutConfig,
    ...     AggregationStrategy
    ... )
    >>>
    >>> orchestrator = ConcurrentOrchestrator()
    >>>
    >>> # ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
    >>> results = await orchestrator.fan_out(
    ...     agents=[security_agent, performance_agent, style_agent],
    ...     input_data={"code": source_code},
    ...     strategy=AggregationStrategy.ALL,
    ... )
    >>>
    >>> # ê²°ê³¼ ì§‘ê³„
    >>> final_result = await orchestrator.fan_in(
    ...     results,
    ...     aggregator=merge_reviews
    ... )
"""

from __future__ import annotations

import asyncio
import logging
import time
import uuid
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import (
    Any,
    Callable,
    Coroutine,
    Generic,
    TypeVar,
)

from .utils import StructuredLogger
from .models import NodeResult

__all__ = [
    # ì„¤ì •
    "FanOutConfig",
    "AggregationStrategy",
    # ê²°ê³¼
    "ParallelResult",
    "AggregatedResult",
    # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    "ConcurrentOrchestrator",
    # ì§‘ê³„ê¸°
    "ResultAggregator",
    "FirstCompleteAggregator",
    "AllCompleteAggregator",
    "MajorityVoteAggregator",
    "WeightedAggregator",
    # íŒ¨í„´
    "MapReducePattern",
    "ScatterGatherPattern",
]

# ============================================================================
# ì„¤ì • ë° ì „ëµ
# ============================================================================

class AggregationStrategy(str, Enum):
    """ê²°ê³¼ ì§‘ê³„ ì „ëµ"""
    FIRST = "first"           # ì²« ë²ˆì§¸ ì™„ë£Œ ê²°ê³¼
    ALL = "all"               # ëª¨ë“  ê²°ê³¼ (ì‹¤íŒ¨ í¬í•¨)
    ALL_SUCCESS = "all_success"  # ëª¨ë“  ì„±ê³µ ê²°ê³¼ë§Œ
    MAJORITY = "majority"     # ë‹¤ìˆ˜ê²°
    WEIGHTED = "weighted"     # ê°€ì¤‘ì¹˜ ê¸°ë°˜
    CUSTOM = "custom"         # ì»¤ìŠ¤í…€ ì§‘ê³„ê¸°

@dataclass(frozen=True, slots=True)
class FanOutConfig:
    """
    Fan-out ì„¤ì •
    
    Args:
        max_concurrency: ìµœëŒ€ ë™ì‹œ ì‹¤í–‰ ìˆ˜
        timeout_seconds: ì „ì²´ íƒ€ì„ì•„ì›ƒ
        per_agent_timeout: ì—ì´ì „íŠ¸ë³„ íƒ€ì„ì•„ì›ƒ
        fail_fast: ì²« ì‹¤íŒ¨ ì‹œ ì „ì²´ ì¤‘ë‹¨
        strategy: ì§‘ê³„ ì „ëµ
        min_success_count: ìµœì†Œ ì„±ê³µ ìˆ˜ (ALL_SUCCESSìš©)
    """
    max_concurrency: int = 10
    timeout_seconds: float = 300.0
    per_agent_timeout: float = 60.0
    fail_fast: bool = False
    strategy: AggregationStrategy = AggregationStrategy.ALL
    min_success_count: int = 1

@dataclass(slots=True)
class ParallelResult:
    """ë³‘ë ¬ ì‹¤í–‰ ê°œë³„ ê²°ê³¼"""
    agent_id: str
    agent_name: str
    success: bool
    result: Any = None
    error: str | None = None
    duration_ms: float = 0.0
    started_at: datetime | None = None
    completed_at: datetime | None = None
    metadata: dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> dict[str, Any]:
        return {
            "agent_id": self.agent_id,
            "agent_name": self.agent_name,
            "success": self.success,
            "result": self.result,
            "error": self.error,
            "duration_ms": self.duration_ms,
        }

@dataclass(frozen=True, slots=True)
class AggregatedResult:
    """ì§‘ê³„ëœ ìµœì¢… ê²°ê³¼"""
    success: bool
    strategy: AggregationStrategy
    results: list[ParallelResult]
    aggregated_value: Any = None
    total_duration_ms: float = 0.0
    success_count: int = 0
    failure_count: int = 0
    metadata: dict[str, Any] = field(default_factory=dict)
    
    @property
    def successful_results(self) -> list[ParallelResult]:
        return [r for r in self.results if r.success]
    
    @property
    def failed_results(self) -> list[ParallelResult]:
        return [r for r in self.results if not r.success]
    
    def to_dict(self) -> dict[str, Any]:
        return {
            "success": self.success,
            "strategy": self.strategy.value,
            "aggregated_value": self.aggregated_value,
            "total_duration_ms": self.total_duration_ms,
            "success_count": self.success_count,
            "failure_count": self.failure_count,
            "results": [r.to_dict() for r in self.results],
        }

# ============================================================================
# ê²°ê³¼ ì§‘ê³„ê¸°
# ============================================================================

T = TypeVar("T")

class ResultAggregator(ABC, Generic[T]):
    """ê²°ê³¼ ì§‘ê³„ê¸° ì¶”ìƒ í´ë˜ìŠ¤"""
    
    @abstractmethod
    def aggregate(self, results: list[ParallelResult]) -> T:
        """ê²°ê³¼ ì§‘ê³„"""
        pass

class FirstCompleteAggregator(ResultAggregator[Any]):
    """ì²« ë²ˆì§¸ ì™„ë£Œ ê²°ê³¼ ë°˜í™˜"""
    
    def aggregate(self, results: list[ParallelResult]) -> Any:
        for result in results:
            if result.success:
                return result.result
        return None

class AllCompleteAggregator(ResultAggregator[list[Any]]):
    """ëª¨ë“  ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
    
    def __init__(self, include_failures: bool = True):
        self.include_failures = include_failures
    
    def aggregate(self, results: list[ParallelResult]) -> list[Any]:
        if self.include_failures:
            return [r.result for r in results]
        return [r.result for r in results if r.success]

class MajorityVoteAggregator(ResultAggregator[Any]):
    """ë‹¤ìˆ˜ê²° ì§‘ê³„"""
    
    def __init__(self, key_func: Callable[[Any], Any] | None = None):
        self.key_func = key_func or (lambda x: x)
    
    def aggregate(self, results: list[ParallelResult]) -> Any:
        votes: dict[Any, int] = {}
        
        for result in results:
            if not result.success:
                continue
            
            key = self.key_func(result.result)
            votes[key] = votes.get(key, 0) + 1
        
        if not votes:
            return None
        
        return max(votes.keys(), key=lambda k: votes[k])

class WeightedAggregator(ResultAggregator[Any]):
    """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì§‘ê³„"""
    
    def __init__(self, weights: dict[str, float]):
        self.weights = weights
    
    def aggregate(self, results: list[ParallelResult]) -> Any:
        weighted_results: list[tuple[Any, float]] = []
        
        for result in results:
            if not result.success:
                continue
            
            weight = self.weights.get(result.agent_id, 1.0)
            weighted_results.append((result.result, weight))
        
        if not weighted_results:
            return None
        
        # ê°€ì¥ ë†’ì€ ê°€ì¤‘ì¹˜ ê²°ê³¼ ë°˜í™˜
        return max(weighted_results, key=lambda x: x[1])[0]

# ============================================================================
# Concurrent Orchestrator
# ============================================================================

class ConcurrentOrchestrator:
    """
    ë™ì‹œ ì‹¤í–‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
    
    Fan-out/Fan-in íŒ¨í„´ì„ ì‚¬ìš©í•œ ë³‘ë ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> orchestrator = ConcurrentOrchestrator()
        >>>
        >>> # ë‹¨ìˆœ ë³‘ë ¬ ì‹¤í–‰
        >>> results = await orchestrator.fan_out(
        ...     agents=my_agents,
        ...     input_data={"query": "ë¶„ì„í•´ì£¼ì„¸ìš”"}
        ... )
        >>>
        >>> # Map-Reduce íŒ¨í„´
        >>> result = await orchestrator.map_reduce(
        ...     items=data_chunks,
        ...     map_func=process_chunk,
        ...     reduce_func=merge_results
        ... )
    """
    
    def __init__(self, config: FanOutConfig | None = None):
        self.config = config or FanOutConfig()
        self._logger = StructuredLogger("concurrent_orchestrator")
        self._active_tasks: dict[str, asyncio.Task] = {}
    
    async def fan_out(
        self,
        agents: list[Any],
        input_data: dict[str, Any],
        config: FanOutConfig | None = None,
        agent_configs: dict[str, dict[str, Any]] | None = None,
    ) -> list[ParallelResult]:
        """
        Fan-out: ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
        
        Args:
            agents: ì—ì´ì „íŠ¸ ë¦¬ìŠ¤íŠ¸ (ë˜ëŠ” Callable ë¦¬ìŠ¤íŠ¸)
            input_data: ê³µí†µ ì…ë ¥ ë°ì´í„°
            config: Fan-out ì„¤ì •
            agent_configs: ì—ì´ì „íŠ¸ë³„ ì¶”ê°€ ì„¤ì •
            
        Returns:
            ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        config = config or self.config
        agent_configs = agent_configs or {}
        
        execution_id = str(uuid.uuid4())[:8]
        start_time = time.time()
        
        self._logger.info(
            "Fan-out started",
            execution_id=execution_id,
            agent_count=len(agents),
            max_concurrency=config.max_concurrency
        )
        
        # ì„¸ë§ˆí¬ì–´ë¡œ ë™ì‹œì„± ì œì–´
        semaphore = asyncio.Semaphore(config.max_concurrency)
        
        async def execute_agent(agent, agent_id: str) -> ParallelResult:
            """ê°œë³„ ì—ì´ì „íŠ¸ ì‹¤í–‰"""
            async with semaphore:
                result = ParallelResult(
                    agent_id=agent_id,
                    agent_name=getattr(agent, 'name', agent_id),
                    success=False,
                    started_at=datetime.now(timezone.utc),
                )
                
                agent_config = agent_configs.get(agent_id, {})
                timeout = agent_config.get('timeout', config.per_agent_timeout)
                
                try:
                    agent_start = time.time()
                    
                    # ì—ì´ì „íŠ¸ ì‹¤í–‰ (ë‹¤ì–‘í•œ ì¸í„°í˜ì´ìŠ¤ ì§€ì›)
                    if asyncio.iscoroutinefunction(agent):
                        output = await asyncio.wait_for(
                            agent(input_data),
                            timeout=timeout
                        )
                    elif hasattr(agent, 'execute'):
                        output = await asyncio.wait_for(
                            agent.execute(input_data),
                            timeout=timeout
                        )
                    elif hasattr(agent, 'run'):
                        output = await asyncio.wait_for(
                            agent.run(input_data),
                            timeout=timeout
                        )
                    elif callable(agent):
                        output = await asyncio.wait_for(
                            asyncio.to_thread(agent, input_data),
                            timeout=timeout
                        )
                    else:
                        raise TypeError(f"Agent {agent_id} is not callable")
                    
                    result.success = True
                    result.result = output
                    result.duration_ms = (time.time() - agent_start) * 1000
                    
                except asyncio.TimeoutError:
                    result.error = f"Timeout after {timeout}s"
                    
                except Exception as e:
                    result.error = str(e)
                    
                finally:
                    result.completed_at = datetime.now(timezone.utc)
                
                return result
        
        # ëª¨ë“  ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
        tasks = []
        for i, agent in enumerate(agents):
            agent_id = getattr(agent, 'id', None) or getattr(agent, 'name', None) or f"agent_{i}"
            task = asyncio.create_task(execute_agent(agent, agent_id))
            tasks.append(task)
            self._active_tasks[f"{execution_id}_{agent_id}"] = task
        
        # ì „ì²´ íƒ€ì„ì•„ì›ƒ ì ìš©
        try:
            if config.fail_fast:
                # ì²« ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨
                results = []
                for task in asyncio.as_completed(tasks):
                    result = await asyncio.wait_for(task, timeout=config.timeout_seconds)
                    results.append(result)
                    if not result.success and config.fail_fast:
                        # ë‚˜ë¨¸ì§€ íƒœìŠ¤í¬ ì·¨ì†Œ
                        for t in tasks:
                            if not t.done():
                                t.cancel()
                        break
            else:
                # ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
                results = await asyncio.wait_for(
                    asyncio.gather(*tasks, return_exceptions=True),
                    timeout=config.timeout_seconds
                )
                # Exceptionì„ ParallelResultë¡œ ë³€í™˜
                results = [
                    r if isinstance(r, ParallelResult)
                    else ParallelResult(
                        agent_id=f"agent_{i}",
                        agent_name=f"agent_{i}",
                        success=False,
                        error=str(r)
                    )
                    for i, r in enumerate(results)
                ]
                
        except asyncio.TimeoutError:
            self._logger.warning("Fan-out timeout", execution_id=execution_id)
            results = []
            for task in tasks:
                if task.done():
                    try:
                        results.append(task.result())
                    except Exception as e:
                        results.append(ParallelResult(
                            agent_id="unknown",
                            agent_name="unknown",
                            success=False,
                            error=str(e)
                        ))
                else:
                    task.cancel()
        
        # íƒœìŠ¤í¬ ì •ë¦¬
        for key in list(self._active_tasks.keys()):
            if key.startswith(execution_id):
                del self._active_tasks[key]
        
        total_duration = (time.time() - start_time) * 1000
        success_count = sum(1 for r in results if r.success)
        
        self._logger.info(
            "Fan-out completed",
            execution_id=execution_id,
            total=len(results),
            success=success_count,
            duration_ms=total_duration
        )
        
        return results
    
    async def fan_in(
        self,
        results: list[ParallelResult],
        strategy: AggregationStrategy | None = None,
        aggregator: ResultAggregator | None = None,
        custom_func: Callable[[list[ParallelResult]], Any] | None = None,
    ) -> AggregatedResult:
        """
        Fan-in: ê²°ê³¼ ìˆ˜ì§‘ ë° ì§‘ê³„
        
        Args:
            results: ë³‘ë ¬ ì‹¤í–‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            strategy: ì§‘ê³„ ì „ëµ
            aggregator: ì»¤ìŠ¤í…€ ì§‘ê³„ê¸°
            custom_func: ì»¤ìŠ¤í…€ ì§‘ê³„ í•¨ìˆ˜
            
        Returns:
            ì§‘ê³„ëœ ê²°ê³¼
        """
        strategy = strategy or self.config.strategy
        
        success_count = sum(1 for r in results if r.success)
        failure_count = len(results) - success_count
        total_duration = sum(r.duration_ms for r in results)
        
        aggregated_value = None
        
        # ì§‘ê³„ ìˆ˜í–‰
        if aggregator:
            aggregated_value = aggregator.aggregate(results)
        elif custom_func:
            aggregated_value = custom_func(results)
        elif strategy == AggregationStrategy.FIRST:
            aggregator = FirstCompleteAggregator()
            aggregated_value = aggregator.aggregate(results)
        elif strategy == AggregationStrategy.ALL:
            aggregator = AllCompleteAggregator(include_failures=True)
            aggregated_value = aggregator.aggregate(results)
        elif strategy == AggregationStrategy.ALL_SUCCESS:
            aggregator = AllCompleteAggregator(include_failures=False)
            aggregated_value = aggregator.aggregate(results)
        elif strategy == AggregationStrategy.MAJORITY:
            aggregator = MajorityVoteAggregator()
            aggregated_value = aggregator.aggregate(results)
        elif strategy == AggregationStrategy.WEIGHTED:
            # ê¸°ë³¸ ê°€ì¤‘ì¹˜ (ë™ì¼)
            weights = {r.agent_id: 1.0 for r in results}
            aggregator = WeightedAggregator(weights)
            aggregated_value = aggregator.aggregate(results)
        
        # ì„±ê³µ ì—¬ë¶€ íŒë‹¨
        success = success_count >= self.config.min_success_count
        
        return AggregatedResult(
            success=success,
            strategy=strategy,
            results=results,
            aggregated_value=aggregated_value,
            total_duration_ms=total_duration,
            success_count=success_count,
            failure_count=failure_count,
        )
    
    async def fan_out_fan_in(
        self,
        agents: list[Any],
        input_data: dict[str, Any],
        config: FanOutConfig | None = None,
        aggregator: ResultAggregator | None = None,
    ) -> AggregatedResult:
        """
        Fan-out/Fan-in í•œ ë²ˆì— ì‹¤í–‰
        
        Args:
            agents: ì—ì´ì „íŠ¸ ë¦¬ìŠ¤íŠ¸
            input_data: ì…ë ¥ ë°ì´í„°
            config: ì„¤ì •
            aggregator: ì§‘ê³„ê¸°
            
        Returns:
            ì§‘ê³„ëœ ê²°ê³¼
        """
        config = config or self.config
        results = await self.fan_out(agents, input_data, config)
        return await self.fan_in(results, config.strategy, aggregator)

# ============================================================================
# ê³ ê¸‰ íŒ¨í„´
# ============================================================================

class MapReducePattern:
    """
    Map-Reduce íŒ¨í„´
    
    ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ ë³‘ë ¬ ì²˜ë¦¬ í›„ ê²°ê³¼ í•©ì¹˜ê¸°
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> pattern = MapReducePattern(orchestrator)
        >>> result = await pattern.execute(
        ...     items=large_dataset,
        ...     map_func=process_item,
        ...     reduce_func=merge_results,
        ...     chunk_size=100
        ... )
    """
    
    def __init__(
        self,
        orchestrator: ConcurrentOrchestrator | None = None,
        config: FanOutConfig | None = None,
    ):
        self.orchestrator = orchestrator or ConcurrentOrchestrator(config)
        self._logger = StructuredLogger("map_reduce")
    
    async def execute(
        self,
        items: list[Any],
        map_func: Callable[[Any], Coroutine[Any, Any, Any]],
        reduce_func: Callable[[list[Any]], Any],
        chunk_size: int = 10,
    ) -> Any:
        """
        Map-Reduce ì‹¤í–‰
        
        Args:
            items: ì²˜ë¦¬í•  ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸
            map_func: Map í•¨ìˆ˜ (ê° ì•„ì´í…œ ì²˜ë¦¬)
            reduce_func: Reduce í•¨ìˆ˜ (ê²°ê³¼ í•©ì¹˜ê¸°)
            chunk_size: ì²­í¬ í¬ê¸°
            
        Returns:
            ìµœì¢… ê²°ê³¼
        """
        # ì²­í¬ ë¶„í• 
        chunks = [items[i:i + chunk_size] for i in range(0, len(items), chunk_size)]
        
        self._logger.info(
            "Map-Reduce started",
            total_items=len(items),
            chunks=len(chunks),
            chunk_size=chunk_size
        )
        
        # Map ë‹¨ê³„: ê° ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬
        async def process_chunk(chunk_data: dict[str, Any]) -> list[Any]:
            chunk = chunk_data["chunk"]
            results = []
            for item in chunk:
                result = await map_func(item)
                results.append(result)
            return results
        
        chunk_agents = [
            lambda data, c=chunk: process_chunk({"chunk": c})
            for chunk in chunks
        ]
        
        # Fan-out
        parallel_results = await self.orchestrator.fan_out(
            agents=chunk_agents,
            input_data={}
        )
        
        # Reduce ë‹¨ê³„: ê²°ê³¼ í•©ì¹˜ê¸°
        all_mapped = []
        for result in parallel_results:
            if result.success and result.result:
                all_mapped.extend(result.result)
        
        final_result = reduce_func(all_mapped)
        
        self._logger.info(
            "Map-Reduce completed",
            mapped_count=len(all_mapped),
        )
        
        return final_result

class ScatterGatherPattern:
    """
    Scatter-Gather íŒ¨í„´
    
    ìš”ì²­ì„ ì—¬ëŸ¬ ì„œë¹„ìŠ¤ì— ë¶„ì‚°í•˜ê³  ê²°ê³¼ ìˆ˜ì§‘
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> pattern = ScatterGatherPattern(orchestrator)
        >>> results = await pattern.execute(
        ...     request={"query": "ê²€ìƒ‰ì–´"},
        ...     services=[google_search, bing_search, duckduckgo],
        ...     timeout=10
        ... )
    """
    
    def __init__(
        self,
        orchestrator: ConcurrentOrchestrator | None = None,
    ):
        self.orchestrator = orchestrator or ConcurrentOrchestrator()
        self._logger = StructuredLogger("scatter_gather")
    
    async def execute(
        self,
        request: dict[str, Any],
        services: list[Callable],
        timeout: float = 30.0,
        min_responses: int = 1,
    ) -> AggregatedResult:
        """
        Scatter-Gather ì‹¤í–‰
        
        Args:
            request: ìš”ì²­ ë°ì´í„°
            services: ì„œë¹„ìŠ¤ ë¦¬ìŠ¤íŠ¸ (Callable)
            timeout: íƒ€ì„ì•„ì›ƒ
            min_responses: ìµœì†Œ ì‘ë‹µ ìˆ˜
            
        Returns:
            ì§‘ê³„ëœ ê²°ê³¼
        """
        config = FanOutConfig(
            timeout_seconds=timeout,
            per_agent_timeout=timeout,
            strategy=AggregationStrategy.ALL_SUCCESS,
            min_success_count=min_responses,
        )
        
        self._logger.info(
            "Scatter-Gather started",
            service_count=len(services),
            timeout=timeout
        )
        
        results = await self.orchestrator.fan_out(
            agents=services,
            input_data=request,
            config=config,
        )
        
        return await self.orchestrator.fan_in(
            results,
            strategy=AggregationStrategy.ALL_SUCCESS
        )

# ============================================================================
# ì¡°ê±´ë¶€ ë¶„ê¸° Fan-out
# ============================================================================

class ConditionalFanOut:
    """
    ì¡°ê±´ë¶€ Fan-out
    
    ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ì§‘í•© ì‹¤í–‰
    
    ì‚¬ìš© ì˜ˆì‹œ:
        >>> fan_out = ConditionalFanOut()
        >>> fan_out.add_branch(
        ...     condition=lambda x: x["type"] == "code",
        ...     agents=[security_agent, performance_agent]
        ... )
        >>> fan_out.add_branch(
        ...     condition=lambda x: x["type"] == "text",
        ...     agents=[grammar_agent, style_agent]
        ... )
        >>> results = await fan_out.execute(input_data)
    """
    
    def __init__(self, orchestrator: ConcurrentOrchestrator | None = None):
        self.orchestrator = orchestrator or ConcurrentOrchestrator()
        self._branches: list[tuple[Callable, list[Any]]] = []
        self._default_agents: list[Any] = []
        self._logger = StructuredLogger("conditional_fan_out")
    
    def add_branch(
        self,
        condition: Callable[[dict[str, Any]], bool],
        agents: list[Any],
    ):
        """ì¡°ê±´ë¶€ ë¸Œëœì¹˜ ì¶”ê°€"""
        self._branches.append((condition, agents))
    
    def set_default(self, agents: list[Any]):
        """ê¸°ë³¸ ì—ì´ì „íŠ¸ ì„¤ì •"""
        self._default_agents = agents
    
    async def execute(
        self,
        input_data: dict[str, Any],
        config: FanOutConfig | None = None,
    ) -> AggregatedResult:
        """
        ì¡°ê±´ë¶€ Fan-out ì‹¤í–‰
        
        Args:
            input_data: ì…ë ¥ ë°ì´í„°
            config: Fan-out ì„¤ì •
            
        Returns:
            ì§‘ê³„ëœ ê²°ê³¼
        """
        # ì¡°ê±´ í‰ê°€í•˜ì—¬ ì—ì´ì „íŠ¸ ì„ íƒ
        selected_agents = []
        
        for condition, agents in self._branches:
            if condition(input_data):
                selected_agents.extend(agents)
                self._logger.debug(
                    "Branch matched",
                    agent_count=len(agents)
                )
        
        # ì„ íƒëœ ì—ì´ì „íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‚¬ìš©
        if not selected_agents:
            selected_agents = self._default_agents
        
        if not selected_agents:
            return AggregatedResult(
                success=False,
                strategy=AggregationStrategy.ALL,
                results=[],
                aggregated_value=None,
            )
        
        self._logger.info(
            "Conditional fan-out",
            selected_count=len(selected_agents)
        )
        
        return await self.orchestrator.fan_out_fan_in(
            agents=selected_agents,
            input_data=input_data,
            config=config,
        )
