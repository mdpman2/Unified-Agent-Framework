#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Agent Framework - ì—ì´ì „íŠ¸ ëª¨ë“ˆ (Agents Module)

================================================================================
ğŸ“ íŒŒì¼ ìœ„ì¹˜: unified_agent/agents.py
ğŸ“‹ ì—­í• : Agent ê¸°ë³¸ í´ë˜ìŠ¤ ë° ë‹¤ì–‘í•œ ì—ì´ì „íŠ¸ êµ¬í˜„ì²´ ì œê³µ
ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 1ì›”
================================================================================

ğŸ¯ ì—ì´ì „íŠ¸ ê³„ì¸µ êµ¬ì¡°:

    Agent (ABC)  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤
        â”œâ”€â”€ SimpleAgent          ë‹¨ìˆœ LLM í˜¸ì¶œ ì—ì´ì „íŠ¸
        â”œâ”€â”€ ApprovalAgent        Human-in-the-loop ìŠ¹ì¸ ì—ì´ì „íŠ¸
        â”œâ”€â”€ RouterAgent          ìš”ì²­ ë¼ìš°íŒ… ì—ì´ì „íŠ¸
        â”œâ”€â”€ ProxyAgent           ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ìœ„ì„ ì—ì´ì „íŠ¸
        â””â”€â”€ SupervisorAgent      ë©€í‹° ì—ì´ì „íŠ¸ ê°ë… ì—ì´ì „íŠ¸

ğŸ“Œ ì—ì´ì „íŠ¸ ìœ í˜•ë³„ ì„¤ëª…:

    1. SimpleAgent
       - ê°€ì¥ ê¸°ë³¸ì ì¸ ì—ì´ì „íŠ¸
       - LLMì— ë©”ì‹œì§€ë¥¼ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ìŒ
       - ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì›

    2. ApprovalAgent
       - ìœ„í—˜í•œ ì‘ì—… ì‹¤í–‰ ì „ ì‚¬ìš©ì ìŠ¹ì¸ í•„ìš”
       - Human-in-the-loop íŒ¨í„´ êµ¬í˜„
       - ìë™ ìŠ¹ì¸ ê·œì¹™ ì„¤ì • ê°€ëŠ¥

    3. RouterAgent
       - ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…
       - ì˜ë„ ë¶„ë¥˜ ë° ì „ë¬¸ ì—ì´ì „íŠ¸ ì„ íƒ
       - A/B í…ŒìŠ¤íŠ¸ ë° ì‹¤í—˜ ê°€ëŠ¥

    4. ProxyAgent
       - ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì—ê²Œ ì‘ì—…ì„ ìœ„ì„
       - ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í†µí•©
       - Handoff íŒ¨í„´ êµ¬í˜„

    5. SupervisorAgent (Microsoft Agent Framework íŒ¨í„´)
       - ì—¬ëŸ¬ ì—ì´ì „íŠ¸ë¥¼ ê°ë…í•˜ê³  ì¡°ìœ¨
       - ê³„íš ìˆ˜ë¦½ ë° ì‹¤í–‰ ê´€ë¦¬
       - ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… ì¡°ì •

ğŸ”§ ê³µí†µ ê¸°ëŠ¥ (Agent ê¸°ë³¸ í´ë˜ìŠ¤):
    - enable_streaming: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì›
    - event_bus: ì´ë²¤íŠ¸ ë°œí–‰ (ì‘ì—… ì‹œì‘/ì™„ë£Œ/ì˜¤ë¥˜ ë“±)
    - circuit_breaker: íšŒë¡œ ì°¨ë‹¨ê¸° í†µí•© (ì¥ì•  ì „íŒŒ ë°©ì§€)
    - ë©”íŠ¸ë¦­ ì¶”ì : total_executions, total_tokens, total_duration_ms

ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:

    ì˜ˆì œ 1: SimpleAgent
    ----------------------------------------
    >>> from unified_agent.agents import SimpleAgent
    >>> from unified_agent.models import AgentRole
    >>>
    >>> agent = SimpleAgent(
    ...     name="assistant",
    ...     role=AgentRole.ASSISTANT,
    ...     system_prompt="You are a helpful assistant.",
    ...     model="gpt-5.2",
    ...     enable_streaming=True
    ... )
    >>>
    >>> result = await agent.execute(state, kernel)

    ì˜ˆì œ 2: SupervisorAgent (ë©€í‹° ì—ì´ì „íŠ¸)
    ----------------------------------------
    >>> from unified_agent.agents import SupervisorAgent
    >>>
    >>> supervisor = SupervisorAgent(
    ...     name="supervisor",
    ...     managed_agents=[researcher, writer, reviewer],
    ...     max_rounds=10
    ... )
    >>>
    >>> # Supervisorê°€ ì—ì´ì „íŠ¸ë¥¼ ì¡°ìœ¨í•˜ì—¬ ì‘ì—… ìˆ˜í–‰
    >>> result = await supervisor.execute(state, kernel)

âš ï¸ ì£¼ì˜ì‚¬í•­:
    - ëª¨ë“  execute() ë©”ì„œë“œëŠ” ë¹„ë™ê¸°(async)ì…ë‹ˆë‹¤.
    - Kernelì€ Semantic Kernel ì¸ìŠ¤í„´ìŠ¤ì…ë‹ˆë‹¤.
    - circuit_breakerëŠ” LLM API í˜¸ì¶œ ì¥ì•  ì‹œ ë°œë™í•©ë‹ˆë‹¤.
    - event_busê°€ ì„¤ì •ë˜ë©´ ì‘ì—… ì´ë²¤íŠ¸ê°€ ìë™ ë°œí–‰ë©ë‹ˆë‹¤.

ğŸ”— ì°¸ê³ :
    - Semantic Kernel: https://github.com/microsoft/semantic-kernel
    - Microsoft Agent Framework: https://github.com/microsoft/agent-framework
    - Circuit Breaker: unified_agent.utils.CircuitBreaker
"""

import re
import json
import time
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any, Callable

from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase
from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior
from semantic_kernel.contents.chat_history import ChatHistory
from semantic_kernel.contents.streaming_chat_message_content import StreamingChatMessageContent

from .config import DEFAULT_LLM_MODEL, create_execution_settings
from .models import (
    AgentRole, AgentState, Message, NodeResult, ExecutionStatus,
    ApprovalStatus, WebSocketMessageType, StreamingMessage
)
from .events import EventType, AgentEvent, EventBus
from .tools import ApprovalRequiredAIFunction
from .utils import CircuitBreaker

__all__ = [
    "Agent",
    "SimpleAgent",
    "ApprovalAgent",
    "RouterAgent",
    "ProxyAgent",
    "InvestigationPlan",
    "SupervisorAgent",
]


# ============================================================================
# Agent ê¸°ë³¸ í´ë˜ìŠ¤
# ============================================================================

class Agent(ABC):
    """
    Agent ì¶”ìƒ ê¸°ë³¸ í´ë˜ìŠ¤ (Abstract Base Class)

    ================================================================================
    ğŸ“‹ ì—­í• : ëª¨ë“  ì—ì´ì „íŠ¸ì˜ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ ë° ê¸°ë³¸ ê¸°ëŠ¥ ì œê³µ
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 1ì›”
    ================================================================================

    ğŸ¯ í•µì‹¬ ê¸°ëŠ¥:
        1. enable_streaming: ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì§€ì› (ì‹¤ì‹œê°„ í† í° ì¶œë ¥)
        2. event_bus: ì´ë²¤íŠ¸ ë°œí–‰ (ì‘ì—… ì‹œì‘/ì™„ë£Œ/ì˜¤ë¥˜ í†µì§€)
        3. circuit_breaker: íšŒë¡œ ì°¨ë‹¨ê¸° (ì¥ì•  ì „íŒŒ ë°©ì§€)
        4. ë©”íŠ¸ë¦­ ì¶”ì : ì‹¤í–‰ íšŸìˆ˜, í† í° ì‚¬ìš©ëŸ‰, ì‹¤í–‰ ì‹œê°„

    ğŸ”§ ê°€ìƒ ë©”ì„œë“œ (êµ¬í˜„ í•„ìˆ˜):
        - execute(state, kernel) -> NodeResult
          ì—ì´ì „íŠ¸ì˜ ìµœì‹  ì‹¤í–‰ ë¡œì§

    ğŸ”§ ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œ (ìƒì† ê°€ëŠ¥):
        - _get_llm_response(): LLM API í˜¸ì¶œ
        - _stream_response(): ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
        - _emit_event(): ì´ë²¤íŠ¸ ë°œí–‰

    Args:
        name (str): ì—ì´ì „íŠ¸ ê³ ìœ  ì´ë¦„
        role (AgentRole): ì—ì´ì „íŠ¸ ì—­í•  (ê¸°ë³¸: ASSISTANT)
        system_prompt (str): ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        model (str): LLM ëª¨ë¸ëª… (ê¸°ë³¸: DEFAULT_LLM_MODEL)
        temperature (float): ìƒì„± ì˜¨ë„ (ê¸°ë³¸: 0.7)
        max_tokens (int): ìµœëŒ€ ìƒì„± í† í° (ê¸°ë³¸: 1000)
        enable_streaming (bool): ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™” (ê¸°ë³¸: False)
        event_bus (EventBus): ì´ë²¤íŠ¸ ë²„ìŠ¤ (ì„ íƒ)
        service_id (str): Semantic Kernel ì„œë¹„ìŠ¤ ID (ì„ íƒ)

    ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
        >>> class MyCustomAgent(Agent):
        ...     async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        ...         # ì»¤ìŠ¤í…€ ë¡œì§ êµ¬í˜„
        ...         response = await self._get_llm_response(kernel, state.messages)
        ...         return NodeResult(
        ...             agent_name=self.name,
        ...             content=response,
        ...             status=ExecutionStatus.COMPLETED
        ...         )

    âš ï¸ ì£¼ì˜ì‚¬í•­:
        - Reasoning ëª¨ë¸(o3, o4-mini ë“±)ì€ temperatureê°€ ë¬´ì‹œë©ë‹ˆë‹¤.
        - circuit_breakerëŠ” 3íšŒ ì—°ì† ì‹¤íŒ¨ ì‹œ ìë™ OPEN ìƒíƒœë¡œ ì „í™˜ë©ë‹ˆë‹¤.
        - event_busê°€ ì—†ìœ¼ë©´ ì´ë²¤íŠ¸ê°€ ë°œí–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    ğŸ”— ì°¸ê³ :
        - Semantic Kernel: https://github.com/microsoft/semantic-kernel
        - CircuitBreaker: unified_agent.utils.CircuitBreaker
        - EventBus: unified_agent.events.EventBus
    """

    def __init__(
        self,
        name: str,
        role: AgentRole = AgentRole.ASSISTANT,
        system_prompt: str = "You are a helpful AI assistant.",
        model: str = DEFAULT_LLM_MODEL,
        temperature: float = 0.7,
        max_tokens: int = 1000,
        enable_streaming: bool = False,
        event_bus: Optional[EventBus] = None,
        service_id: Optional[str] = None
    ):
        self.name = name
        self.role = role
        self.system_prompt = system_prompt
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.enable_streaming = enable_streaming
        self.event_bus = event_bus
        self.service_id = service_id

        # íšŒë¡œ ì°¨ë‹¨ê¸°
        self.circuit_breaker = CircuitBreaker(failure_threshold=3, timeout=30.0)

        # ë©”íŠ¸ë¦­
        self.total_executions = 0
        self.total_tokens = 0
        self.total_duration_ms = 0.0

    @abstractmethod
    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        """ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¡œì§ - ê° ì—ì´ì „íŠ¸ê°€ êµ¬í˜„"""
        pass

    async def _get_llm_response(
        self,
        kernel: Kernel,
        messages: List[Message],
        streaming: bool = False
    ) -> str:
        """LLM ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°"""
        chat_history = ChatHistory(system_message=self.system_prompt)

        for msg in messages:
            if msg.role == AgentRole.USER:
                chat_history.add_user_message(msg.content)
            elif msg.role == AgentRole.ASSISTANT:
                chat_history.add_assistant_message(msg.content)

        # ì‹¤í–‰ ì„¤ì •
        settings = create_execution_settings(
            model=self.model,
            temperature=self.temperature,
            max_tokens=self.max_tokens,
            service_id=self.service_id
        )

        # ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        chat_service = kernel.get_service(type=ChatCompletionClientBase)

        if streaming or self.enable_streaming:
            return await self._stream_response(chat_service, chat_history, settings)
        else:
            response = await chat_service.get_chat_message_content(
                chat_history=chat_history,
                settings=settings
            )
            return str(response) if response else ""

    async def _stream_response(
        self,
        chat_service: ChatCompletionClientBase,
        chat_history: ChatHistory,
        settings
    ) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬"""
        full_response = []
        async for chunk in chat_service.get_streaming_chat_message_content(
            chat_history=chat_history,
            settings=settings
        ):
            if isinstance(chunk, StreamingChatMessageContent):
                content = str(chunk)
                full_response.append(content)
                print(content, end='', flush=True)
        print()
        return "".join(full_response)

    async def _emit_event(self, event_type: EventType, data: Dict[str, Any]):
        """ì´ë²¤íŠ¸ ë°œí–‰"""
        if self.event_bus:
            event = AgentEvent(
                event_type=event_type,
                agent_name=self.name,
                data=data
            )
            await self.event_bus.publish(event)


# ============================================================================
# SimpleAgent - ë‹¨ìˆœ ëŒ€í™” ì—ì´ì „íŠ¸
# ============================================================================

class SimpleAgent(Agent):
    """
    ë‹¨ìˆœ ëŒ€í™” Agent

    ì£¼ìš” ê¸°ëŠ¥:
    1. ì´ë²¤íŠ¸ ë°œí–‰ (AGENT_STARTED, AGENT_COMPLETED, AGENT_FAILED)
    2. íšŒë¡œ ì°¨ë‹¨ê¸°ë¥¼ í†µí•œ í˜¸ì¶œ
    3. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (total_executions, total_duration_ms)
    """

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        start_time = time.time()

        await self._emit_event(EventType.AGENT_STARTED, {"node": self.name})

        try:
            recent_messages = state.get_conversation_history(max_messages=5)

            response = await self.circuit_breaker.call(
                self._get_llm_response,
                kernel,
                recent_messages,
                self.enable_streaming
            )

            state.add_message(AgentRole.ASSISTANT, response, self.name)

            duration_ms = (time.time() - start_time) * 1000

            self.total_executions += 1
            self.total_duration_ms += duration_ms

            await self._emit_event(EventType.AGENT_COMPLETED, {
                "node": self.name,
                "duration_ms": duration_ms
            })

            return NodeResult(
                node_name=self.name,
                output=response,
                success=True,
                duration_ms=duration_ms
            )
        except Exception as e:
            logging.error(f"âŒ Agent {self.name} ì‹¤í–‰ ì‹¤íŒ¨: {e}")

            await self._emit_event(EventType.AGENT_FAILED, {
                "node": self.name,
                "error": str(e)
            })

            return NodeResult(
                node_name=self.name,
                output="",
                success=False,
                error=str(e)
            )


# ============================================================================
# ApprovalAgent - ìŠ¹ì¸ í•„ìš” ì—ì´ì „íŠ¸
# ============================================================================

class ApprovalAgent(Agent):
    """
    ìŠ¹ì¸ì´ í•„ìš”í•œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” Agent

    Human-in-the-loop íŒ¨í„´ êµ¬í˜„

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ë°ì´í„° ì‚­ì œ ì‘ì—…
    - ê²°ì œ ì²˜ë¦¬
    - ì¤‘ìš” ì„¤ì • ë³€ê²½
    - ì™¸ë¶€ API í˜¸ì¶œ
    """

    def __init__(self, *args, approval_function: ApprovalRequiredAIFunction, **kwargs):
        super().__init__(*args, **kwargs)
        self.approval_function = approval_function

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        start_time = time.time()

        try:
            recent_messages = state.get_conversation_history(max_messages=3)
            last_message = recent_messages[-1].content if recent_messages else ""

            approval_result = await self.approval_function.execute(input=last_message)

            if approval_result["status"] == ApprovalStatus.PENDING:
                state.add_pending_approval(approval_result)
                await self._emit_event(EventType.APPROVAL_REQUESTED, approval_result)

                return NodeResult(
                    node_name=self.name,
                    output=f"ìŠ¹ì¸ ëŒ€ê¸° ì¤‘: {approval_result['description']}",
                    success=True,
                    requires_approval=True,
                    approval_data=approval_result,
                    duration_ms=(time.time() - start_time) * 1000
                )
            else:
                result = approval_result.get("result", "")
                state.add_message(AgentRole.ASSISTANT, str(result), self.name)

                return NodeResult(
                    node_name=self.name,
                    output=str(result),
                    success=True,
                    duration_ms=(time.time() - start_time) * 1000
                )

        except Exception as e:
            logging.error(f"âŒ ApprovalAgent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return NodeResult(
                node_name=self.name,
                output="",
                success=False,
                error=str(e)
            )


# ============================================================================
# RouterAgent - ë¼ìš°íŒ… ì—ì´ì „íŠ¸
# ============================================================================

class RouterAgent(Agent):
    """
    ë¼ìš°íŒ… Agent

    ì£¼ìš” ê¸°ëŠ¥:
    1. default_route íŒŒë¼ë¯¸í„°
    2. routing_history ì¶”ì 
    3. ë©”íƒ€ë°ì´í„°ì— confidence ì¶”ê°€
    """

    def __init__(self, *args, routes: Dict[str, str],
                 default_route: Optional[str] = None, **kwargs):
        super().__init__(*args, role=AgentRole.ROUTER, **kwargs)
        self.routes = routes
        self.default_route = default_route or list(routes.values())[0] if routes else None
        self.routing_history: List[Dict[str, Any]] = []

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        start_time = time.time()

        try:
            recent_messages = state.get_conversation_history(max_messages=3)
            last_message = recent_messages[-1].content if recent_messages else ""

            routes_list = ', '.join(self.routes.keys())
            classification_prompt = f"""Classify the user's intent into one of these categories: {routes_list}

User message: {last_message}

Respond with ONLY the category name (one word)."""

            temp_messages = [Message(role=AgentRole.USER, content=classification_prompt)]
            intent = await self._get_llm_response(kernel, temp_messages)
            intent = intent.strip().lower()

            next_node = self.routes.get(intent, self.default_route)
            duration_ms = (time.time() - start_time) * 1000

            routing_record = {
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "message": last_message,
                "intent": intent,
                "next_node": next_node
            }
            self.routing_history.append(routing_record)

            logging.info(f"ğŸ”€ Router: '{intent}' -> '{next_node}'")

            return NodeResult(
                node_name=self.name,
                output=f"ë¼ìš°íŒ…: {next_node} (ì¸í…íŠ¸: {intent})",
                next_node=next_node,
                success=True,
                duration_ms=duration_ms,
                metadata={"intent": intent, "confidence": 0.95}
            )
        except Exception as e:
            logging.error(f"âŒ Router ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return NodeResult(
                node_name=self.name,
                output="",
                next_node=self.default_route,
                success=False,
                error=str(e)
            )


# ============================================================================
# ProxyAgent - ì‚¬ìš©ì ëª…í™•í™” ìš”ì²­ ì—ì´ì „íŠ¸ (Microsoft Pattern)
# ============================================================================

class ProxyAgent(Agent):
    """
    ProxyAgent - ì‚¬ìš©ì ëª…í™•í™” ìš”ì²­ ì—ì´ì „íŠ¸ (Microsoft Pattern)

    ì‘ì—…ì„ ì§„í–‰í•˜ê¸° ì „ì— ì‚¬ìš©ìì—ê²Œ ì¶”ê°€ ì •ë³´ë‚˜ ëª…í™•í™”ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤.

    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - ëª¨í˜¸í•œ ìš”ì²­ì˜ ëª…í™•í™”
    - ì¤‘ìš” ê²°ì • ì „ ì‚¬ìš©ì í™•ì¸
    - ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘
    - ë³µì¡í•œ ì˜µì…˜ ì¤‘ ì„ íƒ ìš”ì²­
    """

    def __init__(
        self,
        *args,
        clarification_callback: Optional[Callable] = None,
        max_wait_seconds: int = 300,
        auto_proceed_on_timeout: bool = False,
        **kwargs
    ):
        super().__init__(*args, **kwargs)
        self.clarification_callback = clarification_callback
        self.max_wait_seconds = max_wait_seconds
        self.auto_proceed_on_timeout = auto_proceed_on_timeout
        self.pending_clarifications: List[Dict[str, Any]] = []

    async def request_clarification(
        self,
        question: str,
        options: Optional[List[str]] = None,
        context: str = "",
        required: bool = True
    ) -> Dict[str, Any]:
        """ì‚¬ìš©ìì—ê²Œ ëª…í™•í™” ìš”ì²­"""
        clarification_request = {
            "id": f"clarify-{int(time.time()*1000)}",
            "question": question,
            "options": options,
            "context": context,
            "required": required,
            "status": "pending",
            "requested_at": datetime.now(timezone.utc).isoformat(),
            "response": None
        }

        self.pending_clarifications.append(clarification_request)
        return clarification_request

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        """ProxyAgent ì‹¤í–‰"""
        start_time = time.time()

        try:
            recent_messages = state.get_conversation_history(max_messages=3)
            last_message = recent_messages[-1].content if recent_messages else ""

            analysis_prompt = f"""Analyze if the following request needs clarification.

User request: {last_message}

If clarification is needed, respond with:
{{
    "needs_clarification": true,
    "question": "the clarification question",
    "options": ["option1", "option2"] or null,
    "reason": "why clarification is needed"
}}

If no clarification is needed, respond with:
{{
    "needs_clarification": false
}}
"""
            temp_messages = [Message(role=AgentRole.USER, content=analysis_prompt)]
            response = await self._get_llm_response(kernel, temp_messages)

            try:
                json_match = re.search(r'\{[^{}]*\}', response, re.DOTALL)
                if json_match:
                    analysis = json.loads(json_match.group())
                else:
                    analysis = {"needs_clarification": False}
            except json.JSONDecodeError:
                analysis = {"needs_clarification": False}

            duration_ms = (time.time() - start_time) * 1000

            if analysis.get("needs_clarification", False):
                clarification = await self.request_clarification(
                    question=analysis.get("question", "ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."),
                    options=analysis.get("options"),
                    context=analysis.get("reason", "")
                )

                await self._emit_event(
                    EventType.APPROVAL_REQUESTED,
                    {"clarification": clarification}
                )

                ws_message = StreamingMessage(
                    type=WebSocketMessageType.USER_CLARIFICATION_NEEDED,
                    content=clarification["question"],
                    agent_name=self.name,
                    session_id=state.session_id,
                    metadata={"clarification_id": clarification["id"], "options": clarification["options"]}
                )

                return NodeResult(
                    node_name=self.name,
                    output=f"ëª…í™•í™” í•„ìš”: {clarification['question']}",
                    success=True,
                    requires_approval=True,
                    approval_data=clarification,
                    duration_ms=duration_ms,
                    metadata={
                        "clarification_request": clarification,
                        "ws_message": ws_message.model_dump()
                    }
                )
            else:
                return NodeResult(
                    node_name=self.name,
                    output="ëª…í™•í™” ë¶ˆí•„ìš” - ì§„í–‰í•©ë‹ˆë‹¤.",
                    success=True,
                    duration_ms=duration_ms
                )

        except Exception as e:
            logging.error(f"âŒ ProxyAgent ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return NodeResult(
                node_name=self.name,
                output="",
                success=False,
                error=str(e)
            )

    async def provide_response(self, clarification_id: str, response: str) -> bool:
        """ëª…í™•í™” ì‘ë‹µ ì œê³µ"""
        for clarification in self.pending_clarifications:
            if clarification["id"] == clarification_id:
                clarification["response"] = response
                clarification["status"] = "answered"
                clarification["answered_at"] = datetime.now(timezone.utc).isoformat()
                return True
        return False


# ============================================================================
# InvestigationPlan & SupervisorAgent
# ============================================================================

@dataclass(slots=True)
class InvestigationPlan:
    """
    Investigation Plan - ë©€í‹° ì—ì´ì „íŠ¸ ì¡°ì‚¬ ê³„íš

    ì°¸ì¡°: amazon-bedrock-agentcore-samples/SRE-agent/supervisor.py
    """
    steps: List[str]
    agents_sequence: List[str]
    complexity: str = "simple"
    auto_execute: bool = True
    reasoning: str = ""

    def to_dict(self) -> Dict[str, Any]:
        return {
            "steps": self.steps,
            "agents_sequence": self.agents_sequence,
            "complexity": self.complexity,
            "auto_execute": self.auto_execute,
            "reasoning": self.reasoning
        }


class SupervisorAgent(Agent):
    """
    Supervisor Agent - ì—¬ëŸ¬ Agentë¥¼ ê°ë…í•˜ê³  ì¡°ìœ¨

    ì£¼ìš” ê¸°ëŠ¥:
    1. Investigation Plan ìƒì„± ë° ì‹¤í–‰
    2. ë¼ìš´ë“œ ê¸°ë°˜ í˜‘ì—… (max_rounds)
    3. ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ("TERMINATE" í‚¤ì›Œë“œ)
    4. ìƒì„¸í•œ ì‹¤í–‰ ë¡œê·¸ (execution_log)
    5. ì‘ë‹µ ì§‘ê³„ (aggregate_responses)
    6. ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ í†µí•© (memory_hook)
    """

    def __init__(
        self,
        *args,
        sub_agents: List[Agent],
        max_rounds: int = 3,
        memory_hook: Optional[Any] = None,
        auto_approve_simple: bool = True,
        **kwargs
    ):
        super().__init__(*args, role=AgentRole.SUPERVISOR, **kwargs)
        self.sub_agents = {agent.name: agent for agent in sub_agents}
        self.max_rounds = max_rounds
        self.memory_hook = memory_hook
        self.auto_approve_simple = auto_approve_simple
        self.execution_log: List[Dict[str, Any]] = []
        self.investigation_history: List[InvestigationPlan] = []

    async def create_investigation_plan(
        self,
        state: AgentState,
        kernel: Kernel
    ) -> InvestigationPlan:
        """Investigation Plan ìƒì„±"""
        agent_names = list(self.sub_agents.keys())
        agent_descriptions = ", ".join([
            f"{name}: {agent.system_prompt[:100]}..."
            for name, agent in self.sub_agents.items()
        ])

        query = state.messages[-1].content if state.messages else ""

        planning_prompt = f"""You are a Supervisor Agent. Create an investigation plan for the following query.

Query: {query}

Available Agents: {agent_descriptions}

Respond with:
1. Steps to execute (numbered list)
2. Agent sequence (comma-separated agent names)
3. Complexity assessment (simple/complex)
4. Brief reasoning

Format your response as:
STEPS: step1, step2, step3
AGENTS: agent1, agent2
COMPLEXITY: simple
REASONING: explanation
"""
        temp_messages = [Message(role=AgentRole.USER, content=planning_prompt)]
        response = await self._get_llm_response(kernel, temp_messages)

        # ì‘ë‹µ íŒŒì‹±
        steps = []
        agents_sequence = agent_names[:2]
        complexity = "simple"
        reasoning = ""

        for line in response.split('\n'):
            line_upper = line.upper().strip()
            if line_upper.startswith('STEPS:'):
                steps = [s.strip() for s in line.split(':', 1)[1].split(',')]
            elif line_upper.startswith('AGENTS:'):
                agents_sequence = [a.strip() for a in line.split(':', 1)[1].split(',')]
            elif line_upper.startswith('COMPLEXITY:'):
                complexity = line.split(':', 1)[1].strip().lower()
            elif line_upper.startswith('REASONING:'):
                reasoning = line.split(':', 1)[1].strip()

        plan = InvestigationPlan(
            steps=steps or ["Execute query"],
            agents_sequence=[a for a in agents_sequence if a in self.sub_agents],
            complexity=complexity,
            auto_execute=self.auto_approve_simple and complexity == "simple",
            reasoning=reasoning
        )

        self.investigation_history.append(plan)
        return plan

    async def execute(self, state: AgentState, kernel: Kernel) -> NodeResult:
        """Supervisor ì‹¤í–‰"""
        start_time = time.time()

        await self._emit_event(EventType.AGENT_STARTED, {
            "agent": self.name,
            "sub_agents": list(self.sub_agents.keys())
        })

        try:
            plan = await self.create_investigation_plan(state, kernel)
            logging.info(f"ğŸ“‹ Investigation Plan: {plan.to_dict()}")

            all_responses = []
            round_count = 0

            for agent_name in plan.agents_sequence:
                if round_count >= self.max_rounds:
                    break

                agent = self.sub_agents.get(agent_name)
                if not agent:
                    continue

                logging.info(f"â–¶ï¸ Round {round_count + 1}: Executing {agent_name}")
                round_start = time.time()

                result = await agent.execute(state, kernel)

                self.execution_log.append({
                    "round": round_count + 1,
                    "agent": agent_name,
                    "success": result.success,
                    "output": result.output[:200],
                    "duration_ms": (time.time() - round_start) * 1000
                })

                if result.success:
                    all_responses.append(f"[{agent_name}]: {result.output}")
                    if "TERMINATE" in result.output.upper():
                        logging.info("ğŸ›‘ ì¢…ë£Œ ì¡°ê±´ ê°ì§€")
                        break

                round_count += 1

            aggregated = await self._aggregate_responses(kernel, all_responses)
            state.add_message(AgentRole.ASSISTANT, aggregated, self.name)

            duration_ms = (time.time() - start_time) * 1000

            await self._emit_event(EventType.AGENT_COMPLETED, {
                "agent": self.name,
                "rounds": round_count,
                "duration_ms": duration_ms
            })

            return NodeResult(
                node_name=self.name,
                output=aggregated,
                success=True,
                duration_ms=duration_ms,
                metadata={
                    "plan": plan.to_dict(),
                    "rounds_executed": round_count,
                    "execution_log": self.execution_log[-round_count:]
                }
            )
        except Exception as e:
            logging.error(f"âŒ Supervisor ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return NodeResult(
                node_name=self.name,
                output="",
                success=False,
                error=str(e)
            )

    async def _aggregate_responses(
        self,
        kernel: Kernel,
        responses: List[str]
    ) -> str:
        """ì‘ë‹µ ì§‘ê³„"""
        if not responses:
            return "No responses collected."

        if len(responses) == 1:
            return responses[0]

        aggregation_prompt = f"""Summarize and synthesize these responses:

{chr(10).join(responses)}

Provide a coherent, comprehensive summary."""

        temp_messages = [Message(role=AgentRole.USER, content=aggregation_prompt)]
        return await self._get_llm_response(kernel, temp_messages)
