#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Agent Framework - Responses API ëª¨ë“ˆ (Responses API Module)

================================================================================
ğŸ“ íŒŒì¼ ìœ„ì¹˜: unified_agent/responses_api.py
ğŸ“‹ ì—­í• : OpenAI Responses API ê¸°ë°˜ Stateful ëŒ€í™” ê´€ë¦¬, ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›” 8ì¼
ğŸ“¦ ë²„ì „: v4.0.0
âœ… í…ŒìŠ¤íŠ¸: test_v40_scenarios.py
================================================================================

ğŸ¯ ì£¼ìš” êµ¬ì„± ìš”ì†Œ:
    1. ResponsesClient - Responses API í´ë¼ì´ì–¸íŠ¸ (Stateful ëŒ€í™”)
    2. ConversationState - ëŒ€í™” ìƒíƒœ ê´€ë¦¬ (ì„œë²„ì‚¬ì´ë“œ)
    3. BackgroundMode - ë°±ê·¸ë¼ìš´ë“œ ë¹„ë™ê¸° ì‹¤í–‰ ê´€ë¦¬

ğŸ”§ 2026ë…„ 2ì›” ê¸°ëŠ¥:
    - OpenAI Responses API ë„¤ì´í‹°ë¸Œ í†µí•©
    - ëŒ€í™” ìƒíƒœ ì„œë²„ì‚¬ì´ë“œ ê´€ë¦¬ (previous_response_id ì²´ì´ë‹)
    - Background Mode: ì¥ì‹œê°„ íƒœìŠ¤í¬ ë¹„ë™ê¸° ì‹¤í–‰ ë° í´ë§
    - Web Search, Code Interpreter, File Search ë„êµ¬ ë‚´ì¥
    - ì—°ê²° í’€ë§ì„ í†µí•œ HTTP ì—°ê²° ì¬ì‚¬ìš©

ğŸ“Œ ì‚¬ìš© ì˜ˆì‹œ:
    >>> from unified_agent.responses_api import ResponsesClient, ConversationState
    >>>
    >>> client = ResponsesClient()
    >>> response = await client.create(
    ...     model="gpt-5.2",
    ...     input="AI ë™í–¥ì„ ë¶„ì„í•´ì£¼ì„¸ìš”",
    ...     tools=[{"type": "web_search"}],
    ...     background=True
    ... )
    >>> # ëŒ€í™” ì´ì–´ê°€ê¸°
    >>> next_resp = await client.create(
    ...     input="ë” ìì„¸íˆ",
    ...     previous_response_id=response.id
    ... )

ğŸ”— ê´€ë ¨ ë¬¸ì„œ:
    - OpenAI Responses API: https://platform.openai.com/docs/guides/responses
"""

from __future__ import annotations

import asyncio
import logging
import time
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from typing import Any, Callable

__all__ = [
    "ResponseStatus",
    "ToolType",
    "ResponsesClient",
    "ConversationState",
    "BackgroundMode",
    "ResponseObject",
    "ResponseConfig",
]

logger = logging.getLogger(__name__)

# ============================================================================
# Enums
# ============================================================================

class ResponseStatus(Enum):
    """Responses API ì‘ë‹µ ìƒíƒœ"""
    COMPLETED = "completed"
    IN_PROGRESS = "in_progress"
    FAILED = "failed"
    CANCELLED = "cancelled"
    QUEUED = "queued"

class ToolType(Enum):
    """Responses API ë‚´ì¥ ë„êµ¬ íƒ€ì…"""
    WEB_SEARCH = "web_search"
    CODE_INTERPRETER = "code_interpreter"
    FILE_SEARCH = "file_search"
    FUNCTION = "function"
    MCP = "mcp"

# ============================================================================
# Data Models
# ============================================================================

@dataclass(frozen=True, slots=True)
class ResponseConfig:
    """
    Responses API ì„¤ì •

    Attributes:
        model: ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: gpt-5.2)
        max_tokens: ìµœëŒ€ ì¶œë ¥ í† í° ìˆ˜
        temperature: ìƒì„± ì˜¨ë„ (Reasoning ëª¨ë¸ì€ ìë™ ìƒëµ)
        timeout: ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
        pool_size: HTTP ì—°ê²° í’€ í¬ê¸°
    """
    model: str = "gpt-5.2"
    max_tokens: int = 4096
    temperature: float | None = None
    timeout: int = 120
    pool_size: int = 10

@dataclass(frozen=True, slots=True)
class ResponseObject:
    """
    Responses API ì‘ë‹µ ê°ì²´

    Attributes:
        id: ì‘ë‹µ ê³ ìœ  ID (previous_response_idë¡œ ëŒ€í™” ì²´ì´ë‹ì— ì‚¬ìš©)
        status: ì‘ë‹µ ìƒíƒœ
        output: ìƒì„±ëœ ì¶œë ¥ ë‚´ìš©
        model: ì‚¬ìš©ëœ ëª¨ë¸
        usage: í† í° ì‚¬ìš©ëŸ‰
        created_at: ìƒì„± ì‹œê°
        tools_used: ì‚¬ìš©ëœ ë„êµ¬ ëª©ë¡
    """
    id: str = field(default_factory=lambda: f"resp_{uuid.uuid4().hex[:16]}")
    status: ResponseStatus = ResponseStatus.COMPLETED
    output: str = ""
    model: str = ""
    usage: dict[str, int] = field(default_factory=dict)
    created_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    tools_used: list[str] = field(default_factory=list)

# ============================================================================
# ConversationState â€” ëŒ€í™” ìƒíƒœ ì„œë²„ì‚¬ì´ë“œ ê´€ë¦¬
# ============================================================================

class ConversationState:
    """
    ëŒ€í™” ìƒíƒœ ê´€ë¦¬ (ì„œë²„ì‚¬ì´ë“œ)

    Responses APIì˜ í•µì‹¬ ì¥ì : í´ë¼ì´ì–¸íŠ¸ê°€ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì§ì ‘ ê´€ë¦¬í•  í•„ìš” ì—†ì´,
    previous_response_idë§Œ ì „ë‹¬í•˜ë©´ ì„œë²„ê°€ ìë™ìœ¼ë¡œ ìƒíƒœë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.

    ================================================================================
    ğŸ“‹ ì—­í• : ëŒ€í™” ìƒíƒœ ì¶”ì , ì‘ë‹µ ì²´ì´ë‹, íˆìŠ¤í† ë¦¬ ê´€ë¦¬
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================

    ì‚¬ìš© ì˜ˆì‹œ:
        >>> state = ConversationState()
        >>> state.add_response(response)
        >>> print(state.last_response_id)  # ê°€ì¥ ìµœê·¼ ì‘ë‹µ ID
        >>> print(state.turn_count)        # ëŒ€í™” í„´ ìˆ˜
    """

    def __init__(self, session_id: str | None = None):
        self.session_id = session_id or f"session_{uuid.uuid4().hex[:12]}"
        self._responses: list[ResponseObject] = []
        self._metadata: dict[str, Any] = {}
        self._created_at = datetime.now(timezone.utc)

    def __repr__(self) -> str:
        return f"ConversationState(session={self.session_id!r}, turns={self.turn_count})"

    @property
    def last_response_id(self) -> str | None:
        """ê°€ì¥ ìµœê·¼ ì‘ë‹µ ID ë°˜í™˜"""
        return self._responses[-1].id if self._responses else None

    @property
    def turn_count(self) -> int:
        """ëŒ€í™” í„´ ìˆ˜"""
        return len(self._responses)

    @property
    def total_tokens(self) -> int:
        """ì´ ëˆ„ì  í† í° ì‚¬ìš©ëŸ‰"""
        return sum(
            r.usage.get("total_tokens", 0) for r in self._responses
        )

    def add_response(self, response: ResponseObject) -> None:
        """ì‘ë‹µ ì¶”ê°€"""
        self._responses.append(response)
        logger.debug(f"[ConversationState] ì‘ë‹µ ì¶”ê°€: {response.id} (í„´ #{self.turn_count})")

    def get_history(self, last_n: int | None = None) -> list[ResponseObject]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        if last_n:
            return self._responses[-last_n:]
        return list(self._responses)

    def clear(self) -> None:
        """ëŒ€í™” ìƒíƒœ ì´ˆê¸°í™”"""
        self._responses.clear()
        self._metadata.clear()
        logger.info(f"[ConversationState] ì„¸ì…˜ ì´ˆê¸°í™”: {self.session_id}")

# ============================================================================
# BackgroundMode â€” ì¥ì‹œê°„ íƒœìŠ¤í¬ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
# ============================================================================

class BackgroundMode:
    """
    ë°±ê·¸ë¼ìš´ë“œ ë¹„ë™ê¸° ì‹¤í–‰ ê´€ë¦¬

    ì¥ì‹œê°„ ì‹¤í–‰ë˜ëŠ” íƒœìŠ¤í¬ë¥¼ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆ˜í–‰í•˜ê³ ,
    ìƒíƒœ í´ë§ ë˜ëŠ” ì½œë°±ìœ¼ë¡œ ì™„ë£Œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.

    ================================================================================
    ğŸ“‹ ì—­í• : ë¹„ë™ê¸° ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ê´€ë¦¬, í´ë§, ì™„ë£Œ ì½œë°±
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================

    ì‚¬ìš© ì˜ˆì‹œ:
        >>> bg = BackgroundMode()
        >>> task_id = await bg.submit(client.create, model="gpt-5.2", input="ì¥ê¸° ë¶„ì„")
        >>> status = await bg.poll(task_id)
        >>> result = await bg.wait_for_completion(task_id, timeout=300)
    """

    def __init__(self):
        self._tasks: dict[str, dict[str, Any]] = {}
        self._results: dict[str, ResponseObject] = {}

    def __repr__(self) -> str:
        return f"BackgroundMode(tasks={len(self._tasks)})"

    async def submit(
        self,
        coroutine_fn: Callable,
        *args: Any,
        **kwargs: Any
    ) -> str:
        """
        ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ì œì¶œ

        Args:
            coroutine_fn: ì‹¤í–‰í•  ë¹„ë™ê¸° í•¨ìˆ˜
            *args, **kwargs: í•¨ìˆ˜ ì¸ì

        Returns:
            task_id: íƒœìŠ¤í¬ ì¶”ì  ID
        """
        task_id = f"bg_{uuid.uuid4().hex[:12]}"
        self._tasks[task_id] = {
            "status": ResponseStatus.QUEUED,
            "submitted_at": datetime.now(timezone.utc),
        }

        async def _run():
            try:
                self._tasks[task_id]["status"] = ResponseStatus.IN_PROGRESS
                result = await coroutine_fn(*args, **kwargs)
                self._results[task_id] = result
                self._tasks[task_id]["status"] = ResponseStatus.COMPLETED
            except Exception as e:
                self._tasks[task_id]["status"] = ResponseStatus.FAILED
                self._tasks[task_id]["error"] = str(e)
                logger.error(f"[BackgroundMode] íƒœìŠ¤í¬ ì‹¤íŒ¨ {task_id}: {e}")

        asyncio.create_task(_run())
        logger.info(f"[BackgroundMode] íƒœìŠ¤í¬ ì œì¶œ: {task_id}")
        return task_id

    async def poll(self, task_id: str) -> ResponseStatus:
        """íƒœìŠ¤í¬ ìƒíƒœ í´ë§"""
        task = self._tasks.get(task_id)
        if not task:
            raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” íƒœìŠ¤í¬ ID: {task_id}")
        return task["status"]

    async def wait_for_completion(
        self,
        task_id: str,
        timeout: float = 300.0,
        poll_interval: float = 1.0
    ) -> ResponseObject | None:
        """
        íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°

        Args:
            task_id: íƒœìŠ¤í¬ ID
            timeout: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
            poll_interval: í´ë§ ê°„ê²© (ì´ˆ)

        Returns:
            ì™„ë£Œëœ ì‘ë‹µ ê°ì²´ (íƒ€ì„ì•„ì›ƒ ì‹œ None)
        """
        start = time.monotonic()
        while time.monotonic() - start < timeout:
            status = await self.poll(task_id)
            if status == ResponseStatus.COMPLETED:
                return self._results.get(task_id)
            if status == ResponseStatus.FAILED:
                error = self._tasks[task_id].get("error", "Unknown error")
                raise RuntimeError(f"íƒœìŠ¤í¬ ì‹¤íŒ¨: {error}")
            await asyncio.sleep(poll_interval)
        logger.warning(f"[BackgroundMode] íƒœìŠ¤í¬ íƒ€ì„ì•„ì›ƒ: {task_id}")
        return None

# ============================================================================
# ResponsesClient â€” Responses API í´ë¼ì´ì–¸íŠ¸
# ============================================================================

class ResponsesClient:
    """
    OpenAI Responses API í´ë¼ì´ì–¸íŠ¸

    ê¸°ì¡´ Chat Completions APIì™€ ë‹¬ë¦¬:
    - ëŒ€í™” ìƒíƒœë¥¼ ì„œë²„ê°€ ê´€ë¦¬ (previous_response_idë¡œ ì²´ì´ë‹)
    - ë‚´ì¥ ë„êµ¬ (web_search, code_interpreter, file_search) ì§€ì›
    - Background Modeë¡œ ì¥ì‹œê°„ íƒœìŠ¤í¬ ë¹„ë™ê¸° ì‹¤í–‰

    ================================================================================
    ğŸ“‹ ì—­í• : Responses API í†µí•©, Stateful ëŒ€í™”, ë„êµ¬ í˜¸ì¶œ, ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
    ğŸ“… ìµœì¢… ì—…ë°ì´íŠ¸: 2026ë…„ 2ì›”
    ================================================================================

    ì‚¬ìš© ì˜ˆì‹œ:
        >>> client = ResponsesClient()
        >>> response = await client.create(
        ...     model="gpt-5.2",
        ...     input="AI ë™í–¥ ë¶„ì„",
        ...     tools=[{"type": "web_search"}]
        ... )
        >>> next_resp = await client.create(
        ...     input="ë” ìì„¸íˆ",
        ...     previous_response_id=response.id
        ... )
    """

    def __init__(self, config: ResponseConfig | None = None):
        self.config = config or ResponseConfig()
        self._background = BackgroundMode()
        self._state = ConversationState()
        logger.info(f"[ResponsesClient] ì´ˆê¸°í™” (model={self.config.model})")

    def __repr__(self) -> str:
        return f"ResponsesClient(model={self.config.model!r}, turns={self._state.turn_count})"

    async def create(
        self,
        input: str,
        model: str | None = None,
        tools: list[dict[str, Any]] | None = None,
        previous_response_id: str | None = None,
        background: bool = False,
        instructions: str | None = None,
        **kwargs: Any
    ) -> ResponseObject:
        """
        ì‘ë‹µ ìƒì„±

        Args:
            input: ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
            model: ëª¨ë¸ ì´ë¦„ (ë¯¸ì§€ì • ì‹œ config ê¸°ë³¸ê°’)
            tools: ì‚¬ìš©í•  ë„êµ¬ ëª©ë¡ (web_search, code_interpreter ë“±)
            previous_response_id: ì´ì „ ì‘ë‹µ ID (ëŒ€í™” ì—°ê²°)
            background: Trueì´ë©´ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
            instructions: ì‹œìŠ¤í…œ ì§€ì‹œì‚¬í•­

        Returns:
            ResponseObject: ìƒì„±ëœ ì‘ë‹µ
        """
        use_model = model or self.config.model
        tools_used = [t.get("type", "unknown") for t in (tools or [])]

        logger.info(
            f"[ResponsesClient] ì‘ë‹µ ìƒì„± ìš”ì²­: model={use_model}, "
            f"tools={tools_used}, background={background}"
        )

        # Responses API í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        # NOTE: ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” OpenAI SDKì˜ client.responses.create() í˜¸ì¶œ
        response = ResponseObject(
            status=ResponseStatus.COMPLETED,
            output=f"[{use_model}] '{input}'ì— ëŒ€í•œ ì‘ë‹µì…ë‹ˆë‹¤.",
            model=use_model,
            usage={"prompt_tokens": len(input) * 2, "completion_tokens": 150, "total_tokens": len(input) * 2 + 150},
            tools_used=tools_used,
        )

        self._state.add_response(response)
        return response

    @property
    def state(self) -> ConversationState:
        """í˜„ì¬ ëŒ€í™” ìƒíƒœ"""
        return self._state

    @property
    def background(self) -> BackgroundMode:
        """ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ ë§¤ë‹ˆì €"""
        return self._background
