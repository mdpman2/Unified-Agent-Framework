#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Unified Agent Framework v5 â€” ì‹¤í–‰ ë°ëª¨

v5ì˜ Runner ì¤‘ì‹¬ ì„¤ê³„ë¥¼ ë³´ì—¬ì£¼ëŠ” ë°ëª¨ì…ë‹ˆë‹¤.
API í‚¤ ì—†ì´ë„ êµ¬ì¡° ê²€ì¦ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
"""

import asyncio
import sys
from pathlib import Path

# Windows cp949 í™˜ê²½ì—ì„œ ì´ëª¨ì§€ ì¶œë ¥ ì‹œ UnicodeEncodeError ë°©ì§€
if sys.stdout and hasattr(sys.stdout, "reconfigure"):
    sys.stdout.reconfigure(encoding="utf-8", errors="replace")
if sys.stderr and hasattr(sys.stderr, "reconfigure"):
    sys.stderr.reconfigure(encoding="utf-8", errors="replace")

sys.path.insert(0, str(Path(__file__).parent))


async def demo_1_basic_types():
    """ë°ëª¨ 1: í•µì‹¬ íƒ€ì… ê²€ì¦"""
    print("\n" + "=" * 60)
    print("ğŸ“¦ ë°ëª¨ 1: Core Types (Message, Memory, Tool)")
    print("=" * 60)

    from unified_agent_v5 import Message, Role, Memory, Tool, AgentConfig

    # Message
    msg = Message.user("ì•ˆë…•í•˜ì„¸ìš”!")
    print(f"  âœ… Message: {msg.to_dict()}")

    msg2 = Message.assistant("ë°˜ê°‘ìŠµë‹ˆë‹¤!")
    print(f"  âœ… Message: {msg2.to_dict()}")

    # Memory
    memory = Memory(system_prompt="You are a Python expert.")
    memory.add_user("íŒŒì´ì¬ì´ë€?")
    memory.add_assistant("íŒŒì´ì¬ì€ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.")
    memory.add_user("ë” ìì„¸íˆ ì•Œë ¤ì¤˜")

    print(f"  âœ… Memory: {memory}")
    print(f"     ë©”ì‹œì§€ ìˆ˜: {len(memory)}")
    print(f"     íˆìŠ¤í† ë¦¬:")
    for m in memory.get_messages():
        print(f"       [{m['role']}] {m['content'][:50]}...")

    # Memory ì§ë ¬í™”
    json_str = memory.to_json()
    restored = Memory.from_json(json_str)
    print(f"  âœ… Memory ì§ë ¬í™”/ë³µì›: {restored}")

    # Tool
    async def search(query: str) -> str:
        return f"ê²€ìƒ‰ ê²°ê³¼: {query}"

    tool = Tool(
        name="web_search",
        description="ì›¹ ê²€ìƒ‰",
        parameters={"query": {"type": "string", "description": "ê²€ìƒ‰ì–´"}},
        fn=search,
    )
    schema = tool.to_openai_schema()
    print(f"  âœ… Tool ìŠ¤í‚¤ë§ˆ: {schema['function']['name']}")

    result = await tool.execute(query="Python tutorial")
    print(f"  âœ… Tool ì‹¤í–‰: {result}")

    # Config
    config = AgentConfig(model="gpt-5.2", engine="direct")
    print(f"  âœ… Config: model={config.model}, engine={config.engine}")

    print("\n  ğŸ‰ ëª¨ë“  Core Types ê²€ì¦ ì™„ë£Œ!")
    return True


async def demo_2_tool_decorator():
    """ë°ëª¨ 2: @mcp_tool ë°ì½”ë ˆì´í„°"""
    print("\n" + "=" * 60)
    print("ğŸ”§ ë°ëª¨ 2: @mcp_tool ë°ì½”ë ˆì´í„°")
    print("=" * 60)

    from unified_agent_v5 import mcp_tool, ToolRegistry

    @mcp_tool(description="ë‚ ì”¨ ì¡°íšŒ")
    async def get_weather(city: str) -> str:
        """ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        city: ì¡°íšŒí•  ë„ì‹œ ì´ë¦„
        """
        return f"{city}: ë§‘ìŒ, 22Â°C"

    @mcp_tool(description="í™˜ìœ¨ ì¡°íšŒ")
    async def get_exchange_rate(from_currency: str, to_currency: str) -> str:
        """í™˜ìœ¨ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        return f"1 {from_currency} = 1,350 {to_currency}"

    print(f"  âœ… get_weather ìŠ¤í‚¤ë§ˆ: {get_weather.to_openai_schema()['function']['name']}")
    print(f"  âœ… get_exchange_rate ìŠ¤í‚¤ë§ˆ: {get_exchange_rate.to_openai_schema()['function']['name']}")

    # ë ˆì§€ìŠ¤íŠ¸ë¦¬
    registry = ToolRegistry()
    registry.register(get_weather)
    registry.register(get_exchange_rate)
    print(f"  âœ… Registry: {registry}")
    print(f"     ìŠ¤í‚¤ë§ˆ: {len(registry.get_openai_schemas())}ê°œ")

    # ì‹¤í–‰
    result = await get_weather.execute(city="ì„œìš¸")
    print(f"  âœ… ì‹¤í–‰ ê²°ê³¼: {result}")

    print("\n  ğŸ‰ ë°ì½”ë ˆì´í„° ê²€ì¦ ì™„ë£Œ!")
    return True


async def demo_3_callbacks():
    """ë°ëª¨ 3: ì½œë°± ì‹œìŠ¤í…œ"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ë°ëª¨ 3: Callback / Observability")
    print("=" * 60)

    from unified_agent_v5 import (
        LoggingCallbackHandler,
        OTelCallbackHandler,
        CompositeCallbackHandler,
        AgentResult,
    )
    from unified_agent_v5.types import ToolCall, ToolResult

    # Logging ì½œë°±
    log_cb = LoggingCallbackHandler()
    await log_cb.on_agent_start("í…ŒìŠ¤íŠ¸ ì§ˆë¬¸")

    result = AgentResult(
        content="í…ŒìŠ¤íŠ¸ ì‘ë‹µ",
        model="gpt-5.2",
        engine="direct",
        usage={"input_tokens": 10, "output_tokens": 20, "total_tokens": 30},
        duration_ms=150.0,
    )
    await log_cb.on_agent_end(result)
    print("  âœ… LoggingCallbackHandler ë™ì‘ í™•ì¸")

    # OTEL ì½œë°± (ì„¤ì¹˜ ì•ˆ ë˜ì–´ ìˆì–´ë„ ì•ˆì „)
    otel_cb = OTelCallbackHandler(service_name="test-agent")
    await otel_cb.on_agent_start("OTEL í…ŒìŠ¤íŠ¸")
    print("  âœ… OTelCallbackHandler ì´ˆê¸°í™” (graceful degradation)")

    # Composite
    composite = CompositeCallbackHandler([log_cb, otel_cb])
    await composite.on_agent_start("ë³µí•© í…ŒìŠ¤íŠ¸")
    await composite.on_llm_start("gpt-5.2", [{"role": "user", "content": "test"}])
    await composite.on_tool_start(ToolCall(id="tc-1", name="search", arguments={"q": "test"}))
    await composite.on_tool_end(ToolResult(tool_call_id="tc-1", name="search", content="result"))
    await composite.on_llm_end("ì‘ë‹µ", {"total_tokens": 50})
    await composite.on_agent_end(result)
    print("  âœ… CompositeCallbackHandler ë™ì‘ í™•ì¸")

    print("\n  ğŸ‰ ì½œë°± ì‹œìŠ¤í…œ ê²€ì¦ ì™„ë£Œ!")
    return True


async def demo_4_engine_registry():
    """ë°ëª¨ 4: ì—”ì§„ ë ˆì§€ìŠ¤íŠ¸ë¦¬"""
    print("\n" + "=" * 60)
    print("âš™ï¸ ë°ëª¨ 4: Engine Registry")
    print("=" * 60)

    from unified_agent_v5.engines import get_engine

    # Direct ì—”ì§„ (í•­ìƒ ì‚¬ìš© ê°€ëŠ¥)
    engine = get_engine("direct")
    print(f"  âœ… Direct ì—”ì§„: {type(engine).__name__}")

    # LangChain ì—”ì§„ (ì„¤ì¹˜ ì—¬ë¶€ì— ë”°ë¼)
    try:
        lc_engine = get_engine("langchain")
        print(f"  âœ… LangChain ì—”ì§„: {type(lc_engine).__name__}")
    except (ValueError, ImportError) as e:
        print(f"  â­ï¸ LangChain ë¯¸ì„¤ì¹˜: {e}")

    # CrewAI ì—”ì§„ (ì„¤ì¹˜ ì—¬ë¶€ì— ë”°ë¼)
    try:
        crew_engine = get_engine("crewai")
        print(f"  âœ… CrewAI ì—”ì§„: {type(crew_engine).__name__}")
    except (ValueError, ImportError) as e:
        print(f"  â­ï¸ CrewAI ë¯¸ì„¤ì¹˜: {e}")

    # ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ì§„
    try:
        get_engine("nonexistent")
    except ValueError as e:
        print(f"  âœ… ìœ íš¨ì„± ê²€ì¦: {e}")

    print("\n  ğŸ‰ ì—”ì§„ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê²€ì¦ ì™„ë£Œ!")
    return True


async def demo_5_runner():
    """ë°ëª¨ 5: Runner êµ¬ì¡° ê²€ì¦ (API í˜¸ì¶œ ì—†ì´)"""
    print("\n" + "=" * 60)
    print("ğŸš€ ë°ëª¨ 5: Runner ì„¤ê³„ ê²€ì¦")
    print("=" * 60)

    from unified_agent_v5 import Runner, AgentConfig, Memory

    # Runner ìƒì„±
    runner = Runner(config=AgentConfig(
        model="gpt-5.2",
        engine="direct",
        system_prompt="You are a Python expert.",
    ))
    print(f"  âœ… Runner ìƒì„±: engine={runner.config.engine}, model={runner.config.model}")

    # Memoryë¥¼ í†µí•œ ëŒ€í™” ê´€ë¦¬
    memory = Memory(system_prompt="You are a helpful assistant.")
    print(f"  âœ… Memory ìƒì„±: {memory}")

    # run_agent í•¨ìˆ˜ import í™•ì¸
    from unified_agent_v5 import run_agent
    print(f"  âœ… run_agent í•¨ìˆ˜ ì‚¬ìš© ê°€ëŠ¥")

    print("""
    ğŸ’¡ ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ (API í‚¤ê°€ ìˆì„ ë•Œ):

        # ê°€ì¥ ê°„ë‹¨í•œ ì‚¬ìš©
        result = await run_agent("íŒŒì´ì¬ í”¼ë³´ë‚˜ì¹˜ í•¨ìˆ˜ ì‘ì„±í•´ì¤˜")
        print(result.content)

        # ëŒ€í™” ì´ì–´ê°€ê¸°
        memory = Memory(system_prompt="You are helpful.")
        r1 = await run_agent("ë‚´ ì´ë¦„ì€ ì² ìˆ˜ì•¼", memory=memory)
        r2 = await run_agent("ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?", memory=memory)

        # ë„êµ¬ ì‚¬ìš©
        @mcp_tool(description="ë‚ ì”¨ ì¡°íšŒ")
        async def get_weather(city: str) -> str:
            return f"{city}: ë§‘ìŒ"
        result = await run_agent("ì„œìš¸ ë‚ ì”¨", tools=[get_weather])

        # ë©€í‹° ì—ì´ì „íŠ¸ (CrewAI)
        result = await run_agent(
            "ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œ",
            engine="crewai",
            crew_agents=[
                {"role": "Researcher", "goal": "ë°ì´í„° ìˆ˜ì§‘"},
                {"role": "Writer", "goal": "ë³´ê³ ì„œ ì‘ì„±"},
            ]
        )
    """)

    print("  ğŸ‰ Runner ì„¤ê³„ ê²€ì¦ ì™„ë£Œ!")
    return True


async def demo_6_comparison():
    """ë°ëª¨ 6: v4.1 vs v5 ë¹„êµ"""
    print("\n" + "=" * 60)
    print("ğŸ“Š ë°ëª¨ 6: v4.1 â†’ v5 ê°œì„  ë¹„êµ")
    print("=" * 60)

    print("""
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ í•­ëª©            â”‚ v4.1 (ê¸°ì¡´)                   â”‚ v5 (ê°œì„ )                     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ ëª¨ë“ˆ ìˆ˜         â”‚ 49ê°œ ëª¨ë“ˆ, 380+ API           â”‚ 9ê°œ ëª¨ë“ˆ, 20ê°œ API            â”‚
    â”‚ ì—”ì§„            â”‚ 16ê°œ í”„ë ˆì„ì›Œí¬ ë¸Œë¦¿ì§€         â”‚ Top 3 + Direct               â”‚
    â”‚ ëª¨ë‹ˆí„°ë§        â”‚ ìì²´ Tracer/Dashboard/DB      â”‚ OTEL ì–´ëŒ‘í„° (Export only)     â”‚
    â”‚ ë©”ëª¨ë¦¬          â”‚ 6ê°œ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ              â”‚ List[Message] + JSON ì§ë ¬í™”  â”‚
    â”‚ ë„êµ¬            â”‚ í”„ë ˆì„ì›Œí¬ë³„ ë‹¤ë¥¸ ë°©ì‹          â”‚ MCP í‘œì¤€ + OpenAI ìŠ¤í‚¤ë§ˆ     â”‚
    â”‚ ì§„ì…ì           â”‚ UnifiedAgentFramework.create() â”‚ run_agent("ì§ˆë¬¸")            â”‚
    â”‚ ì˜ì¡´ì„±          â”‚ semantic-kernel í•„ìˆ˜           â”‚ openaië§Œ í•„ìˆ˜, ë‚˜ë¨¸ì§€ ì„ íƒ    â”‚
    â”‚ ì‚¬ìš© ë‚œì´ë„     â”‚ ë†’ìŒ (ì„¤ì •/ì´í•´ í•„ìš”)          â”‚ ë‚®ìŒ (í•œ ì¤„ë¡œ ì‹œì‘)           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    ğŸ¯ í•µì‹¬ ë³€ê²½:
    1. "16ê°œ ì§€ì›" â†’ Top 3 + Direct (LangChain, CrewAI, Direct API)
    2. ìì²´ ëª¨ë‹ˆí„°ë§ â†’ OTEL í‘œì¤€ ì–´ëŒ‘í„° (callback_handler íŒ¨í„´)
    3. ë³µì¡í•œ ë©”ëª¨ë¦¬ â†’ ë‹¨ìˆœ List[Message]
    4. í”„ë ˆì„ì›Œí¬ë³„ ë„êµ¬ â†’ MCP í‘œì¤€ ì¼ì›í™”
    5. "ë§Œë“œëŠ” ë„êµ¬" â†’ "ì‹¤í–‰í•˜ëŠ” Runner"
    """)

    print("  ğŸ‰ ë¹„êµ ì™„ë£Œ!")
    return True


async def main():
    """ì „ì²´ ë°ëª¨ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸš€ Unified Agent Framework v5 â€” ë°ëª¨")
    print("   Runner-Centric Design")
    print("=" * 60)

    demos = [
        ("Core Types", demo_1_basic_types),
        ("@mcp_tool Decorator", demo_2_tool_decorator),
        ("Callback System", demo_3_callbacks),
        ("Engine Registry", demo_4_engine_registry),
        ("Runner Design", demo_5_runner),
        ("v4.1 vs v5 Comparison", demo_6_comparison),
    ]

    results = []
    for name, demo_fn in demos:
        try:
            success = await demo_fn()
            results.append((name, success))
        except Exception as e:
            print(f"\n  âŒ {name} ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“‹ ë°ëª¨ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    passed = sum(1 for _, s in results if s)
    total = len(results)
    for name, success in results:
        status = "âœ…" if success else "âŒ"
        print(f"  {status} {name}")
    print(f"\n  ê²°ê³¼: {passed}/{total} í†µê³¼")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())
